{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e516e46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization, \\\n",
    "                                    Input, Embedding, Masking, Bidirectional, Conv1D, Flatten, \\\n",
    "                                    MaxPooling1D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "from sklearn.utils import class_weight, shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 300\n",
    "\n",
    "from datetime import datetime, timedelta, date\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cx_Oracle\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "class seven_days_LSTM:\n",
    "    def __init__(self, eq_id, alarm_table, hour_horizontal, hour_vertical):\n",
    "        self.eq_id = eq_id\n",
    "        self.alarm_table = alarm_table\n",
    "        self.status_table = self.query_status()\n",
    "        self.hour_horizontal = hour_horizontal\n",
    "        self.hour_vertical = hour_vertical\n",
    "        \n",
    "        status_start = self.status_table.iloc[0][\"TIMESTAMP_START\"].date() + timedelta(days=1)\n",
    "        status_end = self.status_table.iloc[len(self.status_table)-1][\"TIMESTAMP_START\"].date()\n",
    "        alarm_start = self.alarm_table.iloc[0][\"DT_SET\"].date() + timedelta(days=1) # add one day to make it start from 00:00:00\n",
    "        alarm_end = self.alarm_table.iloc[len(self.alarm_table)-1][\"DT_SET\"].date()\n",
    "        self.start_date = max(status_start, alarm_start)\n",
    "        self.end_date = min(status_end, alarm_end)\n",
    "        \n",
    "        self.timeframe_table = self.generate_time(self.start_date.strftime(\"%d/%m/%Y\"), self.end_date.strftime(\"%d/%m/%Y\"), \\\n",
    "                                                  self.hour_horizontal, self.hour_vertical)\n",
    "        \n",
    "        #self.major_down_arr = self.new_major_down(self.timeframe_table, self.status_table, 6, 3600)\n",
    "\n",
    "        self.X_seq = self.alarm_breakdown_pattern(self.timeframe_table, self.alarm_table, self.status_table, self.hour_horizontal)\n",
    "        \n",
    "    def generate_time(self, start_date:str, end_date:str, hours_row:int, hour:int):\n",
    "        start = datetime.strptime(start_date, '%d/%m/%Y')\n",
    "        end = datetime.strptime(end_date, '%d/%m/%Y')\n",
    "\n",
    "        dates = []\n",
    "        while start+timedelta(hours=hours_row)<=end:\n",
    "            row = [start, start+timedelta(hours=hours_row)]\n",
    "            dates.append(row)\n",
    "            start += timedelta(hours=hour)\n",
    "\n",
    "        return pd.DataFrame(dates, columns=['TIMESTAMP_START', 'TIMESTAMP_END'])\n",
    "\n",
    "    \n",
    "    def alarm_breakdown_pattern(self, datetime_table, alarm_table, status_table, hour):\n",
    "        ORIG_ALARMS = []\n",
    "        \n",
    "        #validate alarm table date\n",
    "        if alarm_table.iloc[0]['DT_SET'] < status_table.iloc[0]['TIMESTAMP_START'] or \\\n",
    "            alarm_table.iloc[len(alarm_table)-1]['DT_SET'] > status_table.iloc[len(status_table)-1]['TIMESTAMP_START']:\n",
    "            raise ValueError(\"Alarm table date must be within the range of status table date\")\n",
    "\n",
    "        for idx, row in datetime_table.iterrows():\n",
    "            start = row['TIMESTAMP_START']\n",
    "            end = row['TIMESTAMP_END']\n",
    "\n",
    "            table = alarm_table[(alarm_table['DT_SET']>=start) & (alarm_table['DT_SET']<=end)]\n",
    "            new_table = table[[\"Alarm ID\"]]\n",
    "            \n",
    "            tmp2 = []\n",
    "            for n in new_table.values: # this part is needed to achieve the data structure in X_seq, else it would fail\n",
    "                tmp2.append(n[0])\n",
    "            ORIG_ALARMS.append(tmp2)\n",
    "\n",
    "        return np.array(ORIG_ALARMS)\n",
    "    \n",
    "    def query_status(self):\n",
    "        try:\n",
    "            oracle_string = \"oracle+cx_oracle://{username}:{password}@{hostname}:{port}/{database}\"\n",
    "            engine = create_engine(\n",
    "                oracle_string.format(\n",
    "                    username = 'TFM4CEBERUS',\n",
    "                    password = 'TFM4CEBERUS',\n",
    "                    hostname = 'ome-db.bth.infineon.com',\n",
    "                    port = '1538',\n",
    "                    database = 'ome'\n",
    "                    )\n",
    "                )\n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "\n",
    "        query = f\"\"\"select EQ_ID, TIMESTAMP_START, TIMESTAMP_END, DURATION, LEVEL3_NAME, LEVEL3 \n",
    "                from (SELECT\n",
    "                  eq.eq_id, eq.name, eq.eq_type_ident\n",
    "                , data.timestamp_start,data.timestamp_end\n",
    "                , ROUND((data.timestamp_end - data.timestamp_start)*24*60*60,0) AS Duration\n",
    "                , data.tr25_3_status,data.tr25_4_status,data.tr25_5_status,data.eq_status\n",
    "                , level5s.state_name\n",
    "                , level5.state_name Level5_Name, level5.state_sign Level5\n",
    "                , level4.state_name Level4_Name, level4.state_sign Level4\n",
    "                , level3.state_name Level3_Name, level3.state_sign Level3\n",
    "                ,mh.device\n",
    "                ,mh.package,\n",
    "                mh.lotid as lot,\n",
    "                mh.product,\n",
    "                mh.operation\n",
    "\n",
    "                FROM OMEDATA.EQUIPMENT_STATE_HISTORY data\n",
    "                , OMEADMIN.EQUIPMENT_INSTANCES eq\n",
    "                , V_EQ_STATES level5s\n",
    "                , OMEADMIN.DEF_STANDARD_STATEMODEL level5\n",
    "                , OMEADMIN.DEF_STANDARD_STATEMODEL level4\n",
    "                , OMEADMIN.DEF_STANDARD_STATEMODEL level3\n",
    "                , OMEDATA.METAKEY_HISTORY mh\n",
    "\n",
    "                WHERE data.eq_ident  = eq.eq_ident\n",
    "                AND  data.eq_status = level5s.state_ident(+)\n",
    "                AND level5.state_ident = data.tr25_5_status\n",
    "                AND level4.state_ident = data.tr25_4_status\n",
    "                AND level3.state_ident = data.tr25_3_status\n",
    "                AND  data.metakey_ident =mh.ident(+)\n",
    "                and data.timestamp_start > sysdate - 1500)\n",
    "                where eq_id = '{self.eq_id}'\n",
    "                ORDER BY TIMESTAMP_START\"\"\"\n",
    "\n",
    "        status = pd.read_sql(query, engine)\n",
    "        status.columns = map(lambda x: str(x).upper(), status.columns) \n",
    "\n",
    "        return status\n",
    "\n",
    "#     def major_down(self, input_table, status_table, hour, threshold):\n",
    "#         hour = pd.Timedelta(hours=hour)\n",
    "#         major_down = []\n",
    "        \n",
    "#         # timeframe table must be a subset of the status table to correctly determine major down\n",
    "#         if status_table.iloc[0][\"TIMESTAMP_START\"] > input_table.iloc[0][\"TIMESTAMP_START\"]:\n",
    "#             raise Exception(\"Timeframe table must be a subset of the status table\")\n",
    "#         if status_table.iloc[len(status_table)-1][\"TIMESTAMP_START\"] <= input_table.iloc[len(input_table)-1][\"TIMESTAMP_START\"]:\n",
    "#             raise Exception(\"Timeframe table must be a subset of the status table\")   \n",
    "            \n",
    "#         for idx, row in input_table.iterrows():\n",
    "#             start = row['TIMESTAMP_END']\n",
    "#             end = start+hour\n",
    "#             frame = status_table[(status_table['TIMESTAMP_START']>start) & (status_table['TIMESTAMP_START']<end)]\n",
    "#             UD = frame.loc[frame['LEVEL3']=='UDT']\n",
    "\n",
    "#             if len(UD) == 0: #no record within this 6 hours:\n",
    "#                 major_down.append(0)\n",
    "#             else:\n",
    "#                 time_diff = (UD['TIMESTAMP_END']-UD['TIMESTAMP_START']).dt.seconds\n",
    "#                 if any(time_diff>threshold):\n",
    "#                     major_down.append(1)\n",
    "#                 else:\n",
    "#                     major_down.append(0)\n",
    "#         return major_down\n",
    "\n",
    "def new_major_down(timeframe_table, status_table):\n",
    "    \"\"\"\n",
    "    Clean Status will have all 'Exception' LEVEL3 REMOVED to be able to use the str.contains pandas filter\n",
    "    Does not affect Major Down count since only EXC is removed\n",
    "    \"\"\"\n",
    "    major_down = []\n",
    "    for idx, row in timeframe_table.iterrows():\n",
    "        start = row['TIMESTAMP_START']\n",
    "        end = start + timedelta(hours=6)\n",
    "\n",
    "        down_query_filter = ((status_table['TIMESTAMP_START']>=start) &\n",
    "                    (status_table['TIMESTAMP_START']<=end) &\n",
    "                    (~(status_table['STATE_NAME'].str.contains('Waiting'))) &\n",
    "                    (status_table['LEVEL3']=='UDT'))\n",
    "\n",
    "        UD = status_table[down_query_filter]\n",
    "\n",
    "        if len(UD) == 0: #no record within this 6 hours:\n",
    "            major_down.append(0)\n",
    "        else:\n",
    "            time_diff = (UD['TIMESTAMP_END']-UD['TIMESTAMP_START']).dt.seconds\n",
    "            if any(time_diff>=3600): #threshold = 3600s\n",
    "                major_down.append(1)\n",
    "            else:\n",
    "                major_down.append(0)\n",
    "    return np.array(major_down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baf9c0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hour = 24\n",
    "wba127_fullalarm = pd.read_excel(\"Data/WBA127_FullAlarm.xlsx\", usecols = \"B,C,D,F,M\")\n",
    "wba127 = seven_days_LSTM(\"WBA127\", wba127_fullalarm, hour, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10a01d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "hour = 24\n",
    "wba124_fullalarm = pd.read_excel(\"Data/WBA127_FullAlarm.xlsx\", usecols = \"B,C,D,F,M\")\n",
    "wba124 = seven_days_LSTM(\"WBA127\", wba127_fullalarm, hour, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2eab6b6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIMESTAMP_START</th>\n",
       "      <th>TIMESTAMP_END</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-09-18 00:00:00</td>\n",
       "      <td>2018-09-19 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-09-18 03:00:00</td>\n",
       "      <td>2018-09-19 03:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-09-18 06:00:00</td>\n",
       "      <td>2018-09-19 06:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-09-18 09:00:00</td>\n",
       "      <td>2018-09-19 09:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-09-18 12:00:00</td>\n",
       "      <td>2018-09-19 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8604</th>\n",
       "      <td>2021-08-28 12:00:00</td>\n",
       "      <td>2021-08-29 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8605</th>\n",
       "      <td>2021-08-28 15:00:00</td>\n",
       "      <td>2021-08-29 15:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8606</th>\n",
       "      <td>2021-08-28 18:00:00</td>\n",
       "      <td>2021-08-29 18:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8607</th>\n",
       "      <td>2021-08-28 21:00:00</td>\n",
       "      <td>2021-08-29 21:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8608</th>\n",
       "      <td>2021-08-29 00:00:00</td>\n",
       "      <td>2021-08-30 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8609 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         TIMESTAMP_START       TIMESTAMP_END\n",
       "0    2018-09-18 00:00:00 2018-09-19 00:00:00\n",
       "1    2018-09-18 03:00:00 2018-09-19 03:00:00\n",
       "2    2018-09-18 06:00:00 2018-09-19 06:00:00\n",
       "3    2018-09-18 09:00:00 2018-09-19 09:00:00\n",
       "4    2018-09-18 12:00:00 2018-09-19 12:00:00\n",
       "...                  ...                 ...\n",
       "8604 2021-08-28 12:00:00 2021-08-29 12:00:00\n",
       "8605 2021-08-28 15:00:00 2021-08-29 15:00:00\n",
       "8606 2021-08-28 18:00:00 2021-08-29 18:00:00\n",
       "8607 2021-08-28 21:00:00 2021-08-29 21:00:00\n",
       "8608 2021-08-29 00:00:00 2021-08-30 00:00:00\n",
       "\n",
       "[8609 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wba124.timeframe_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6aad2f7",
   "metadata": {},
   "source": [
    "# Training with Embedding layer\n",
    "### LabelEncode the alarm id to determine n_vocab in Embedding layer\n",
    "### Since max_vocab measures the maximum number of unique vocab in our input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6e2ce0",
   "metadata": {},
   "source": [
    "## MOST UPDATED CODE - USE THE CODES BLOCKS BELOW!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91a0d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up 'None' statename with Exception LEVEL3, in order for str.contains to work\n",
    "wba127_clean_status = wba127_clean_status[wba127_clean_status['STATE_NAME'].notnull()]\n",
    "\n",
    "# find out which waiting to exclude\n",
    "query_filter = (wba127_clean_status['STATE_NAME'].str.contains('Waiting')) & (wba127_clean_status['LEVEL3']=='UDT')\n",
    "udt = wba127_clean_status[query_filter]\n",
    "udt['TYPE'] = np.where(udt['DURATION']>=3600, 'MAJOR DOWN', 'MINOR')\n",
    "udt.groupby(['STATE_NAME', 'TYPE']).agg({'STATE_NAME': 'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da63673",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeframe_table = generate_time('08/12/2018', '25/08/2021', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764f6fca",
   "metadata": {},
   "source": [
    "#### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a118d48f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.seven_days_LSTM at 0x7feb380dcbd0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wba124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc33a2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encode(X_seq): # do this the manual way as we are not certain if sklearn LabelEncoder can handle 3D array\n",
    "    all_unique_alarms = [set(ele) for ele in X_seq]\n",
    "    unique_alarms = set()\n",
    "    for ele in all_unique_alarms:\n",
    "        unique_alarms |= ele\n",
    "    \n",
    "    enc_label = 1  #start encoding from 1 as we have to pad the sequence with 0\n",
    "    mapping_dict = {}\n",
    "    for ele in unique_alarms:\n",
    "        mapping_dict[ele] = enc_label\n",
    "        enc_label += 1\n",
    "\n",
    "        enc_array = []\n",
    "        \n",
    "    #X_seq is a 3D array\n",
    "    for timestamp in X_seq:\n",
    "        tmp_arr = []\n",
    "        for ele in timestamp:\n",
    "            tmp_arr.append(mapping_dict[ele])\n",
    "        enc_array.append(np.array(tmp_arr))\n",
    "\n",
    "    return np.array(enc_array), len(unique_alarms)+1, mapping_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44f3a9f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([28, 11, 46, 46, 11, 4, 28, 28, 28, 28, 46, 73, 46, 73, 73, 46, 46, 73, 46, 73, 73, 73, 89, 73, 80, 80, 45, 20, 73, 46, 11, 73, 5, 5, 5, 28, 73]),\n",
       "       list([11, 4, 28, 28, 28, 28, 46, 73, 46, 73, 73, 46, 46, 73, 46, 73, 73, 73, 89, 73, 80, 80, 45, 20, 73, 46, 11, 73, 5, 5, 5, 28, 73, 11, 4, 5, 5, 5, 5, 5, 5, 33, 27]),\n",
       "       list([46, 73, 46, 73, 73, 46, 46, 73, 46, 73, 73, 73, 89, 73, 80, 80, 45, 20, 73, 46, 11, 73, 5, 5, 5, 28, 73, 11, 4, 5, 5, 5, 5, 5, 5, 33, 27, 11, 28, 150, 150, 150]),\n",
       "       ...,\n",
       "       list([27, 27, 27, 27, 27, 27, 27, 23, 23, 47, 47, 23, 47, 47, 28, 28, 47, 47, 47, 47, 47, 46, 46, 51, 47, 47, 47, 47, 47, 47, 47, 47, 47, 33, 33, 47, 46, 47, 28, 47, 46, 46, 46, 46, 47, 47, 46, 46, 46, 46, 11, 33, 33, 33, 33, 46, 46, 11, 33, 33, 33, 33, 10]),\n",
       "       list([47, 47, 23, 47, 47, 28, 28, 47, 47, 47, 47, 47, 46, 46, 51, 47, 47, 47, 47, 47, 47, 47, 47, 47, 33, 33, 47, 46, 47, 28, 47, 46, 46, 46, 46, 47, 47, 46, 46, 46, 46, 11, 33, 33, 33, 33, 46, 46, 11, 33, 33, 33, 33, 10, 33, 46, 46, 46, 47, 46, 46, 11, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 46]),\n",
       "       list([28, 47, 46, 46, 46, 46, 47, 47, 46, 46, 46, 46, 11, 33, 33, 33, 33, 46, 46, 11, 33, 33, 33, 33, 10, 33, 46, 46, 46, 47, 46, 46, 11, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 46, 11, 33, 33, 33, 33, 33, 46])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wba123.X_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abe426d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp1 = np.concatenate((wba123.X_seq, wba124.X_seq, wba126.X_seq, wba127.X_seq, wba128.X_seq))\n",
    "encoded_X_seq, n_alarms, mapping_dict = label_encode(tmp1)\n",
    "target = np.concatenate((wba123.major_down_arr, wba124.major_down_arr, wba126.major_down_arr, wba127.major_down_arr, wba128.major_down_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d73336c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14114dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([25, 11, 34, 34, 11,  4, 25, 25, 25, 25, 34, 42, 34, 42, 42, 34, 34,\n",
       "       42, 34, 42, 42, 42, 46, 42, 44, 44, 33, 17, 42, 34, 11, 42,  5,  5,\n",
       "        5, 25, 42]),\n",
       "       array([11,  4, 25, 25, 25, 25, 34, 42, 34, 42, 42, 34, 34, 42, 34, 42, 42,\n",
       "       42, 46, 42, 44, 44, 33, 17, 42, 34, 11, 42,  5,  5,  5, 25, 42, 11,\n",
       "        4,  5,  5,  5,  5,  5,  5, 29, 24]),\n",
       "       array([34, 42, 34, 42, 42, 34, 34, 42, 34, 42, 42, 42, 46, 42, 44, 44, 33,\n",
       "       17, 42, 34, 11, 42,  5,  5,  5, 25, 42, 11,  4,  5,  5,  5,  5,  5,\n",
       "        5, 29, 24, 11, 25, 19, 19, 19]),\n",
       "       ...,\n",
       "       array([34, 25, 34, 34, 32, 11, 31, 31, 31, 34, 34, 34, 25, 34, 32, 25, 34,\n",
       "       34, 34, 32, 32, 34, 34, 11, 34, 21, 34, 34, 34, 25, 34, 34, 34, 19,\n",
       "       26, 19, 26, 19, 26, 29, 11,  8,  8,  8,  8,  8,  8, 34, 25, 34, 32,\n",
       "       32, 32, 32, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "       20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "       20, 11]),\n",
       "       array([11, 31, 31, 31, 34, 34, 34, 25, 34, 32, 25, 34, 34, 34, 32, 32, 34,\n",
       "       34, 11, 34, 21, 34, 34, 34, 25, 34, 34, 34, 19, 26, 19, 26, 19, 26,\n",
       "       29, 11,  8,  8,  8,  8,  8,  8, 34, 25, 34, 32, 32, 32, 32, 20, 20,\n",
       "       20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "       20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11]),\n",
       "       array([34, 34, 25, 34, 32, 25, 34, 34, 34, 32, 32, 34, 34, 11, 34, 21, 34,\n",
       "       34, 34, 25, 34, 34, 34, 19, 26, 19, 26, 19, 26, 29, 11,  8,  8,  8,\n",
       "        8,  8,  8, 34, 25, 34, 32, 32, 32, 32, 20, 20, 20, 20, 20, 20, 20,\n",
       "       20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "       20, 20, 20, 20, 20, 20, 20, 20, 11])], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_X_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f3c89753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_alarms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd68d6c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17218"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_X_seq.shape[0] #Total number of data (alarm sequence from multiple equipments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "759f1ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_alarms_index = []\n",
    "for i in range(encoded_X_seq.shape[0]):\n",
    "    if encoded_X_seq[i].shape[0]==0:\n",
    "        empty_alarms_index.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a64c3b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2080"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(empty_alarms_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5c84a29b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 1997, 1: 83})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_values_for_empty_alarms = [target[i] for i in empty_alarms_index]\n",
    "from collections import Counter\n",
    "Counter(y_values_for_empty_alarms)\n",
    "#There are only 604 records of EMPTY alarms which cause breakdown (target = 1) out of 43000 -> very little, only 1%. \n",
    "#So these empty alarms records will be removed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "062f6f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removing empty alarms: \n",
    "encoded_X_seq_no_empty = np.delete(encoded_X_seq,empty_alarms_index)\n",
    "target_no_empty_alarms = np.delete(target,empty_alarms_index)\n",
    "encoded_X_seq_no_empty.shape[0]==target_no_empty_alarms.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2254b88",
   "metadata": {},
   "source": [
    "#### SAMPLE WEIGHTING - GENERATE THE WEIGHT FOR EACH ALARM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ba33ff8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{32: 2.6749897435897436,\n",
       " 10: 3.26014375,\n",
       " 11: 9.484054545454546,\n",
       " 30: 11.591622222222222,\n",
       " 41: 10.43246,\n",
       " 40: 3.26014375,\n",
       " 9: 3.26014375,\n",
       " 24: 2.608115,\n",
       " 33: 10.43246,\n",
       " 39: 3.26014375,\n",
       " 31: 10.43246,\n",
       " 20: 10.43246,\n",
       " 36: 3.26014375,\n",
       " 27: 4.3468583333333335,\n",
       " 19: 3.26014375,\n",
       " 21: 3.26014375,\n",
       " 18: 10.43246,\n",
       " 42: 3.26014375,\n",
       " 4: 3.26014375,\n",
       " 23: 2.608115,\n",
       " 6: 3.26014375,\n",
       " 5: 3.26014375,\n",
       " 29: 10.43246,\n",
       " 12: 3.26014375,\n",
       " 3: 3.26014375,\n",
       " 2: 10.43246,\n",
       " 14: 3.26014375,\n",
       " 16: 3.477486666666667,\n",
       " 15: 3.26014375,\n",
       " 34: 3.26014375,\n",
       " 1: 3.26014375,\n",
       " 13: 3.26014375,\n",
       " 22: 2.54450243902439,\n",
       " 17: 3.26014375,\n",
       " 35: 3.26014375,\n",
       " 7: 3.26014375,\n",
       " 43: 3.26014375,\n",
       " 25: 11.591622222222222,\n",
       " 37: 3.26014375,\n",
       " 45: 3.477486666666667,\n",
       " 38: 10.43246,\n",
       " 26: 10.43246,\n",
       " 8: 3.26014375,\n",
       " 44: 3.477486666666667,\n",
       " 28: 3.161351515151515,\n",
       " 0: 0}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Determining Sampling weights\n",
    "all_alarms = np.concatenate(encoded_X_seq_no_empty,axis = 0) #combining all ALARMS appear in X INTO 1 LIST\n",
    "#Counter(all_alarms).keys()\n",
    "\n",
    "alarm_weight = dict()\n",
    "for key in Counter(all_alarms).keys():\n",
    "    alarm_weight[key] = (all_alarms.shape[0]/all_alarms[key])/10000\n",
    "\n",
    "#100 alarms, alarm ID 44 appear 3 times. the 100/3 = 33\n",
    "\n",
    "alarm_weight[0] = 0 #For zeros value in X (to ignore the padding)\n",
    "alarm_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b74e54e",
   "metadata": {},
   "source": [
    "#### TF IDF TRIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "57ea8050",
   "metadata": {},
   "outputs": [],
   "source": [
    "#String alarm versions \n",
    "str_enc_X_alarm_no_empty = [encoded_X_seq_no_empty[i].astype(str) for i in range(encoded_X_seq_no_empty.shape[0]) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b70c38f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf=idf trial\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(lowercase=False)\n",
    "dummyvec = vectorizer.fit_transform(str_enc_X_alarm_no_empty[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cbbea62e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['32', '10', '32', '10', '32', '41', '40', '40', '9', '10', '24',\n",
       "       '33', '10', '9', '10', '39', '10', '32', '32', '32', '32', '10',\n",
       "       '32', '32', '10', '32', '32', '30', '30', '31', '30', '30', '30',\n",
       "       '30', '30', '30', '30', '30', '31', '10', '10', '10', '10'],\n",
       "      dtype='<U21')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_enc_X_alarm_no_empty[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f7f97098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_enc_X_alarm_no_empty[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6afe3c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10', '24', '30', '31', '32', '33', '39', '40', '41']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c8cbe152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43, 9)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummyvec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108b796f",
   "metadata": {},
   "source": [
    "#### Take a look at full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "531c9897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11,  4, 25, 25, 25])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_X_seq_no_empty[1][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "11aa9e49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = np.zeros((full_data.shape[0],5))\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "9f655069",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = pd.DataFrame({'Seq_no_empty':encoded_X_seq_no_empty})\n",
    "full_data['target'] = target_no_empty_alarms\n",
    "\n",
    "full_data['last_5_alarms'] = np.asarray([np.array(full_data['Seq_no_empty'][i][-5:]) for i in range(full_data.shape[0])])\n",
    "\n",
    "last_5 = full_data[['last_5_alarms','target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "051b48c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>last_5_alarms</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[5, 5, 5, 25, 42]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[5, 5, 5, 29, 24]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[11, 25, 19, 19, 19]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[25, 25, 21, 25, 42]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[42, 42, 25, 42, 42]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34889</th>\n",
       "      <td>[20, 20, 20, 20, 20]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34890</th>\n",
       "      <td>[20, 20, 20, 20, 11]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34891</th>\n",
       "      <td>[20, 20, 20, 20, 11]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34892</th>\n",
       "      <td>[20, 20, 20, 20, 11]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34893</th>\n",
       "      <td>[20, 20, 20, 20, 11]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34894 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              last_5_alarms  target\n",
       "0         [5, 5, 5, 25, 42]       0\n",
       "1         [5, 5, 5, 29, 24]       0\n",
       "2      [11, 25, 19, 19, 19]       0\n",
       "3      [25, 25, 21, 25, 42]       0\n",
       "4      [42, 42, 25, 42, 42]       0\n",
       "...                     ...     ...\n",
       "34889  [20, 20, 20, 20, 20]       0\n",
       "34890  [20, 20, 20, 20, 11]       0\n",
       "34891  [20, 20, 20, 20, 11]       0\n",
       "34892  [20, 20, 20, 20, 11]       0\n",
       "34893  [20, 20, 20, 20, 11]       0\n",
       "\n",
       "[34894 rows x 2 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2813a932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.options.display.max_colwidth=250\n",
    "# full_data.loc[full_data['target']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5180dbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.options.display.max_colwidth=250\n",
    "# full_data.loc[full_data['target']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "35a4c26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.options.display.max_colwidth=400\n",
    "# full_data.iloc[42:49]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0b3da9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.options.display.max_colwidth=400\n",
    "# full_data.iloc[108:116]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "48ebb6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.options.display.max_colwidth=400\n",
    "# full_data.iloc[50:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1d6a6d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.options.display.max_colwidth=1000\n",
    "# full_data.iloc[34792:34803]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf4661c",
   "metadata": {},
   "source": [
    "#### Last n Alarms Data Pre Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "594ac55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# last_5['length==5'] = [len(last_5['last_5_alarms'][i])==5 for i in range(last_5.shape[0])]\n",
    "# last_5.loc[(last_5['length==5'] == False)] #There are 703 rows where the number of alarms in that timeframe <5. \n",
    "# #Out of these 703 records, only 49 are major down. So we will remove these records. \n",
    "# #last_5.loc[(last_5['length==5'] == False) & (last_5['target'] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d33affe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop duplicates (duplication = no alarms happen in the 3 hours period between rows)\n",
    "last_5_clean = last_5_clean[['last_5_alarms','target']]\n",
    "last_5_clean['str_version'] = last_5_clean['last_5_alarms'].astype(str)\n",
    "duplicate = last_5_clean.duplicated(subset=['str_version'])\n",
    "\n",
    "index_duplicate = [i for i,x in enumerate(duplicate) if x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "09caa232",
   "metadata": {},
   "outputs": [],
   "source": [
    "l5nd = last_5_clean.drop_duplicates(subset=['str_version']) #l5nd = last 5 clean no duplicates \n",
    "pd.set_option(\"display.max_rows\",100)\n",
    "l5nd['target'].value_counts()\n",
    "l5nd_sf = l5nd.sample(frac=1,random_state = 3)\n",
    "l5nd_sf = l5nd_sf.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "ad870b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Padding data with alarm sequence length <5 \n",
    "pad_last_alarms = pad_sequences(\n",
    "    l5nd_sf['last_5_alarms'], maxlen=5, dtype='int32', padding='pre',\n",
    "    truncating='pre', value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "7abf340a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 364, 0: 2821})"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_tr_last,X_ts_last,y_tr_last,y_ts_last = train_test_split(pad_last_alarms,l5nd_sf['target'],stratify = l5nd_sf['target'], test_size = 0.2, random_state = 43)\n",
    "\n",
    "from collections import Counter \n",
    "Counter(y_ts_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "389cc483",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_weight: to be fit inside model.fit Keras API\n",
    "modelwtr_last = np.zeros((X_tr_last.shape[0],5))\n",
    "for i in range(modelwtr_last.shape[0]):\n",
    "    for j in range(5):\n",
    "        modelwtr_last[i,j] = alarm_weight[(X_tr_last[i][j])]\n",
    "        \n",
    "#FOR TEST \n",
    "modelwts_last = np.zeros((X_ts_last.shape[0],5)) #initialize model_weight\n",
    "#model_weight: to be fit inside model.fit Keras API\n",
    "for i in range(modelwts_last.shape[0]):\n",
    "    for j in range(5):\n",
    "        modelwts_last[i,j] = alarm_weight[(X_ts_last[i][j])]\n",
    "        \n",
    "#Changing to 1D\n",
    "mw1dtr_last = np.array([modelwtr_last[i].sum()/(modelwtr_last.shape[1]*30) for i in range(modelwtr_last.shape[0])])\n",
    "mw1dts_last = np.array([modelwts_last[i].sum()/(modelwts_last.shape[1]*30) for i in range(modelwts_last.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "4f563198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.12777505, 1.0238456 , 0.50613779, ..., 0.26760911, 0.20988101,\n",
       "       1.29771376])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mw1dts_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "f6b2d3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SMOTE\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "oversample = BorderlineSMOTE()\n",
    "X_tr_last_sm, y_tr_last_sm = oversample.fit_resample(X_tr_last,y_tr_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "40f0dbaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 11282, 1: 11282})"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_tr_last_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "00d7e20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model weight for SMOTE dataset\n",
    "#model_weight: to be fit inside model.fit Keras API\n",
    "modelwtr_last_sm = np.zeros((X_tr_last_sm.shape[0],5))\n",
    "\n",
    "for i in range(modelwtr_last_sm.shape[0]):\n",
    "    for j in range(5):\n",
    "        modelwtr_last_sm[i,j] = alarm_weight[(X_tr_last_sm[i][j])]\n",
    "        \n",
    "#Changing to 1D\n",
    "mw1dtr_last_sm = np.array([modelwtr_last_sm[i].sum()/(modelwtr_last_sm.shape[1]*30) for i in range(modelwtr_last_sm.shape[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9926d06a",
   "metadata": {},
   "source": [
    "#### Train Val Test Split (Original Data Frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ee8abc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividing to train & test split. To ensure there is no data leakage: \n",
    "#1. divide to train & test split BY index. 2. Shuffle EACH tain & test separately. \n",
    "\n",
    "training_size = round(encoded_X_seq_no_empty.shape[0]*(2/3))\n",
    "X_train = encoded_X_seq_no_empty[0:training_size]\n",
    "X_test = encoded_X_seq_no_empty[training_size:]\n",
    "\n",
    "y_train = target_no_empty_alarms[0:training_size]\n",
    "y_test = target_no_empty_alarms[training_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a6c6b1b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([32, 32, 36, 32, 36, 36, 32, 32, 32, 30, 41, 40, 40, 30, 18, 10, 30,\n",
       "       31, 31, 31, 31, 31, 31, 31, 32, 32, 32, 32, 32, 31, 31, 31, 31, 30,\n",
       "       31, 30, 31, 31, 31, 31, 31, 31, 32, 31, 31, 30, 32, 30, 32, 32, 31,\n",
       "       10, 30, 31, 31, 30, 31, 31, 31, 32, 30, 30, 30, 30, 30, 39, 32, 32,\n",
       "       39, 30, 32, 32, 32, 32, 32, 32, 32, 30, 39, 32, 32, 32, 39, 30, 32,\n",
       "       32, 18, 32, 24, 30, 32, 32, 32, 32, 11, 10, 31, 32, 32, 32, 32, 32])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "22eb35b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15138"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_X_seq_no_empty.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0512eea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape[0] ==X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "23f7cfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#COMBINE X & Y FIRST, THEN SHUFFLE (Otherwise the X & y values will not match if X shuffle, then y shuffle)\n",
    "tr = pd.DataFrame({'X_tr':X_train})\n",
    "ts = pd.DataFrame({'X_ts':X_test})\n",
    "tr['y_tr'] = y_train\n",
    "ts['y_ts'] = y_test\n",
    "\n",
    "#Shuffling \n",
    "tr_sf = tr.sample(frac=1,random_state = 40)\n",
    "ts_sf = ts.sample(frac=1,random_state = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5bdf4320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1185                                 [32, 31, 31, 19, 19]\n",
       "3796    [31, 31, 31, 31, 32, 39, 32, 31, 39, 32, 31, 3...\n",
       "7369    [27, 31, 31, 24, 22, 24, 31, 30, 32, 32, 32, 3...\n",
       "4164    [20, 20, 5, 18, 32, 39, 32, 32, 32, 39, 18, 18...\n",
       "8592    [33, 36, 36, 33, 33, 30, 36, 31, 32, 32, 32, 3...\n",
       "                              ...                        \n",
       "7839    [10, 30, 31, 31, 27, 24, 10, 31, 31, 31, 11, 3...\n",
       "3603    [11, 11, 39, 10, 39, 30, 30, 30, 30, 30, 10, 3...\n",
       "5959    [24, 20, 37, 24, 22, 37, 18, 20, 32, 32, 32, 3...\n",
       "5426    [37, 24, 32, 32, 24, 32, 10, 10, 19, 19, 19, 3...\n",
       "7608    [27, 32, 32, 32, 32, 32, 30, 32, 32, 32, 32, 3...\n",
       "Name: X_tr, Length: 10092, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_sf['X_tr']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb58d16",
   "metadata": {},
   "source": [
    "#### Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eec2021e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "sequence_length = [tr['X_tr'][i].shape[0] for i in range(tr.shape[0])]\n",
    "mean_length = round(np.mean(sequence_length))\n",
    "\n",
    "#padding & truncating PRE sequences (zeros will be at the beginning for sequence < mean_length. Cutting beginning sentence\n",
    "#for sentence > mean_length\n",
    "\n",
    "pad_X_tr = pad_sequences(\n",
    "    tr['X_tr'], maxlen=mean_length, dtype='int32', padding='pre',\n",
    "    truncating='pre', value=0)\n",
    "pad_X_ts = pad_sequences(\n",
    "    ts['X_ts'], maxlen=mean_length, dtype='int32', padding='pre',\n",
    "    truncating='pre', value=0)\n",
    "\n",
    "y_tr = tr['y_tr']\n",
    "y_ts = ts['y_ts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "823b2a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ..., 31, 10, 10],\n",
       "       [ 0,  0,  0, ..., 10, 10, 10],\n",
       "       [ 0,  0,  0, ..., 10, 32, 10],\n",
       "       ...,\n",
       "       [32, 31, 31, ..., 32, 32, 32],\n",
       "       [31, 31, 31, ..., 32, 32, 11],\n",
       "       [31, 31, 31, ..., 32, 11, 10]], dtype=int32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_X_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "34194e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10092, 66)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_X_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ef7c4a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[0,0,0,0,4,5,6,7]\n",
    "#[5,6,6,6,7,8,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "213fc4dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_alarms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "eee83362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 9491, 1: 601})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter \n",
    "Counter(tr['y_tr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cc431e",
   "metadata": {},
   "source": [
    "#### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052d88f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Putting SMOTE inside the pipline of imblearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "366a626e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying borderline SMOTE\n",
    "#has smoother result than regular SMOTE\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "oversample = BorderlineSMOTE()\n",
    "pad_X_tr_smote, y_tr_smote = oversample.fit_resample(pad_X_tr,tr['y_tr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "69befc33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "41081    1\n",
       "41082    1\n",
       "41083    1\n",
       "41084    1\n",
       "41085    1\n",
       "Name: y_tr, Length: 41086, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr_smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "25a83a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 10363, 1: 1268})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3b4433dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f836bfad",
   "metadata": {},
   "source": [
    "Data Preprocessing. <br>\n",
    "**To Do:** <br>\n",
    "~~1. TF-IDF + LSTM <br> ~~\n",
    "~~2. Class balancing <br> ~~\n",
    "~~2. Padding ? ~~\n",
    "~~3. Embedding ~~<br>\n",
    "4. Convolution + LSTM <br>\n",
    "5. Standardize the Alarm <br>ASSIGNING WEIGHT **BEFORE** STANDARDIZE THE DATA : ALARM_WEIGHT DICTIONARY KEYS = THE REAL ALARMS NOT THE STANDARDIZED ONE <br>\n",
    "6. Standardize the sample weight (to minimize the loss) <br>\n",
    "**7. Try 2D weighting <br>**\n",
    "8. Why overfit for the current model? Should the test set also has SMOTE? <br>\n",
    "9. To SMOTE or not to SMOTE? SMOTE seems to cause the overfitting <br>\n",
    "10. SMOTE + CROSS VALIDATION (Put SMOTE inside imblearn pipeline) <br>\n",
    "- Understand how LSTM works with words vs numbers ? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307f3efb",
   "metadata": {},
   "source": [
    "#### Generate Sample weight for both training & test set (for model.fit & model.evaluate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d3ce657c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ...,  5, 25, 42],\n",
       "       [ 0,  0,  0, ...,  5, 29, 24],\n",
       "       [ 0,  0,  0, ..., 19, 19, 19],\n",
       "       ...,\n",
       "       [34, 36, 36, ..., 26, 11, 26],\n",
       "       [34, 33, 32, ..., 33, 33, 33],\n",
       "       [ 0,  0,  0, ..., 43, 41, 41]], dtype=int32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_X_tr_smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0c5cd77e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.269384"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alarm_weight[pad_X_tr_smote[0][43]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a408069a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #FOR TRAINING WITH SMOTE\n",
    "# model_weight_tr = np.zeros((pad_X_tr_smote.shape[0],pad_X_tr_smote.shape[1])) #initialize model_weight\n",
    "# #model_weight: to be fit inside model.fit Keras API\n",
    "# for i in range(model_weight_tr.shape[0]):\n",
    "#     for j in range(model_weight_tr.shape[1]):\n",
    "#         model_weight_tr[i,j] = alarm_weight[(pad_X_tr_smote[i][j])]\n",
    "        \n",
    "#FOR TRAINING WITHOUT SMOTE \n",
    "model_weight_tr = np.zeros((pad_X_tr.shape[0],pad_X_tr.shape[1])) #initialize model_weight\n",
    "#model_weight: to be fit inside model.fit Keras API\n",
    "for i in range(model_weight_tr.shape[0]):\n",
    "    for j in range(model_weight_tr.shape[1]):\n",
    "        model_weight_tr[i,j] = alarm_weight[(pad_X_tr[i][j])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7bafc838",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR TEST (TEST = NO SMOTE)\n",
    "model_weight_ts = np.zeros((pad_X_ts.shape[0],pad_X_ts.shape[1])) #initialize model_weight\n",
    "#model_weight: to be fit inside model.fit Keras API\n",
    "for i in range(model_weight_ts.shape[0]):\n",
    "    for j in range(model_weight_ts.shape[1]):\n",
    "        model_weight_ts[i,j] = alarm_weight[(pad_X_ts[i][j])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "22897e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10.43246   , 10.43246   , 10.43246   , ...,  2.67498974,\n",
       "         2.67498974,  2.67498974],\n",
       "       [10.43246   , 10.43246   , 11.59162222, ..., 10.43246   ,\n",
       "         3.26014375,  2.67498974],\n",
       "       [10.43246   ,  2.67498974, 11.59162222, ..., 10.43246   ,\n",
       "         3.26014375,  3.26014375],\n",
       "       ...,\n",
       "       [11.59162222,  2.67498974,  2.67498974, ..., 11.59162222,\n",
       "         2.608115  , 11.59162222],\n",
       "       [ 2.67498974,  2.608115  ,  2.67498974, ...,  3.26014375,\n",
       "         2.608115  ,  3.26014375],\n",
       "       [ 2.67498974, 10.43246   , 11.59162222, ...,  3.26014375,\n",
       "         3.26014375,  3.26014375]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_weight_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "423bbdd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ..., 10.43246   ,\n",
       "         3.26014375,  3.26014375],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  3.26014375,\n",
       "         3.26014375,  3.26014375],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  3.26014375,\n",
       "         2.67498974,  3.26014375],\n",
       "       ...,\n",
       "       [ 2.67498974, 10.43246   , 10.43246   , ...,  2.67498974,\n",
       "         2.67498974,  2.67498974],\n",
       "       [10.43246   , 10.43246   , 10.43246   , ...,  2.67498974,\n",
       "         2.67498974,  9.48405455],\n",
       "       [10.43246   , 10.43246   , 10.43246   , ...,  2.67498974,\n",
       "         9.48405455,  3.26014375]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_weight_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f8a7ff29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardizing the data -> Try after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5c5f3ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad_X_tr_smote.shape == model_weight.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d1517b",
   "metadata": {},
   "source": [
    "Trying Sample Weight with dimension (number of records,1) instead of 2D array. For 2D array sample weight, perhaps need to change the dataset to temporal data type, or change the loss function? Cos otherwise it will throw dimension error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b169aad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weight_1D_tr = np.array([model_weight_tr[i].sum()/(model_weight_tr.shape[1]*30) for i in range(model_weight_tr.shape[0])])\n",
    "model_weight_1D_ts = np.array([model_weight_ts[i].sum()/(model_weight_ts.shape[1]*30) for i in range(model_weight_ts.shape[0])])\n",
    "                                                                                            \n",
    "#model_weight[i].sum()/model_weight.shape[1] = taking the average of ALL the weights in the i-th row of model_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "079ab647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5046,)\n",
      "(10092,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(model_weight_1D_ts))\n",
    "print(np.shape(model_weight_1D_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "88b91e00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 9491, 1: 601})"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ef692e",
   "metadata": {},
   "source": [
    "#### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dc593eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardizing the training data & test data separately \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "pad_X_tr_smote_scl = scaler.fit_transform(pad_X_tr_smote)\n",
    "pad_X_ts_scl = scaler.transform(pad_X_ts) #For test dataset ONLY TRANSFORM (do not fit the scaler), so the range is not changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ca5f183a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ensuring scaling result for train / test is the same\n",
    "pad_X_tr_smote[1][44]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c5f75dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_X_ts[1][8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "04e91928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.830188679245283"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_X_tr_smote_scl[1][44]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fb103138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.830188679245283"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_X_ts_scl[1][8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ba404a16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True, False, False,  True,\n",
       "       False, False,  True, False,  True, False, False, False, False,\n",
       "       False, False, False,  True, False, False, False,  True,  True,\n",
       "        True,  True,  True,  True, False, False,  True, False, False,\n",
       "        True, False, False,  True,  True, False,  True,  True,  True,\n",
       "        True, False, False,  True,  True, False, False, False, False,\n",
       "       False,  True, False,  True, False, False, False, False, False,\n",
       "       False, False, False])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_X_ts_scl[1]==pad_X_ts_scl[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6376562e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2162"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = pd.DataFrame(pad_X_tr_smote)\n",
    "d.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4b4ffc86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[31, 31, 31, ..., 32, 32, 32],\n",
       "       [31, 31, 30, ..., 18, 39, 32],\n",
       "       [31, 32, 30, ..., 41, 40, 40],\n",
       "       ...,\n",
       "       [30, 32, 32, ..., 30, 24, 30],\n",
       "       [32, 24, 32, ..., 37, 24, 37],\n",
       "       [32, 18, 25, ..., 40, 40, 40]], dtype=int32)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_X_ts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35dd1f76",
   "metadata": {},
   "source": [
    "#### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "98d76ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_length = pad_X_tr_smote.shape[1]\n",
    "#input_length = 5 #for last_5 alarms data\n",
    "input_length = pad_X_tr.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3bf9cfce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10092"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f032ed2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ..., 10.43246   ,\n",
       "         3.26014375,  3.26014375],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  3.26014375,\n",
       "         3.26014375,  3.26014375],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  3.26014375,\n",
       "         2.67498974,  3.26014375],\n",
       "       ...,\n",
       "       [ 2.67498974, 10.43246   , 10.43246   , ...,  2.67498974,\n",
       "         2.67498974,  2.67498974],\n",
       "       [10.43246   , 10.43246   , 10.43246   , ...,  2.67498974,\n",
       "         2.67498974,  9.48405455],\n",
       "       [10.43246   , 10.43246   , 10.43246   , ...,  2.67498974,\n",
       "         9.48405455,  3.26014375]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_weight_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4a6e2e1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5046,)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(y_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b63c4579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       1\n",
       "2       1\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "5041    0\n",
       "5042    0\n",
       "5043    0\n",
       "5044    0\n",
       "5045    0\n",
       "Name: y_ts, Length: 5046, dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9aa1d7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ts_tensor = tf.data.Dataset.from_tensor_slices((np.array(y_ts)).reshape((y_ts.shape[0],1)))\n",
    "y_tr_tensor = tf.data.Dataset.from_tensor_slices((np.array(y_tr)).reshape((y_tr.shape[0],1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9b72ad25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.1517004533230518, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1237886404806613, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "for element in weight_tr_tensor.take(2): \n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "3f2ca1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0  0  0  0  0  0 32 32 10 32 32 32 32 32 32 32 32 11 32 32 32 32\n",
      " 30 32 10 32 10 32 41 40 40  9 10 24 33 10  9 10 39 10 32 32 32 32 10 32\n",
      " 32 10 32 32 30 30 31 30 30 30 30 30 30 30 30 31 10 10]  =>  [0] -> [0.15170045]\n",
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 32\n",
      " 10 32 10 32 41 40 40  9 10 24 33 10  9 10 39 10 32 32 32 32 10 32 32 10\n",
      " 32 32 30 30 31 30 30 30 30 30 30 30 30 31 10 10 10 10]  =>  [0] -> [0.12378864]\n",
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  9 10 24 33 10  9 10 39 10 32 32 32 32 10 32 32 10 32 32\n",
      " 30 30 31 30 30 30 30 30 30 30 30 31 10 10 10 10 32 10]  =>  [0] -> [0.1108781]\n",
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0 10  9 10 39 10 32 32 32 32 10 32 32 10 32 32 30 30 31 30\n",
      " 30 30 30 30 30 30 30 31 10 10 10 10 32 10 10 10 20 20]  =>  [0] -> [0.11482979]\n",
      "[ 0 10 39 10 32 32 32 32 10 32 32 10 32 32 30 30 31 30 30 30 30 30 30 30\n",
      " 30 31 10 10 10 10 32 10 10 10 20 20 39 39 39 31 32 32 32 32 32 32 32 32\n",
      " 32 32 32 32 32 32 32 32 32 32 32 32 36 32 32 32 32 32]  =>  [0] -> [0.15716691]\n"
     ]
    }
   ],
   "source": [
    "for features, label, weight in tr_tensor.take(5):\n",
    "    print(features.numpy(), \" => \", label.numpy(), \"->\", weight.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "89859fc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15170045],\n",
       "       [0.12378864],\n",
       "       [0.1108781 ],\n",
       "       ...,\n",
       "       [0.23651874],\n",
       "       [0.23995766],\n",
       "       [0.23633528]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_weight_1D_tr\n",
    "(np.array(model_weight_1D_tr)).reshape((model_weight_1D_tr.shape[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "2277977b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_X_ts_tensor = tf.data.Dataset.from_tensor_slices(pad_X_ts)\n",
    "pad_X_tr_tensor = tf.data.Dataset.from_tensor_slices(pad_X_tr)\n",
    "\n",
    "weight_tr_tensor = tf.data.Dataset.from_tensor_slices((np.array(model_weight_1D_tr)).reshape((model_weight_1D_tr.shape[0],1)))\n",
    "weight_ts_tensor = tf.data.Dataset.from_tensor_slices((np.array(model_weight_1D_ts)).reshape((model_weight_1D_ts.shape[0],1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "2c06e05c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15170045],\n",
       "       [0.12378864],\n",
       "       [0.1108781 ],\n",
       "       ...,\n",
       "       [0.23651874],\n",
       "       [0.23995766],\n",
       "       [0.23633528]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array(model_weight_1D_tr)).reshape((model_weight_1D_tr.shape[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ee7313dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_tensor = tf.data.Dataset.zip((pad_X_tr_tensor, y_tr_tensor, weight_tr_tensor))\n",
    "ts_tensor = tf.data.Dataset.zip((pad_X_ts_tensor, y_ts_tensor, weight_ts_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "683eefe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.ZipDataset"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tr_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f328f879",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [i for i in range(100)]\n",
    "s = tf.keras.preprocessing.timeseries_dataset_from_array(l,targets=None,sequence_length=10, sampling_rate=2, sequence_stride=3, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5cee3490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0  2  4  6  8 10 12 14 16 18]\n",
      " [ 3  5  7  9 11 13 15 17 19 21]\n",
      " [ 6  8 10 12 14 16 18 20 22 24]\n",
      " [ 9 11 13 15 17 19 21 23 25 27]\n",
      " [12 14 16 18 20 22 24 26 28 30]\n",
      " [15 17 19 21 23 25 27 29 31 33]\n",
      " [18 20 22 24 26 28 30 32 34 36]\n",
      " [21 23 25 27 29 31 33 35 37 39]\n",
      " [24 26 28 30 32 34 36 38 40 42]\n",
      " [27 29 31 33 35 37 39 41 43 45]\n",
      " [30 32 34 36 38 40 42 44 46 48]\n",
      " [33 35 37 39 41 43 45 47 49 51]\n",
      " [36 38 40 42 44 46 48 50 52 54]\n",
      " [39 41 43 45 47 49 51 53 55 57]\n",
      " [42 44 46 48 50 52 54 56 58 60]\n",
      " [45 47 49 51 53 55 57 59 61 63]\n",
      " [48 50 52 54 56 58 60 62 64 66]\n",
      " [51 53 55 57 59 61 63 65 67 69]\n",
      " [54 56 58 60 62 64 66 68 70 72]\n",
      " [57 59 61 63 65 67 69 71 73 75]\n",
      " [60 62 64 66 68 70 72 74 76 78]\n",
      " [63 65 67 69 71 73 75 77 79 81]\n",
      " [66 68 70 72 74 76 78 80 82 84]\n",
      " [69 71 73 75 77 79 81 83 85 87]\n",
      " [72 74 76 78 80 82 84 86 88 90]\n",
      " [75 77 79 81 83 85 87 89 91 93]\n",
      " [78 80 82 84 86 88 90 92 94 96]], shape=(27, 10), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for element in s: \n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "3657a7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_14 (Embedding)     (None, 10092, 200)        20000     \n",
      "_________________________________________________________________\n",
      "lstm_45 (LSTM)               (None, 10092, 64)         67840     \n",
      "_________________________________________________________________\n",
      "lstm_46 (LSTM)               (None, 10092, 32)         12416     \n",
      "_________________________________________________________________\n",
      "lstm_47 (LSTM)               (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 110,753\n",
      "Trainable params: 110,753\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 10092) for input KerasTensor(type_spec=TensorSpec(shape=(None, 10092), dtype=tf.float32, name='embedding_14_input'), name='embedding_14_input', description=\"created by layer 'embedding_14_input'\"), but it was called on an input with incompatible shape (66, 1).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/engine/training.py:853 train_function  *\n        return step_function(self, iterator)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/engine/training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/engine/training.py:835 run_step  **\n        outputs = model.train_step(data)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/engine/training.py:789 train_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/engine/compile_utils.py:201 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/losses.py:141 __call__\n        losses = call_fn(y_true, y_pred)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/losses.py:245 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/losses.py:1809 binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/backend.py:5000 binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:246 sigmoid_cross_entropy_with_logits_v2\n        logits=logits, labels=labels, name=name)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:133 sigmoid_cross_entropy_with_logits\n        (logits.get_shape(), labels.get_shape()))\n\n    ValueError: logits and labels must have the same shape ((66, 1) vs (1, 1))\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-138-e1fdd6f257eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m#                 validation_data=(X_val_seq, y_val_seq),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    759\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 760\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3065\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3066\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3067\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3463\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3306\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3307\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3308\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3309\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3310\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    992\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/engine/training.py:853 train_function  *\n        return step_function(self, iterator)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/engine/training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/engine/training.py:835 run_step  **\n        outputs = model.train_step(data)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/engine/training.py:789 train_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/engine/compile_utils.py:201 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/losses.py:141 __call__\n        losses = call_fn(y_true, y_pred)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/losses.py:245 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/losses.py:1809 binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/backend.py:5000 binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:246 sigmoid_cross_entropy_with_logits_v2\n        logits=logits, labels=labels, name=name)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:133 sigmoid_cross_entropy_with_logits\n        (logits.get_shape(), labels.get_shape()))\n\n    ValueError: logits and labels must have the same shape ((66, 1) vs (1, 1))\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(100, 200, input_length = input_length, mask_zero=True))\n",
    "#model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "#model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(LSTM(64,return_sequences=True,dropout=0.1))\n",
    "model.add(LSTM(32,return_sequences=True,dropout=0.1))\n",
    "model.add(LSTM(32))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(64,activation='sigmoid'))\n",
    "#model.add(Dense(128))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              metrics=[tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), 'accuracy'],\n",
    "             sample_weight_mode=\"temporal\")\n",
    "#model.add(Embedding(input_dim=n_alarms, output_dim=200, input_length=mean_length, mask_zero=True))\n",
    "#model.add(LSTM(64,return_sequences=True))\n",
    "\n",
    "# ## model.add(LSTM(64,return_sequences=True))\n",
    "# ## model.add(Dropout(0.2))\n",
    "# ## model.add(Dense(64))\n",
    "# ## model.add(Embedding(input_dim = n_alarms,output_dim=100,input_length=64, mask_zero=True))\n",
    "# ## model.add(LSTM(100))\n",
    "# ## model.add(Dropout(0.2))\n",
    "# #model.add(Dense(32,input_shape=(66,)))\n",
    "# model.add(Dense(32))\n",
    "# model.add(Dense(1, activation = 'sigmoid'))\n",
    "# model.compile(loss=\"binary_crossentropy\", metrics=[tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), 'accuracy'],\n",
    "#              )\n",
    "\n",
    "model.summary()\n",
    "history = model.fit(tr_tensor, epochs=1)\n",
    "\n",
    "#                 validation_data=(X_val_seq, y_val_seq), \n",
    "#                 class_weight=class_weights_dict)\n",
    "evaluate = model.evaluate(ts_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "2a2c20fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold value is: 0.0812124\n",
      "[[2820    1]\n",
      " [ 364    0]]\n",
      "Precision:  0.0\n",
      "Recall:  0.0\n"
     ]
    }
   ],
   "source": [
    "#Prediction for last alarms \n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "y_pred_last = model.predict(X_ts_last)\n",
    "\n",
    "#Finding the correct threshold for the prediction probability \n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_ts_last, y_pred_last)\n",
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "print(\"Threshold value is:\", optimal_threshold)\n",
    "\n",
    "y_pred_classes = [1 if i>=0.19547457 else 0 for i in y_pred_last]\n",
    "\n",
    "print(confusion_matrix(y_ts_last,y_pred_classes))\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "print('Precision: ', precision_score(y_ts_last, y_pred_classes))\n",
    "print('Recall: ',recall_score(y_ts_last,y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "838e31ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "y_pred = model.predict(pad_X_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ea8b1440",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_tr = model.predict(pad_X_tr_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c3b7151d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08234662],\n",
       "       [0.10907879],\n",
       "       [0.09238783],\n",
       "       ...,\n",
       "       [0.99087316],\n",
       "       [0.99234456],\n",
       "       [0.9928473 ]], dtype=float32)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e3ec67e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.07431686],\n",
       "       [0.07096049],\n",
       "       [0.09277186],\n",
       "       ...,\n",
       "       [0.08759838],\n",
       "       [0.08759838],\n",
       "       [0.08759838]], dtype=float32)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ad1f3187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold value is: 0.19547457\n"
     ]
    }
   ],
   "source": [
    "#Finding the correct threshold for the prediction probability \n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_ts, y_pred)\n",
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "print(\"Threshold value is:\", optimal_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b4f778e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6710 3653]\n",
      " [ 562  706]]\n",
      "Precision:  0.1619637531543932\n",
      "Recall:  0.556782334384858\n"
     ]
    }
   ],
   "source": [
    "y_pred_classes = [1 if i>=0.19547457 else 0 for i in y_pred]\n",
    "\n",
    "print(confusion_matrix(y_ts,y_pred_classes))\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "print('Precision: ', precision_score(y_ts, y_pred_classes))\n",
    "print('Recall: ',recall_score(y_ts,y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d75afa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05249625],\n",
       "       [0.04950985],\n",
       "       [0.08126721],\n",
       "       ...,\n",
       "       [0.04248771],\n",
       "       [0.04248771],\n",
       "       [0.04248771]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "precision_score(y_ts, y_pred_classes)\n",
    "recall_score(y_ts,y_pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "364c29fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PRINTING EMBEDDING OUTPUT\n",
    "from keras import backend as K\n",
    "embedding_output = K.function([model.layers[0].input],\n",
    "                                  [model.layers[0].output])\n",
    "layer_output = embedding_output([pad_X_tr_smote])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cce12df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-2.3895418e-02, -1.6276203e-02,  3.1923268e-02, ...,\n",
       "         -3.8270272e-02, -4.0735424e-02, -4.2077791e-02],\n",
       "        [-2.3895418e-02, -1.6276203e-02,  3.1923268e-02, ...,\n",
       "         -3.8270272e-02, -4.0735424e-02, -4.2077791e-02],\n",
       "        [-2.3895418e-02, -1.6276203e-02,  3.1923268e-02, ...,\n",
       "         -3.8270272e-02, -4.0735424e-02, -4.2077791e-02],\n",
       "        ...,\n",
       "        [-1.1178352e-01, -2.6677804e-02,  6.2990971e-02, ...,\n",
       "          2.5753653e-01, -1.1366834e-01,  2.7692720e-01],\n",
       "        [ 6.4532846e-02, -2.9874226e-01, -2.9774123e-01, ...,\n",
       "          1.3571341e-01,  2.4962841e-01,  1.5970303e-01],\n",
       "        [ 1.4041986e-02, -3.8650730e-01, -2.1490693e-01, ...,\n",
       "          4.4231106e-02,  3.4318039e-01,  2.9738441e-01]],\n",
       "\n",
       "       [[-2.3895418e-02, -1.6276203e-02,  3.1923268e-02, ...,\n",
       "         -3.8270272e-02, -4.0735424e-02, -4.2077791e-02],\n",
       "        [-2.3895418e-02, -1.6276203e-02,  3.1923268e-02, ...,\n",
       "         -3.8270272e-02, -4.0735424e-02, -4.2077791e-02],\n",
       "        [-2.3895418e-02, -1.6276203e-02,  3.1923268e-02, ...,\n",
       "         -3.8270272e-02, -4.0735424e-02, -4.2077791e-02],\n",
       "        ...,\n",
       "        [-1.1178352e-01, -2.6677804e-02,  6.2990971e-02, ...,\n",
       "          2.5753653e-01, -1.1366834e-01,  2.7692720e-01],\n",
       "        [ 8.5773431e-02, -3.2112624e-02,  3.0357793e-01, ...,\n",
       "          4.0467900e-01, -1.1439020e-01,  1.6802052e-01],\n",
       "        [-7.3004872e-02,  1.7424430e-01, -1.6985087e-01, ...,\n",
       "          3.2275978e-02,  7.2372861e-02,  2.6399935e-02]],\n",
       "\n",
       "       [[-2.3895418e-02, -1.6276203e-02,  3.1923268e-02, ...,\n",
       "         -3.8270272e-02, -4.0735424e-02, -4.2077791e-02],\n",
       "        [-2.3895418e-02, -1.6276203e-02,  3.1923268e-02, ...,\n",
       "         -3.8270272e-02, -4.0735424e-02, -4.2077791e-02],\n",
       "        [-2.3895418e-02, -1.6276203e-02,  3.1923268e-02, ...,\n",
       "         -3.8270272e-02, -4.0735424e-02, -4.2077791e-02],\n",
       "        ...,\n",
       "        [-4.9574438e-02, -2.0511748e-01,  6.4043246e-02, ...,\n",
       "          1.6762105e-01,  1.5406668e-01,  2.8549215e-01],\n",
       "        [-4.9574438e-02, -2.0511748e-01,  6.4043246e-02, ...,\n",
       "          1.6762105e-01,  1.5406668e-01,  2.8549215e-01],\n",
       "        [-4.9574438e-02, -2.0511748e-01,  6.4043246e-02, ...,\n",
       "          1.6762105e-01,  1.5406668e-01,  2.8549215e-01]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 4.8299093e-02, -8.4198173e-03, -8.9162752e-02, ...,\n",
       "          5.2686691e-01, -5.8579579e-02, -1.3832313e-02],\n",
       "        [ 7.5120583e-02, -5.1387656e-02,  5.5360403e-02, ...,\n",
       "          4.5034744e-02, -2.0337938e-01,  1.7828722e-02],\n",
       "        [ 5.1828995e-02,  3.3648863e-01, -4.0192279e-01, ...,\n",
       "         -2.2725706e-01,  1.1002636e-01,  3.0297411e-04],\n",
       "        ...,\n",
       "        [ 2.6262328e-01, -1.6117372e-01, -2.4394194e-02, ...,\n",
       "         -2.9265936e-02,  6.6892460e-02, -3.5319552e-01],\n",
       "        [ 7.5120583e-02, -5.1387656e-02,  5.5360403e-02, ...,\n",
       "          4.5034744e-02, -2.0337938e-01,  1.7828722e-02],\n",
       "        [ 4.2557508e-02,  1.8334013e-01, -2.2483349e-02, ...,\n",
       "         -8.3098980e-03, -2.1425343e-01, -4.0070448e-02]],\n",
       "\n",
       "       [[-8.3030118e-03, -2.2401072e-02, -4.0031441e-02, ...,\n",
       "         -2.0175730e-01,  1.4223330e-01,  3.9757986e-02],\n",
       "        [-8.3030118e-03, -2.2401072e-02, -4.0031441e-02, ...,\n",
       "         -2.0175730e-01,  1.4223330e-01,  3.9757986e-02],\n",
       "        [-8.3030118e-03, -2.2401072e-02, -4.0031441e-02, ...,\n",
       "         -2.0175730e-01,  1.4223330e-01,  3.9757986e-02],\n",
       "        ...,\n",
       "        [ 7.5120583e-02, -5.1387656e-02,  5.5360403e-02, ...,\n",
       "          4.5034744e-02, -2.0337938e-01,  1.7828722e-02],\n",
       "        [ 7.5120583e-02, -5.1387656e-02,  5.5360403e-02, ...,\n",
       "          4.5034744e-02, -2.0337938e-01,  1.7828722e-02],\n",
       "        [ 7.5120583e-02, -5.1387656e-02,  5.5360403e-02, ...,\n",
       "          4.5034744e-02, -2.0337938e-01,  1.7828722e-02]],\n",
       "\n",
       "       [[-2.0658746e-01,  2.6304254e-01,  5.5931765e-01, ...,\n",
       "         -1.7406932e-01, -3.0365205e-01, -8.0686674e-04],\n",
       "        [-9.8685421e-02,  6.2500976e-02,  6.3222989e-02, ...,\n",
       "          1.2576725e-02, -2.5109714e-01, -8.5694030e-02],\n",
       "        [-2.0658746e-01,  2.6304254e-01,  5.5931765e-01, ...,\n",
       "         -1.7406932e-01, -3.0365205e-01, -8.0686674e-04],\n",
       "        ...,\n",
       "        [ 6.4532846e-02, -2.9874226e-01, -2.9774123e-01, ...,\n",
       "          1.3571341e-01,  2.4962841e-01,  1.5970303e-01],\n",
       "        [ 7.5120583e-02, -5.1387656e-02,  5.5360403e-02, ...,\n",
       "          4.5034744e-02, -2.0337938e-01,  1.7828722e-02],\n",
       "        [ 6.4532846e-02, -2.9874226e-01, -2.9774123e-01, ...,\n",
       "          1.3571341e-01,  2.4962841e-01,  1.5970303e-01]]], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778d4ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=n_alarms, output_dim=10, input_length=X_train.shape[1], mask_zero=True))\n",
    "model.add(Conv1D(64,15,strides=2,input_shape=(X_train.shape[1], 1), use_bias=False, activation='relu'))\n",
    "model.add(Conv1D(64,3))\n",
    "model.add(Conv1D(64,3,strides=2, activation=\"relu\"))\n",
    "model.add(Conv1D(64,3))\n",
    "model.add(Conv1D(64,3,strides=2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), 'accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28197e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_model(padded_alarm, n_alarms):\n",
    "#     model = Sequential()\n",
    "#     model.add(Input(shape=(padded_alarm.shape[1])))\n",
    "#     model.add(Embedding(n_alarms, 128, mask_zero=True))\n",
    "#     model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "#     model.add(Bidirectional(LSTM(10)))\n",
    "#     model.add(Dropout(0.3))\n",
    "#     model.add(Dense(10, activation='relu'))\n",
    "#     model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#     model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), 'accuracy'])\n",
    "    \n",
    "#     return model\n",
    "\n",
    "def create_model(X_train, n_alarm):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=n_alarms, output_dim=10, input_length=X_train.shape[1], mask_zero=True))\n",
    "    model.add(Conv1D(64,15,strides=2,input_shape=(X_train.shape[1], 1), use_bias=False, activation='relu'))\n",
    "    model.add(Conv1D(64,3))\n",
    "    model.add(Conv1D(64,3,strides=2, activation=\"relu\"))\n",
    "    model.add(Conv1D(64,3))\n",
    "    model.add(Conv1D(64,3,strides=2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), 'accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a6bf92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomly_select_negative(X_seq, major_down_arr, ratio):\n",
    "    bool_arr = [ele==0 for ele in major_down_arr]\n",
    "    major_arr = np.array(major_down_arr)[np.where(bool_arr)[0]]\n",
    "    print(len(major_arr), len(major_down_arr))\n",
    "    negative = X_seq[np.where(bool_arr)[0]]\n",
    "    \n",
    "    positive_bool_arr = [ele==1 for ele in major_down_arr]\n",
    "    positive_major_arr = np.array(major_down_arr)[np.where(positive_bool_arr)[0]]\n",
    "    print(len(positive_major_arr))\n",
    "    positive = X_seq[np.where(positive_bool_arr)[0]]\n",
    "    \n",
    "    discard, keep, target_discard, target_keep = train_test_split(negative, major_arr, test_size=ratio)\n",
    "    \n",
    "    handpicked = np.concatenate((positive, keep))\n",
    "    target = np.concatenate((positive_major_arr, target_keep))\n",
    "    \n",
    "    if len(handpicked) != len(target):\n",
    "        raise Exception(\"Length of training inputs are different\")\n",
    "    \n",
    "    return handpicked, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40286b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_empty_datapoint(X_seq, major_down_arr):\n",
    "    bool_arr = [len(ele)==0 for ele in X_seq] #this is to find the index to remove for bot y array and X_seq\n",
    "    idx_remove = np.where(bool_arr)[0]\n",
    "    major_down_arr = np.delete(np.array(major_down_arr), idx_remove) # remove the corresponding y value as well\n",
    "    X_seq = np.delete(X_seq, idx_remove) #remove rows with no alarms\n",
    "    return X_seq, major_down_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2aa23fb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "monitor = 'val_recall'\n",
    "\n",
    "#shuffle the X and Y values to make generalize better\n",
    "shuffled = shuffle(encoded_X_seq, target)\n",
    "encoded_X_seq = shuffled[0]\n",
    "target = shuffled[1]\n",
    "\n",
    "# padding to average length\n",
    "mean_length = int(np.mean([len(x) for x in encoded_X_seq]))\n",
    "padded_alarm = np.zeros([len(encoded_X_seq), mean_length])\n",
    "for i,j in enumerate(encoded_X_seq):\n",
    "    padded_alarm[i][0:len(j)] = j[:mean_length]\n",
    "\n",
    "#train_val_test split\n",
    "X_train_seq, X_val_seq, y_train_seq, y_val_seq =  train_test_split(padded_alarm, target, test_size=0.4, random_state=42, stratify=target)\n",
    "X_val_seq, X_test_seq, y_val_seq, y_test_seq =  train_test_split(X_val_seq, y_val_seq, test_size=0.4, random_state=42, stratify=y_val_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5c2795b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/engine/training.py:853 train_function  *\n        return step_function(self, iterator)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/engine/training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/engine/training.py:835 run_step  **\n        outputs = model.train_step(data)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/engine/training.py:792 train_step\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/engine/compile_utils.py:457 update_state\n        metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/utils/metrics_utils.py:73 decorated\n        update_op = update_state_fn(*args, **kwargs)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/metrics.py:177 update_state_fn\n        return ag_update_state(*args, **kwargs)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/metrics.py:1366 update_state  **\n        sample_weight=sample_weight)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/utils/metrics_utils.py:623 update_confusion_matrix_variables\n        y_pred.shape.assert_is_compatible_with(y_true.shape)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/tensorflow/python/framework/tensor_shape.py:1161 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 2) and (None, 1) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-6a6910432b37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m                 \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                 callbacks=callbacks)\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mevaluate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_seq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#loss, mse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    759\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 760\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3065\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3066\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3067\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3463\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3306\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3307\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3308\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3309\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3310\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    992\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/engine/training.py:853 train_function  *\n        return step_function(self, iterator)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/engine/training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/engine/training.py:835 run_step  **\n        outputs = model.train_step(data)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/engine/training.py:792 train_step\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/engine/compile_utils.py:457 update_state\n        metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/utils/metrics_utils.py:73 decorated\n        update_op = update_state_fn(*args, **kwargs)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/metrics.py:177 update_state_fn\n        return ag_update_state(*args, **kwargs)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/metrics.py:1366 update_state  **\n        sample_weight=sample_weight)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/utils/metrics_utils.py:623 update_confusion_matrix_variables\n        y_pred.shape.assert_is_compatible_with(y_true.shape)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/tensorflow/python/framework/tensor_shape.py:1161 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 2) and (None, 1) are incompatible\n"
     ]
    }
   ],
   "source": [
    "model = create_model(padded_alarm, n_alarms)\n",
    "\n",
    "# model seems to be overfitting, try to reduce overfitting by reduce LR, but model should take longer to converge so use a larger EPOCH\n",
    "callbacks = [ReduceLROnPlateau(monitor=monitor, factor=0.2, patience=5, min_lr=0.001), \\\n",
    "            EarlyStopping(monitor=monitor, patience=30, mode=mode, restore_best_weights=True)]\n",
    "\n",
    "history = model.fit(X_train_seq, y_train_seq, \n",
    "                batch_size=BATCH_SIZE, epochs=EPOCHS, \n",
    "                validation_data=(X_val_seq, y_val_seq), \n",
    "                callbacks=callbacks)\n",
    "\n",
    "evaluate = model.evaluate(X_test_seq, y_test_seq) #loss, mse\n",
    "\n",
    "pred = model.predict(X_test_seq)\n",
    "classes = []\n",
    "for ele in pred:\n",
    "    classes.append(int((ele>0.5)[0]))\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test_seq, classes)\n",
    "\n",
    "seq_result[hour] = [evaluate, cm]\n",
    "\n",
    "end = datetime.now()\n",
    "time = end - start\n",
    "print(f\"Training took {time.seconds} seconds to complete.\")\n",
    "seq_result[hour, mean_length] = evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a754f11",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer conv1d is incompatible with the layer: : expected min_ndim=3, found ndim=2. Full shape received: (53, 128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-29d238c3cc80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_embed_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_test_seq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0malarms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m44\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m45\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/backend.py\u001b[0m in \u001b[0;36mfunc\u001b[0;34m(model_inputs)\u001b[0m\n\u001b[1;32m   4076\u001b[0m     \u001b[0mwrap_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4077\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4078\u001b[0;31m       \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4079\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mwrap_outputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4080\u001b[0m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    413\u001b[0m     \"\"\"\n\u001b[1;32m    414\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m--> 415\u001b[0;31m         inputs, training=training, mask=mask)\n\u001b[0m\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1018\u001b[0m         training=training_mode):\n\u001b[1;32m   1019\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m       \u001b[0minput_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1021\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0meager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \u001b[0mcall_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    232\u001b[0m                          \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                          \u001b[0;34m'. Full shape received: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                          str(tuple(shape)))\n\u001b[0m\u001b[1;32m    235\u001b[0m     \u001b[0;31m# Check dtype.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer conv1d is incompatible with the layer: : expected min_ndim=3, found ndim=2. Full shape received: (53, 128)"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# with a Sequential model\n",
    "get_embed_out = keras.backend.function(\n",
    "    model.layers[0].input,\n",
    "    model.layers[1].output)\n",
    "\n",
    "\n",
    "layer_output = get_embed_out([X_test_seq[0]])\n",
    "\n",
    "alarms = [44, 45 ,90, 150]\n",
    "emb_alarms = tf.constant([mapping_dict[alarm] for alarm in alarms])\n",
    "\n",
    "words = get_embed_out([enc_review])[0]\n",
    "\n",
    "plt.scatter(words[:,0], words[:,1])\n",
    "for i, txt in enumerate(alarms):\n",
    "    plt.annotate(txt, (words[i,0], words[i,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e0fb32f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<KerasTensor: shape=(None, 53) dtype=float32 (created by layer 'embedding_1_input')>,\n",
       " <KerasTensor: shape=(None, 20, 64) dtype=float32 (created by layer 'conv1d_5')>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].input, model.layers[1].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b81ef0d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer conv1d is incompatible with the layer: : expected min_ndim=3, found ndim=2. Full shape received: (53, 128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-a6964863743b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_embed_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_test_seq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/backend.py\u001b[0m in \u001b[0;36mfunc\u001b[0;34m(model_inputs)\u001b[0m\n\u001b[1;32m   4076\u001b[0m     \u001b[0mwrap_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4077\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4078\u001b[0;31m       \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4079\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mwrap_outputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4080\u001b[0m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    413\u001b[0m     \"\"\"\n\u001b[1;32m    414\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m--> 415\u001b[0;31m         inputs, training=training, mask=mask)\n\u001b[0m\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1018\u001b[0m         training=training_mode):\n\u001b[1;32m   1019\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m       \u001b[0minput_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1021\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0meager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \u001b[0mcall_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    232\u001b[0m                          \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                          \u001b[0;34m'. Full shape received: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                          str(tuple(shape)))\n\u001b[0m\u001b[1;32m    235\u001b[0m     \u001b[0;31m# Check dtype.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer conv1d is incompatible with the layer: : expected min_ndim=3, found ndim=2. Full shape received: (53, 128)"
     ]
    }
   ],
   "source": [
    "layer_output = get_embed_out([X_test_seq[0]])\n",
    "print(type(layer_output), len(layer_output), layer_output[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49dce51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_wba124_X_seq, n_alarm_wba124, mapping_dict_wba124 = label_encode(wba124.X_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5564ab0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "feature = pad_sequences(enc_wba124_X_seq, maxlen=n_alarm_wba124, value=0, \n",
    "                         truncating='pre', padding='pre') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dd126c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.5609915198956295, 1: 4.598930481283422}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(feature, wba124.major_down_arr, test_size=0.4)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.4)\n",
    "\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(y_train),\n",
    "                                                 y_train)\n",
    "weights ={}\n",
    "for idx, val in enumerate(class_weights):\n",
    "    weights[idx] = val\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5199fb5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "162/162 [==============================] - 6s 22ms/step - loss: 0.6785 - accuracy: 0.5545 - val_loss: 0.6619 - val_accuracy: 0.4423\n",
      "Epoch 2/10\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.6614 - accuracy: 0.4715 - val_loss: 0.6575 - val_accuracy: 0.4583\n",
      "Epoch 3/10\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.6477 - accuracy: 0.4713 - val_loss: 0.7895 - val_accuracy: 0.3711\n",
      "Epoch 4/10\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.6436 - accuracy: 0.4638 - val_loss: 0.6128 - val_accuracy: 0.4893\n",
      "Epoch 5/10\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.6346 - accuracy: 0.5116 - val_loss: 0.6018 - val_accuracy: 0.5058\n",
      "Epoch 6/10\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.6254 - accuracy: 0.4913 - val_loss: 0.7448 - val_accuracy: 0.3910\n",
      "Epoch 7/10\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.6182 - accuracy: 0.4818 - val_loss: 0.6637 - val_accuracy: 0.4535\n",
      "Epoch 8/10\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.6080 - accuracy: 0.5444 - val_loss: 0.6437 - val_accuracy: 0.4651\n",
      "Epoch 9/10\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.6047 - accuracy: 0.5932 - val_loss: 0.6631 - val_accuracy: 0.4453\n",
      "Epoch 10/10\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5899 - accuracy: 0.5547 - val_loss: 0.6133 - val_accuracy: 0.4937\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(n_alarm_wba124, 128, input_length=feature.shape[1], mask_zero=True))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_accuracy', mode='max', patience=5)]\n",
    "\n",
    "model.fit(np.array(X_train), np.array(y_train), \n",
    "          epochs=10, \n",
    "          batch_size=BATCH_SIZE,\n",
    "          verbose = 1,\n",
    "          class_weight=weights,\n",
    "          callbacks=callbacks,\n",
    "          validation_data=(X_val, np.array(y_val)))\n",
    "\n",
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1e427919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_14 (Embedding)     (None, 48, 128)           6144      \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 48, 32)            12320     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 24, 32)            0         \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 71,765\n",
      "Trainable params: 71,765\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bfd2bf71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[552 696]\n",
      " [ 35  94]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 0.4691358024691358)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = []\n",
    "for ele in pred:\n",
    "    classes.append(int((ele>0.5)[0]))\n",
    "\n",
    "print(confusion_matrix(np.array(y_test), classes)), accuracy_score(np.array(y_test), classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c9ffd6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=1.000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[553, 695],\n",
       "        [ 37,  92]]),\n",
       " 0.4684095860566449)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "def to_labels(y_scores, threshold):\n",
    "    return (y_scores >= threshold).astype('int')\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(np.array(y_test), classes)\n",
    "J = tpr - fpr\n",
    "ix = np.argmax(J)\n",
    "best_thresh = thresholds[ix]\n",
    "print('Best Threshold=%f' % (best_thresh))\n",
    "\n",
    "testest = to_labels(classes, best_thresh) # best thresh optimizes recall\n",
    "confusion_matrix(np.array(y_test), testest), accuracy_score(np.array(y_test), testest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ee5246a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer conv1d_18 is incompatible with the layer: : expected min_ndim=3, found ndim=2. Full shape received: (4, 128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-1b1a8c2a2a1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0memb_alarms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmapping_dict_wba124\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0malarm\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0malarm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0malarms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_embed_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0memb_alarms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/backend.py\u001b[0m in \u001b[0;36mfunc\u001b[0;34m(model_inputs)\u001b[0m\n\u001b[1;32m   4076\u001b[0m     \u001b[0mwrap_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4077\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4078\u001b[0;31m       \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4079\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mwrap_outputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4080\u001b[0m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    413\u001b[0m     \"\"\"\n\u001b[1;32m    414\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m--> 415\u001b[0;31m         inputs, training=training, mask=mask)\n\u001b[0m\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1018\u001b[0m         training=training_mode):\n\u001b[1;32m   1019\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m       \u001b[0minput_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1021\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0meager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \u001b[0mcall_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    232\u001b[0m                          \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                          \u001b[0;34m'. Full shape received: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                          str(tuple(shape)))\n\u001b[0m\u001b[1;32m    235\u001b[0m     \u001b[0;31m# Check dtype.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer conv1d_18 is incompatible with the layer: : expected min_ndim=3, found ndim=2. Full shape received: (4, 128)"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# with a Sequential model\n",
    "get_embed_out = keras.backend.function(\n",
    "    [model.layers[0].input],\n",
    "    [model.layers[1].output])\n",
    "\n",
    "layer_output = get_embed_out([X_test[0].reshape(-1, X_test[0].shape[0])])\n",
    "\n",
    "alarms = [44, 45 ,90, 150]\n",
    "emb_alarms = tf.constant([mapping_dict_wba124[alarm] for alarm in alarms])\n",
    "\n",
    "words = get_embed_out([emb_alarms])[0]\n",
    "\n",
    "plt.scatter(words[:,0], words[:,1])\n",
    "for i, txt in enumerate(alarms):\n",
    "    plt.annotate(txt, (words[i,0], words[i,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "308e683d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([28, 29, 42, 17], dtype=int32)>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_alarms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8fcf1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920dde0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_result # Embedding + Conv1D + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "701dbb0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{12: [[0.6287420988082886,\n",
       "   0.5336463451385498,\n",
       "   0.4633152186870575,\n",
       "   0.6475076079368591],\n",
       "  array([[932, 298],\n",
       "         [395, 341]])],\n",
       " (12, 30): [0.6287420988082886,\n",
       "  0.5336463451385498,\n",
       "  0.4633152186870575,\n",
       "  0.6475076079368591],\n",
       " 24: [[0.6324173808097839,\n",
       "   0.5170998573303223,\n",
       "   0.5142857432365417,\n",
       "   0.6386768221855164],\n",
       "  array([[877, 353],\n",
       "         [357, 378]])],\n",
       " (24, 58): [0.6324173808097839,\n",
       "  0.5170998573303223,\n",
       "  0.5142857432365417,\n",
       "  0.6386768221855164],\n",
       " 48: [[0.6813942790031433,\n",
       "   0.4801097512245178,\n",
       "   0.47683924436569214,\n",
       "   0.6113092303276062],\n",
       "  array([[850, 379],\n",
       "         [384, 350]])],\n",
       " (48, 115): [0.6813942790031433,\n",
       "  0.4801097512245178,\n",
       "  0.47683924436569214,\n",
       "  0.6113092303276062],\n",
       " 72: [[0.8038536310195923,\n",
       "   0.42728298902511597,\n",
       "   0.5156462788581848,\n",
       "   0.5596330165863037],\n",
       "  array([[719, 508],\n",
       "         [356, 379]])],\n",
       " (72, 169): [0.8038536310195923,\n",
       "  0.42728298902511597,\n",
       "  0.5156462788581848,\n",
       "  0.5596330165863037]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_result # stack Conv1D above LSTM (without removing noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cd13298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{12: [[0.6843389272689819,\n",
       "   0.4783889949321747,\n",
       "   0.7767145037651062,\n",
       "   0.5706973671913147],\n",
       "  array([[405, 531],\n",
       "         [140, 487]])],\n",
       " (12, 38): [0.6843389272689819,\n",
       "  0.4783889949321747,\n",
       "  0.7767145037651062,\n",
       "  0.5706973671913147],\n",
       " 24: [[0.6756141185760498,\n",
       "   0.4753146171569824,\n",
       "   0.7695924639701843,\n",
       "   0.5767813324928284],\n",
       "  array([[448, 542],\n",
       "         [147, 491]])],\n",
       " (24, 71): [0.6756141185760498,\n",
       "  0.4753146171569824,\n",
       "  0.7695924639701843,\n",
       "  0.5767813324928284],\n",
       " 48: [[0.686356782913208,\n",
       "   0.4554730951786041,\n",
       "   0.7577160596847534,\n",
       "   0.5595026612281799],\n",
       "  array([[454, 587],\n",
       "         [157, 491]])],\n",
       " (48, 133): [0.686356782913208,\n",
       "  0.4554730951786041,\n",
       "  0.7577160596847534,\n",
       "  0.5595026612281799],\n",
       " 72: [[0.6810200810432434,\n",
       "   0.4411483108997345,\n",
       "   0.7048929929733276,\n",
       "   0.5485183000564575],\n",
       "  array([[483, 584],\n",
       "         [193, 461]])],\n",
       " (72, 193): [0.6810200810432434,\n",
       "  0.4411483108997345,\n",
       "  0.7048929929733276,\n",
       "  0.5485183000564575]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_result # downsample negative data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1b9a45c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(12, 34): [0.7047469019889832,\n",
       "  0.1626969575881958,\n",
       "  0.7081339955329895,\n",
       "  0.534690797328949],\n",
       " (24, 66): [0.7164930105209351,\n",
       "  0.15516085922718048,\n",
       "  0.7257053256034851,\n",
       "  0.517192006111145],\n",
       " (48, 126): [0.6946452856063843,\n",
       "  0.14175792038440704,\n",
       "  0.7391975522041321,\n",
       "  0.4753846228122711]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_result # monitor val recall\n",
    "# {72: [0.7307, 0.1300, 0.8012, 0.3925]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c67a3624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(24, 34): [0.5954988598823547,\n",
       "  0.1780264526605606,\n",
       "  0.5582137107849121,\n",
       "  0.6430995464324951],\n",
       " (12, 34): [0.6063371300697327,\n",
       "  0.17000912129878998,\n",
       "  0.5948963165283203,\n",
       "  0.6087858080863953],\n",
       " (24, 66): [0.6042451858520508,\n",
       "  0.1820913404226303,\n",
       "  0.47492164373397827,\n",
       "  0.6962750554084778],\n",
       " (48, 126): [0.5850675106048584,\n",
       "  0.1593644618988037,\n",
       "  0.5108024477958679,\n",
       "  0.6473504304885864],\n",
       " (72, 185): [0.5972234010696411,\n",
       "  0.1689220666885376,\n",
       "  0.5535168051719666,\n",
       "  0.6538076400756836]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_result # train on 5 machines same EQ family with shuffle and masking and empty datapoints removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8529d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_result # everything on top but trained on a bidirectional LSTM layer\n",
    "# {12: [1.4355, 0.2238, 0.2041, 0.8222]}\n",
    "# {24: [1.0140, 0.2651, 0.2962, 0.8258]}\n",
    "# {48: [0.9016, 0.2873, 0.3210, 0.8366]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c179781",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d11b162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef04aea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENV-MAL-VE",
   "language": "python",
   "name": "env-mal-ve_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
