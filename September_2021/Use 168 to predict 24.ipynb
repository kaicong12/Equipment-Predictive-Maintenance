{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef385019",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight, shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 300\n",
    "\n",
    "from datetime import datetime, timedelta, date\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cx_Oracle\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "import joblib\n",
    "import shap\n",
    "\n",
    "class Aggregate_helper:\n",
    "    def __init__(self, eq_id, lookback_window, major_down_hour, alarm_table):\n",
    "        self.eq_id = eq_id\n",
    "        self.lookback_window = lookback_window\n",
    "        self.alarm_table = alarm_table\n",
    "        self.status_table = self.query_status()\n",
    "        self.major_down_hour = major_down_hour\n",
    "        \n",
    "        ## include all status instead since further preprocessing would be performed\n",
    "        ## make sure that the timeframe table is a subset of both the alarm and status table to compute major down correctly\n",
    "        time1 = self.alarm_table.iloc[0][\"DT_SET\"]\n",
    "        time2 = self.status_table.iloc[0][\"TIMESTAMP_START\"]\n",
    "        timeend1 = self.alarm_table.iloc[len(self.alarm_table)-1][\"DT_SET\"]\n",
    "        timeend2 = self.status_table.iloc[len(self.status_table)-1][\"TIMESTAMP_START\"]\n",
    "        \n",
    "        # give a 3 days window to ensure that the alarm and status are captured fully\n",
    "        start = (max(time1, time2) + timedelta(days=3)).strftime(\"%d/%m/%Y\") \n",
    "        end = min(timeend1, timeend2).strftime(\"%d/%m/%Y\")\n",
    "        \n",
    "        self.timeframe_table = self.generate_time(start, end, 3)\n",
    "        self.major_down_arr = self.major_down(self.timeframe_table, self.status_table, self.major_down_hour, 3600)\n",
    "        self.aggregated = self.aggregate(self.timeframe_table, self.lookback_window, self.alarm_table, self.status_table)\n",
    "        self.aggregated_table = pd.concat([self.timeframe_table.reset_index(drop=True), self.aggregated.reset_index(drop=True)], axis=1)\n",
    "        \n",
    "    def generate_time(self, start_date:str, end_date:str, hour:int):\n",
    "        start = datetime.strptime(start_date, '%d/%m/%Y')\n",
    "        end = datetime.strptime(end_date, '%d/%m/%Y')\n",
    "\n",
    "        dates = []\n",
    "        while start<=end:\n",
    "            row = [start]\n",
    "            dates.append(row)\n",
    "            start += timedelta(hours=hour)\n",
    "\n",
    "        return pd.DataFrame(dates, columns=['TIMESTAMP'])\n",
    "    \n",
    "    def query_status(self):\n",
    "        try:\n",
    "            oracle_string = \"oracle+cx_oracle://{username}:{password}@{hostname}:{port}/{database}\"\n",
    "            engine = create_engine(\n",
    "                oracle_string.format(\n",
    "                    username = 'TFM4CEBERUS',\n",
    "                    password = 'TFM4CEBERUS',\n",
    "                    hostname = 'ome-db.bth.infineon.com',\n",
    "                    port = '1538',\n",
    "                    database = 'ome'\n",
    "                    )\n",
    "                )\n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "\n",
    "        query = f\"\"\"select EQ_ID, TIMESTAMP_START, TIMESTAMP_END, DURATION, STATE_NAME, LEVEL3_NAME, LEVEL3 \n",
    "                from (SELECT\n",
    "                  eq.eq_id, eq.name, eq.eq_type_ident\n",
    "                , data.timestamp_start,data.timestamp_end\n",
    "                , ROUND((data.timestamp_end - data.timestamp_start)*24*60*60,0) AS Duration\n",
    "                , data.tr25_3_status,data.tr25_4_status,data.tr25_5_status,data.eq_status\n",
    "                , level5s.state_name\n",
    "                , level5.state_name Level5_Name, level5.state_sign Level5\n",
    "                , level4.state_name Level4_Name, level4.state_sign Level4\n",
    "                , level3.state_name Level3_Name, level3.state_sign Level3\n",
    "                ,mh.device\n",
    "                ,mh.package,\n",
    "                mh.lotid as lot,\n",
    "                mh.product,\n",
    "                mh.operation\n",
    "\n",
    "                FROM OMEDATA.EQUIPMENT_STATE_HISTORY data\n",
    "                , OMEADMIN.EQUIPMENT_INSTANCES eq\n",
    "                , V_EQ_STATES level5s\n",
    "                , OMEADMIN.DEF_STANDARD_STATEMODEL level5\n",
    "                , OMEADMIN.DEF_STANDARD_STATEMODEL level4\n",
    "                , OMEADMIN.DEF_STANDARD_STATEMODEL level3\n",
    "                , OMEDATA.METAKEY_HISTORY mh\n",
    "\n",
    "                WHERE data.eq_ident  = eq.eq_ident\n",
    "                AND  data.eq_status = level5s.state_ident(+)\n",
    "                AND level5.state_ident = data.tr25_5_status\n",
    "                AND level4.state_ident = data.tr25_4_status\n",
    "                AND level3.state_ident = data.tr25_3_status\n",
    "                AND  data.metakey_ident =mh.ident(+)\n",
    "                and data.timestamp_start > sysdate - 1050)\n",
    "                where eq_id = '{self.eq_id}'\n",
    "                ORDER BY TIMESTAMP_START\"\"\"\n",
    "\n",
    "        status = pd.read_sql(query, engine)\n",
    "        status.columns = map(lambda x: str(x).upper(), status.columns) \n",
    "\n",
    "        return status\n",
    "    \n",
    "    def aggregate(self, timeframe_table, lookback_window, alarm_table, status_table):\n",
    "        alarm_df = pd.DataFrame()\n",
    "        statename_df = pd.DataFrame()\n",
    "\n",
    "        for idx, row in timeframe_table.iterrows():\n",
    "            end = row[\"TIMESTAMP\"]\n",
    "            start = end - timedelta(hours=lookback_window)\n",
    "\n",
    "            ## count the frequencies of each alarm\n",
    "            filtered_alarm = alarm_table.loc[(alarm_table[\"DT_SET\"] >= start) & (alarm_table[\"DT_SET\"] <= end)]\n",
    "            alarm_freq_table = filtered_alarm[\"Alarm ID\"].value_counts().to_frame().T.reset_index(drop=True)\n",
    "            alarm_df = pd.concat([alarm_df, alarm_freq_table], axis=0)\n",
    "\n",
    "            ## count the frequencies of each statename, include everything since feature engineering would be performed\n",
    "            filtered_statename = status_table.loc[(status_table[\"TIMESTAMP_START\"] >= start) & (status_table[\"TIMESTAMP_START\"] <= end)]\n",
    "            status_freq_table = filtered_statename[\"STATE_NAME\"].value_counts().to_frame().T.reset_index(drop=True)\n",
    "            statename_df = pd.concat([statename_df, status_freq_table], axis=0)\n",
    "        \n",
    "        df = pd.concat([alarm_df, statename_df], axis=1) # current dataframe\n",
    "        df = df.fillna(0)\n",
    "\n",
    "        ## convert all columns from float to int\n",
    "        cols = df.columns\n",
    "        df[cols] = df[cols].astype(int)\n",
    "        df[\"EQUIPMENT\"] = self.eq_id\n",
    "        return df\n",
    "        \n",
    "    def major_down(self, input_df, status_table, hour, threshold): \n",
    "        hour = pd.Timedelta(hours=hour)\n",
    "        major_down = []\n",
    "\n",
    "        for idx, row in input_df.iterrows():\n",
    "            start = row['TIMESTAMP']\n",
    "            end = start+hour\n",
    "            frame = status_table[(status_table['TIMESTAMP_START']>start) & (status_table['TIMESTAMP_START']<end)]\n",
    "            UD = frame.loc[frame['LEVEL3']=='UDT']\n",
    "\n",
    "            if len(UD) == 0: #no record within this 6 hours:\n",
    "                major_down.append(0)\n",
    "            else:\n",
    "                time_diff = (UD['TIMESTAMP_END']-UD['TIMESTAMP_START']).dt.seconds\n",
    "                if any(time_diff>=threshold): #threshold = 3600s\n",
    "                    major_down.append(1)\n",
    "                else:\n",
    "                    major_down.append(0)\n",
    "        return np.array(major_down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0d80118e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WBA120\n",
      "WBA121\n",
      "WBA122\n",
      "WBA123\n",
      "WBA124\n",
      "WBA125\n",
      "WBA126\n",
      "WBA127\n",
      "WBA128\n",
      "WBA129\n",
      "WBA130\n",
      "WBA132\n",
      "WBA133\n",
      "WBA134\n",
      "WBA135\n",
      "WBA137\n",
      "Data collection took 1980 seconds\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "all_tables = []\n",
    "all_target = []\n",
    "\n",
    "start = datetime.now()\n",
    "for _, path, filename in os.walk(\"Data\"):\n",
    "    for ele in filename:\n",
    "        alarm_file = ele\n",
    "        eq_id = ele[:6]\n",
    "        print(eq_id)\n",
    "\n",
    "        full_alarm = pd.read_excel(f\"Data/{alarm_file}\", engine='openpyxl', usecols = \"B,C,D,F,M\")\n",
    "        equipment = Aggregate_helper(eq_id, 24, 24, full_alarm)\n",
    "\n",
    "        all_tables.append(equipment.aggregated_table)\n",
    "        all_target.append(equipment.major_down_arr)\n",
    "\n",
    "end = datetime.now()\n",
    "print(f\"Data collection took {(end-start).seconds} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "87328572",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_training = pd.concat(all_tables, axis=0)\n",
    "new_training = new_training.fillna(0)\n",
    "\n",
    "## convert all columns from float to int\n",
    "df_float = new_training.select_dtypes(include=[np.float])\n",
    "cols = df_float.columns\n",
    "new_training[cols] = new_training[cols].astype(int)\n",
    "\n",
    "new_target = np.concatenate(all_target)\n",
    "\n",
    "col_order = new_training.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "05d8ca92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>8</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>...</th>\n",
       "      <th>238</th>\n",
       "      <th>Conversion</th>\n",
       "      <th>64</th>\n",
       "      <th>70</th>\n",
       "      <th>236</th>\n",
       "      <th>91</th>\n",
       "      <th>159</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-02-12 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-02-12 03:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-02-12 06:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-02-12 09:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-02-12 12:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7908</th>\n",
       "      <td>2021-08-26 12:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7909</th>\n",
       "      <td>2021-08-26 15:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7910</th>\n",
       "      <td>2021-08-26 18:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7911</th>\n",
       "      <td>2021-08-26 21:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7912</th>\n",
       "      <td>2021-08-27 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101728 rows Ã— 140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               TIMESTAMP  2  3  4  5  8  10  11  12  13  ...  238  Conversion  \\\n",
       "0    2021-02-12 00:00:00  0  0  0  0  0   0   4   0   0  ...    0           0   \n",
       "1    2021-02-12 03:00:00  0  0  0  0  0   0   3   0   0  ...    0           0   \n",
       "2    2021-02-12 06:00:00  0  0  0  0  0   0   2   0   0  ...    0           0   \n",
       "3    2021-02-12 09:00:00  0  0  0  0  0   0   1   0   0  ...    0           0   \n",
       "4    2021-02-12 12:00:00  0  0  0  0  0   0   1   0   0  ...    0           0   \n",
       "...                  ... .. .. .. .. ..  ..  ..  ..  ..  ...  ...         ...   \n",
       "7908 2021-08-26 12:00:00  0  0  0  0  1   0   6   0   0  ...    0           0   \n",
       "7909 2021-08-26 15:00:00  0  0  0  0  1   0   5   0   0  ...    0           0   \n",
       "7910 2021-08-26 18:00:00  0  0  0  0  0   0   4   0   0  ...    0           0   \n",
       "7911 2021-08-26 21:00:00  0  0  0  0  0   0   4   0   0  ...    0           0   \n",
       "7912 2021-08-27 00:00:00  0  0  0  0  0   0   4   1   0  ...    0           0   \n",
       "\n",
       "      64  70  236  91  159  131  132  TARGET  \n",
       "0      0   0    0   0    0    0    0       0  \n",
       "1      0   0    0   0    0    0    0       0  \n",
       "2      0   0    0   0    0    0    0       0  \n",
       "3      0   0    0   0    0    0    0       0  \n",
       "4      0   0    0   0    0    0    0       0  \n",
       "...   ..  ..  ...  ..  ...  ...  ...     ...  \n",
       "7908   0   0    0   0    0    0    0       1  \n",
       "7909   0   0    0   0    0    0    0       1  \n",
       "7910   0   0    0   0    0    0    0       1  \n",
       "7911   0   0    0   0    0    0    0       1  \n",
       "7912   0   0    0   0    0    0    0       1  \n",
       "\n",
       "[101728 rows x 140 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "03107f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_training[\"TARGET\"] = new_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fc2c7971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 7388, 1: 2796}) Counter({0: 1847, 1: 699})\n"
     ]
    }
   ],
   "source": [
    "training_df = new_training.drop([\"TIMESTAMP\", \"EQUIPMENT\", \"TARGET\"], axis=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(training_df.values, new_target, test_size=0.2, stratify=new_target)\n",
    "print(Counter(y_train), Counter(y_val))\n",
    "\n",
    "# time interval of 3 hours (rolling time frame)\n",
    "# 24 hours: 93% testing accuracy\n",
    "# 168 hours: 95% RF 92% DT\n",
    "\n",
    "# time interval of 24 hours (rolling time frame)\n",
    "# 24 hours: 71% testing accuracy\n",
    "# 168 hours: 65% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a4a215",
   "metadata": {},
   "source": [
    "# Check Prediction if train_val_split by index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b9c88a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 58260, 1: 23122}) Counter({0: 15734, 1: 4612})\n"
     ]
    }
   ],
   "source": [
    "training_df = new_training.drop([\"TIMESTAMP\", \"EQUIPMENT\"], axis=1)\n",
    "train_pct = int(0.8*len(training_df))\n",
    "train = training_df[:train_pct]\n",
    "val = training_df[train_pct:]\n",
    "\n",
    "X_train = train.drop([\"TARGET\"], axis=1).values\n",
    "y_train = train[\"TARGET\"].values\n",
    "\n",
    "X_val = val.drop([\"TARGET\"], axis=1).values\n",
    "y_val = val[\"TARGET\"].values\n",
    "print(Counter(y_train), Counter(y_val))\n",
    "\n",
    "# 3 hours interval (rolling time frame)\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a6322b",
   "metadata": {},
   "source": [
    "# Check prediction results when test set is collected from the latest dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ed122f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect test set by date\n",
    "aug = datetime(2021, 8, 1)\n",
    "test_set = new_training[new_training[\"TIMESTAMP\"]>=aug].drop([\"TIMESTAMP\", \"EQUIPMENT\"], axis=1)\n",
    "training_set = new_training[new_training[\"TIMESTAMP\"]<aug].drop([\"TIMESTAMP\", \"EQUIPMENT\"], axis=1)\n",
    "\n",
    "X_train = training_set.drop([\"TARGET\"], axis=1).values\n",
    "y_train = np.array(training_set[\"TARGET\"].values)\n",
    "\n",
    "X_val = test_set.drop([\"TARGET\"], axis=1).values\n",
    "y_val = np.array(test_set[\"TARGET\"].values)\n",
    "\n",
    "# Accuracy: 81% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff4c3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(y_train), Counter(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca427a4",
   "metadata": {},
   "source": [
    "# Check prediction results when test set is one specific equipment after a date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9ff203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect test set by EQ\n",
    "# predict aug results for that EQ\n",
    "test_set = new_training[(new_training[\"TIMESTAMP\"]>=aug) &\n",
    "                        (new_training[\"EQUIPMENT\"]==\"WBA127\")].drop([\"TIMESTAMP\", \"EQUIPMENT\"], axis=1)\n",
    "training_set = new_training[~((new_training[\"TIMESTAMP\"]>=aug) &\n",
    "                        (new_training[\"EQUIPMENT\"]==\"WBA127\"))].drop([\"TIMESTAMP\", \"EQUIPMENT\"], axis=1)\n",
    "\n",
    "X_train = training_set.drop([\"TARGET\"], axis=1).values\n",
    "y_train = np.array(training_set[\"TARGET\"].values)\n",
    "\n",
    "X_val = test_set.drop([\"TARGET\"], axis=1).values\n",
    "y_val = np.array(test_set[\"TARGET\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaa23e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(y_train), Counter(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69198131",
   "metadata": {},
   "source": [
    "# Check prediction when it is only trained on one equipment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cf4b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = datetime(2021, 8, 1)\n",
    "test_set = new_training[(new_training[\"TIMESTAMP\"]>=aug) &\n",
    "                        (new_training[\"EQUIPMENT\"]==\"WBA128\")].drop([\"TIMESTAMP\", \"EQUIPMENT\"], axis=1)\n",
    "training_set = new_training[(new_training[\"TIMESTAMP\"]<=aug) &\n",
    "                        (new_training[\"EQUIPMENT\"]==\"WBA128\")].drop([\"TIMESTAMP\", \"EQUIPMENT\"], axis=1)\n",
    "\n",
    "X_train = training_set.drop([\"TARGET\"], axis=1).values\n",
    "y_train = np.array(training_set[\"TARGET\"].values)\n",
    "\n",
    "X_val = test_set.drop([\"TARGET\"], axis=1).values\n",
    "y_val = np.array(test_set[\"TARGET\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d245e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(y_train), Counter(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a2006e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15046   688]\n",
      " [ 3953   659]] 0.7718961958124447\n",
      "Model out of bag score =  0.8942395124228945\n",
      "Best Threshold=0.178988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[8286, 7448],\n",
       "        [ 526, 4086]]),\n",
       " 0.6080802123267472)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_model = DecisionTreeClassifier(random_state=42) # decision tree has no n_jobs parameter\n",
    "# xgb_model = XGBClassifier(random_state=42, n_jobs=-1)\n",
    "rf_model = RandomForestClassifier(random_state=42, n_jobs=-1, oob_score=True)\n",
    "\n",
    "def to_labels(y_scores, threshold):\n",
    "    return (y_scores >= threshold).astype('int')\n",
    "\n",
    "models = [rf_model]\n",
    "for model in models:\n",
    "    start = datetime.now()\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_val)\n",
    "    y_score = model.predict_proba(X_val)[:,1]\n",
    "\n",
    "#     end = datetime.now()\n",
    "#     print(f\"Training took {(end-start).seconds} seconds\")\n",
    "#     print(confusion_matrix(y_val, pred))\n",
    "#     print(f\"Prediction Accuracy for {type(model).__name__} is {accuracy_score(y_val, pred)}\")\n",
    "print(confusion_matrix(y_val, pred), accuracy_score(y_val, pred))\n",
    "print(\"Model out of bag score = \", rf_model.oob_score_)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_val, y_score)\n",
    "J = tpr - fpr\n",
    "ix = np.argmax(J)\n",
    "best_thresh = thresholds[ix]\n",
    "print('Best Threshold=%f' % (best_thresh))\n",
    "\n",
    "testest = to_labels(y_score, best_thresh) # best thresh optimizes recall\n",
    "confusion_matrix(y_val, testest), accuracy_score(y_val, testest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d87aa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation to check if picking from the center would yield different results\n",
    "from sklearn.model_selection import KFold \n",
    "\n",
    "k = 5\n",
    "kf = KFold(n_splits=k, random_state=None) \n",
    "acc_score = []\n",
    "\n",
    "X = new_training.drop([\"TIMESTAMP\", \"EQUIPMENT\", \"TARGET\"], axis=1)\n",
    "y = new_training[\"TARGET\"]\n",
    "\n",
    "for train_index , test_index in kf.split(X):\n",
    "    X_train , X_test = X.iloc[train_index,:],X.iloc[test_index,:]\n",
    "    y_train , y_test = y[train_index] , y[test_index]\n",
    "     \n",
    "    model.fit(X_train,y_train)\n",
    "    pred_values = model.predict(X_test)\n",
    "     \n",
    "    acc = accuracy_score(pred_values , y_test)\n",
    "    acc_score.append(acc)\n",
    "     \n",
    "avg_acc_score = sum(acc_score)/k\n",
    " \n",
    "print('accuracy of each fold - {}'.format(acc_score))\n",
    "print('Avg accuracy : {}'.format(avg_acc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd445ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_train, y_train)\n",
    "pred = rf_model.predict(X_val)\n",
    "\n",
    "print(confusion_matrix(y_val, pred))\n",
    "print(f\"Prediction Accuracy for {type(rf_model).__name__} is {accuracy_score(y_val, pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ae3b96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENV-MAL-VE",
   "language": "python",
   "name": "env-mal-ve_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
