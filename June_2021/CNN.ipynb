{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b5e3058",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reads variable from the previous notebook\n",
    "%store -r train_dataset_by_row validation_dataset_by_row test_dataset_by_row res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6270deff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input_Time_Window_Start</th>\n",
       "      <th>Input_Time_Window_End</th>\n",
       "      <th>No. Small hangups</th>\n",
       "      <th>Alarm2Count</th>\n",
       "      <th>Alarm4Count</th>\n",
       "      <th>Alarm10Count</th>\n",
       "      <th>Alarm3Count</th>\n",
       "      <th>Alarm5Count</th>\n",
       "      <th>Alarm90Count</th>\n",
       "      <th>Alarm19Count</th>\n",
       "      <th>...</th>\n",
       "      <th>Machine Failure Failed</th>\n",
       "      <th>Machine Failure Reset</th>\n",
       "      <th>Change Setup</th>\n",
       "      <th>Change Setup Passed</th>\n",
       "      <th>Change Setup Failed</th>\n",
       "      <th>Change Setup Reset</th>\n",
       "      <th>xscation error 1087242244 Count</th>\n",
       "      <th>xscation error 13500912 Count</th>\n",
       "      <th>xscation error 13500638 Count</th>\n",
       "      <th>xscation error 999 Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-28 00:00:00</td>\n",
       "      <td>2021-01-28 06:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-28 06:00:00</td>\n",
       "      <td>2021-01-28 12:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-28 12:00:00</td>\n",
       "      <td>2021-01-28 18:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-28 18:00:00</td>\n",
       "      <td>2021-01-29 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-29 00:00:00</td>\n",
       "      <td>2021-01-29 06:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14107</th>\n",
       "      <td>2021-06-08 12:00:00</td>\n",
       "      <td>2021-06-08 18:00:00</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14108</th>\n",
       "      <td>2021-06-08 18:00:00</td>\n",
       "      <td>2021-06-09 00:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14109</th>\n",
       "      <td>2021-06-09 00:00:00</td>\n",
       "      <td>2021-06-09 06:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14110</th>\n",
       "      <td>2021-06-09 06:00:00</td>\n",
       "      <td>2021-06-09 12:00:00</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14111</th>\n",
       "      <td>2021-06-09 12:00:00</td>\n",
       "      <td>2021-06-09 18:00:00</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14112 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Input_Time_Window_Start Input_Time_Window_End  No. Small hangups  \\\n",
       "0         2021-01-28 00:00:00   2021-01-28 06:00:00                  0   \n",
       "1         2021-01-28 06:00:00   2021-01-28 12:00:00                  4   \n",
       "2         2021-01-28 12:00:00   2021-01-28 18:00:00                  3   \n",
       "3         2021-01-28 18:00:00   2021-01-29 00:00:00                  1   \n",
       "4         2021-01-29 00:00:00   2021-01-29 06:00:00                  6   \n",
       "...                       ...                   ...                ...   \n",
       "14107     2021-06-08 12:00:00   2021-06-08 18:00:00                 21   \n",
       "14108     2021-06-08 18:00:00   2021-06-09 00:00:00                  6   \n",
       "14109     2021-06-09 00:00:00   2021-06-09 06:00:00                  4   \n",
       "14110     2021-06-09 06:00:00   2021-06-09 12:00:00                 16   \n",
       "14111     2021-06-09 12:00:00   2021-06-09 18:00:00                 35   \n",
       "\n",
       "       Alarm2Count  Alarm4Count  Alarm10Count  Alarm3Count  Alarm5Count  \\\n",
       "0                0            0             0            0            0   \n",
       "1                0            0             0            0            1   \n",
       "2                0            0             2            0            1   \n",
       "3                0            0             0            0            0   \n",
       "4                0            0             0            0            0   \n",
       "...            ...          ...           ...          ...          ...   \n",
       "14107            0            0             1            0            0   \n",
       "14108            0            0             0            0            0   \n",
       "14109            0            0             0            0            0   \n",
       "14110            0            0             0            0            0   \n",
       "14111            0            0             0            0            0   \n",
       "\n",
       "       Alarm90Count  Alarm19Count  ...  Machine Failure Failed  \\\n",
       "0                 0             0  ...                       0   \n",
       "1                 0             0  ...                       0   \n",
       "2                 0             0  ...                       0   \n",
       "3                 0             0  ...                       0   \n",
       "4                 0             0  ...                       0   \n",
       "...             ...           ...  ...                     ...   \n",
       "14107             0             0  ...                       0   \n",
       "14108             0             0  ...                       0   \n",
       "14109             0             0  ...                       0   \n",
       "14110             0             0  ...                       0   \n",
       "14111             0             0  ...                       0   \n",
       "\n",
       "       Machine Failure Reset  Change Setup  Change Setup Passed  \\\n",
       "0                          0             0                    0   \n",
       "1                          0             0                    0   \n",
       "2                          0             0                    0   \n",
       "3                          0             0                    0   \n",
       "4                          0             0                    0   \n",
       "...                      ...           ...                  ...   \n",
       "14107                      0             0                    0   \n",
       "14108                      0             0                    0   \n",
       "14109                      0             0                    0   \n",
       "14110                      0             0                    0   \n",
       "14111                      0             0                    0   \n",
       "\n",
       "       Change Setup Failed  Change Setup Reset  \\\n",
       "0                        0                   0   \n",
       "1                        0                   0   \n",
       "2                        0                   0   \n",
       "3                        0                   0   \n",
       "4                        0                   0   \n",
       "...                    ...                 ...   \n",
       "14107                    0                   0   \n",
       "14108                    0                   0   \n",
       "14109                    0                   0   \n",
       "14110                    0                   0   \n",
       "14111                    0                   0   \n",
       "\n",
       "       xscation error 1087242244 Count  xscation error 13500912 Count  \\\n",
       "0                                    0                              0   \n",
       "1                                    0                              0   \n",
       "2                                    0                              0   \n",
       "3                                    0                              0   \n",
       "4                                    0                              0   \n",
       "...                                ...                            ...   \n",
       "14107                                2                              0   \n",
       "14108                                1                              0   \n",
       "14109                                0                              0   \n",
       "14110                                0                              0   \n",
       "14111                                0                              0   \n",
       "\n",
       "       xscation error 13500638 Count  xscation error 999 Count  \n",
       "0                                  0                         0  \n",
       "1                                  0                         0  \n",
       "2                                  0                         0  \n",
       "3                                  0                         0  \n",
       "4                                  0                         0  \n",
       "...                              ...                       ...  \n",
       "14107                              0                         0  \n",
       "14108                              0                         0  \n",
       "14109                              0                         0  \n",
       "14110                              1                         0  \n",
       "14111                              0                         0  \n",
       "\n",
       "[14112 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_by_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "865a85ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras_tuner as kt\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, Input, Conv1D, BatchNormalization #import in this exact format to prevent errors\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler #this is to scale the data from 0 to 1 to increase the model training efficiency\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc2761c",
   "metadata": {},
   "source": [
    "# Changed input data to 3D array and make use of RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8be3b57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_len = round(0.75*len(res2)) #90\n",
    "validation_data_len = round(0.2*len(res2)) #24\n",
    "test_data_len = len(res2) - training_data_len - validation_data_len #6\n",
    "\n",
    "#load in train_dataset_by_row validation_dataset_by_row test_dataset_by_row res2\n",
    "train_dataset_by_row = train_dataset_by_row.drop(['Input_Time_Window_Start', 'Input_Time_Window_End'], axis=1)\n",
    "validation_dataset_by_row = validation_dataset_by_row.drop(['Input_Time_Window_Start', 'Input_Time_Window_End'], axis=1)\n",
    "test_dataset_by_row = test_dataset_by_row.drop(['Input_Time_Window_Start', 'Input_Time_Window_End'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6d4f64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#split data\n",
    "x_train, y_train = [], []\n",
    "\n",
    "x_val, y_val = [], []\n",
    "\n",
    "x_test, y_test = [], []\n",
    "\n",
    "for i in range(training_data_len): #loops from 0 to 90\n",
    "    x_data = train_dataset_by_row[i*28:i*28+28]\n",
    "    y_data = res2.iloc[i]['NoMajorDown']\n",
    "    x_train.append(x_data)\n",
    "    y_train.append(y_data)\n",
    "    \n",
    "for i in range(validation_data_len): #loops from 0 to 90\n",
    "    x_data = validation_dataset_by_row[i*28:i*28+28]\n",
    "    y_data = res2.iloc[training_data_len + i]['NoMajorDown']\n",
    "    x_val.append(x_data)\n",
    "    y_val.append(y_data)\n",
    "    \n",
    "for i in range(test_data_len): #loops from 0 to 90\n",
    "    x_data = test_dataset_by_row[i*28:i*28+28]\n",
    "    y_data = res2.iloc[training_data_len + validation_data_len + i]['NoMajorDown']\n",
    "    x_test.append(x_data)\n",
    "    y_test.append(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17078621",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize the data for the model to learn better\n",
    "train_mean = np.mean(x_train)\n",
    "val_mean = np.mean(x_val)\n",
    "test_mean = np.mean(x_test)\n",
    "\n",
    "x_train = x_train/train_mean\n",
    "x_val = x_val/val_mean\n",
    "x_test = x_test/test_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec95d4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All shapes are (batches, timestamps, features)\n",
      "Training data has (318, 28, 19)\n",
      "label has (318, 1, 1)\n",
      "Validation data has (85, 28, 19)\n",
      "val_label has (85, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "def convert_to_binary(array): #convert no. major down to binary for classification \n",
    "    return [1 if ele!= 0 else 0 for ele in array]\n",
    "\n",
    "binary_y_train = convert_to_binary(y_train)\n",
    "binary_y_val = convert_to_binary(y_val)\n",
    "binary_y_test = convert_to_binary(y_test)\n",
    "\n",
    "x_train, x_val, x_test = np.array(x_train), np.array(x_val), np.array(x_test)\n",
    "binary_y_train = np.reshape(binary_y_train, (len(binary_y_train),1,1)) #90 samples, 1 timestamp, 1 feature\n",
    "binary_y_val = np.reshape(binary_y_val, (len(binary_y_val),1,1))\n",
    "binary_y_test = np.reshape(binary_y_test, (len(binary_y_test),1,1))\n",
    "\n",
    "print(\"All shapes are (batches, timestamps, features)\")\n",
    "print(f'Training data has {x_train.shape}')\n",
    "print(f'label has {binary_y_train.shape}')\n",
    "\n",
    "#check this to make sure training and validation data have the same features\n",
    "print(f'Validation data has {x_val.shape}')\n",
    "print(f'val_label has {binary_y_val.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43fe6649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 1)                 84        \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 86\n",
      "Trainable params: 86\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    #Input with 32 neurons\n",
    "    model.add(LSTM(1, input_shape=(x_train.shape[1], x_train.shape[2]), return_sequences=False))\n",
    "    \n",
    "    #output layer\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c30fc67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "12/12 [==============================] - 4s 93ms/step - loss: 0.6980 - binary_accuracy: 0.4245 - val_loss: 0.6934 - val_binary_accuracy: 0.6000\n",
      "Epoch 2/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.6930 - binary_accuracy: 0.5912 - val_loss: 0.6895 - val_binary_accuracy: 0.6941\n",
      "Epoch 3/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.6883 - binary_accuracy: 0.6761 - val_loss: 0.6858 - val_binary_accuracy: 0.7294\n",
      "Epoch 4/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.6837 - binary_accuracy: 0.7862 - val_loss: 0.6821 - val_binary_accuracy: 0.7882\n",
      "Epoch 5/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.6791 - binary_accuracy: 0.8333 - val_loss: 0.6784 - val_binary_accuracy: 0.7882\n",
      "Epoch 6/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.6730 - binary_accuracy: 0.8333 - val_loss: 0.6726 - val_binary_accuracy: 0.7882\n",
      "Epoch 7/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.6665 - binary_accuracy: 0.8333 - val_loss: 0.6690 - val_binary_accuracy: 0.7882\n",
      "Epoch 8/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.6624 - binary_accuracy: 0.8333 - val_loss: 0.6657 - val_binary_accuracy: 0.7882\n",
      "Epoch 9/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.6583 - binary_accuracy: 0.8333 - val_loss: 0.6624 - val_binary_accuracy: 0.7882\n",
      "Epoch 10/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.6542 - binary_accuracy: 0.8333 - val_loss: 0.6591 - val_binary_accuracy: 0.7882\n",
      "Epoch 11/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.6500 - binary_accuracy: 0.8333 - val_loss: 0.6559 - val_binary_accuracy: 0.7882\n",
      "Epoch 12/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.6459 - binary_accuracy: 0.8333 - val_loss: 0.6526 - val_binary_accuracy: 0.7882\n",
      "Epoch 13/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.6416 - binary_accuracy: 0.8333 - val_loss: 0.6493 - val_binary_accuracy: 0.7882\n",
      "Epoch 14/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.6373 - binary_accuracy: 0.8333 - val_loss: 0.6460 - val_binary_accuracy: 0.7882\n",
      "Epoch 15/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.6329 - binary_accuracy: 0.8333 - val_loss: 0.6426 - val_binary_accuracy: 0.7882\n",
      "Epoch 16/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.6283 - binary_accuracy: 0.8333 - val_loss: 0.6391 - val_binary_accuracy: 0.7882\n",
      "Epoch 17/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.6235 - binary_accuracy: 0.8333 - val_loss: 0.6353 - val_binary_accuracy: 0.7882\n",
      "Epoch 18/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.6184 - binary_accuracy: 0.8333 - val_loss: 0.6308 - val_binary_accuracy: 0.7882\n",
      "Epoch 19/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.6126 - binary_accuracy: 0.8333 - val_loss: 0.6251 - val_binary_accuracy: 0.7882\n",
      "Epoch 20/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.6058 - binary_accuracy: 0.8333 - val_loss: 0.6173 - val_binary_accuracy: 0.7882\n",
      "Epoch 21/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.5978 - binary_accuracy: 0.8333 - val_loss: 0.6078 - val_binary_accuracy: 0.7882\n",
      "Epoch 22/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.5893 - binary_accuracy: 0.8333 - val_loss: 0.5986 - val_binary_accuracy: 0.7882\n",
      "Epoch 23/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.5806 - binary_accuracy: 0.8333 - val_loss: 0.5905 - val_binary_accuracy: 0.7882\n",
      "Epoch 24/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.5729 - binary_accuracy: 0.8333 - val_loss: 0.5837 - val_binary_accuracy: 0.7882\n",
      "Epoch 25/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.5661 - binary_accuracy: 0.8333 - val_loss: 0.5779 - val_binary_accuracy: 0.7882\n",
      "Epoch 26/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.5600 - binary_accuracy: 0.8333 - val_loss: 0.5728 - val_binary_accuracy: 0.7882\n",
      "Epoch 27/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.5544 - binary_accuracy: 0.8333 - val_loss: 0.5682 - val_binary_accuracy: 0.7882\n",
      "Epoch 28/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.5491 - binary_accuracy: 0.8333 - val_loss: 0.5640 - val_binary_accuracy: 0.7882\n",
      "Epoch 29/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.5443 - binary_accuracy: 0.8333 - val_loss: 0.5602 - val_binary_accuracy: 0.7882\n",
      "Epoch 30/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.5397 - binary_accuracy: 0.8333 - val_loss: 0.5567 - val_binary_accuracy: 0.7882\n",
      "Epoch 31/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.5354 - binary_accuracy: 0.8333 - val_loss: 0.5535 - val_binary_accuracy: 0.7882\n",
      "Epoch 32/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.5313 - binary_accuracy: 0.8333 - val_loss: 0.5504 - val_binary_accuracy: 0.7882\n",
      "Epoch 33/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.5275 - binary_accuracy: 0.8333 - val_loss: 0.5476 - val_binary_accuracy: 0.7882\n",
      "Epoch 34/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.5238 - binary_accuracy: 0.8333 - val_loss: 0.5450 - val_binary_accuracy: 0.7882\n",
      "Epoch 35/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.5203 - binary_accuracy: 0.8333 - val_loss: 0.5425 - val_binary_accuracy: 0.7882\n",
      "Epoch 36/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.5170 - binary_accuracy: 0.8333 - val_loss: 0.5402 - val_binary_accuracy: 0.7882\n",
      "Epoch 37/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.5139 - binary_accuracy: 0.8333 - val_loss: 0.5380 - val_binary_accuracy: 0.7882\n",
      "Epoch 38/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.5109 - binary_accuracy: 0.8333 - val_loss: 0.5360 - val_binary_accuracy: 0.7882\n",
      "Epoch 39/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.5081 - binary_accuracy: 0.8333 - val_loss: 0.5341 - val_binary_accuracy: 0.7882\n",
      "Epoch 40/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.5053 - binary_accuracy: 0.8333 - val_loss: 0.5323 - val_binary_accuracy: 0.7882\n",
      "Epoch 41/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.5027 - binary_accuracy: 0.8333 - val_loss: 0.5306 - val_binary_accuracy: 0.7882\n",
      "Epoch 42/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.5003 - binary_accuracy: 0.8333 - val_loss: 0.5290 - val_binary_accuracy: 0.7882\n",
      "Epoch 43/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.4979 - binary_accuracy: 0.8333 - val_loss: 0.5276 - val_binary_accuracy: 0.7882\n",
      "Epoch 44/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.4957 - binary_accuracy: 0.8333 - val_loss: 0.5262 - val_binary_accuracy: 0.7882\n",
      "Epoch 45/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4935 - binary_accuracy: 0.8333 - val_loss: 0.5249 - val_binary_accuracy: 0.7882\n",
      "Epoch 46/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4915 - binary_accuracy: 0.8333 - val_loss: 0.5237 - val_binary_accuracy: 0.7882\n",
      "Epoch 47/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4895 - binary_accuracy: 0.8333 - val_loss: 0.5225 - val_binary_accuracy: 0.7882\n",
      "Epoch 48/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4876 - binary_accuracy: 0.8333 - val_loss: 0.5215 - val_binary_accuracy: 0.7882\n",
      "Epoch 49/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.4858 - binary_accuracy: 0.8333 - val_loss: 0.5205 - val_binary_accuracy: 0.7882\n",
      "Epoch 50/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.4841 - binary_accuracy: 0.8333 - val_loss: 0.5195 - val_binary_accuracy: 0.7882\n",
      "Epoch 51/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.4825 - binary_accuracy: 0.8333 - val_loss: 0.5187 - val_binary_accuracy: 0.7882\n",
      "Epoch 52/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4809 - binary_accuracy: 0.8333 - val_loss: 0.5179 - val_binary_accuracy: 0.7882\n",
      "Epoch 53/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4794 - binary_accuracy: 0.8333 - val_loss: 0.5171 - val_binary_accuracy: 0.7882\n",
      "Epoch 54/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4780 - binary_accuracy: 0.8333 - val_loss: 0.5164 - val_binary_accuracy: 0.7882\n",
      "Epoch 55/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4766 - binary_accuracy: 0.8333 - val_loss: 0.5158 - val_binary_accuracy: 0.7882\n",
      "Epoch 56/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4753 - binary_accuracy: 0.8333 - val_loss: 0.5152 - val_binary_accuracy: 0.7882\n",
      "Epoch 57/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.4741 - binary_accuracy: 0.8333 - val_loss: 0.5147 - val_binary_accuracy: 0.7882\n",
      "Epoch 58/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.4729 - binary_accuracy: 0.8333 - val_loss: 0.5142 - val_binary_accuracy: 0.7882\n",
      "Epoch 59/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.4718 - binary_accuracy: 0.8333 - val_loss: 0.5137 - val_binary_accuracy: 0.7882\n",
      "Epoch 60/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.4707 - binary_accuracy: 0.8333 - val_loss: 0.5133 - val_binary_accuracy: 0.7882\n",
      "Epoch 61/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4696 - binary_accuracy: 0.8333 - val_loss: 0.5130 - val_binary_accuracy: 0.7882\n",
      "Epoch 62/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4686 - binary_accuracy: 0.8333 - val_loss: 0.5126 - val_binary_accuracy: 0.7882\n",
      "Epoch 63/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4677 - binary_accuracy: 0.8333 - val_loss: 0.5124 - val_binary_accuracy: 0.7882\n",
      "Epoch 64/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4668 - binary_accuracy: 0.8333 - val_loss: 0.5121 - val_binary_accuracy: 0.7882\n",
      "Epoch 65/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4659 - binary_accuracy: 0.8333 - val_loss: 0.5119 - val_binary_accuracy: 0.7882\n",
      "Epoch 66/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4651 - binary_accuracy: 0.8333 - val_loss: 0.5118 - val_binary_accuracy: 0.7882\n",
      "Epoch 67/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4643 - binary_accuracy: 0.8333 - val_loss: 0.5117 - val_binary_accuracy: 0.7882\n",
      "Epoch 68/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4635 - binary_accuracy: 0.8333 - val_loss: 0.5116 - val_binary_accuracy: 0.7882\n",
      "Epoch 69/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4628 - binary_accuracy: 0.8333 - val_loss: 0.5115 - val_binary_accuracy: 0.7882\n",
      "Epoch 70/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4621 - binary_accuracy: 0.8333 - val_loss: 0.5115 - val_binary_accuracy: 0.7882\n",
      "Epoch 71/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4614 - binary_accuracy: 0.8333 - val_loss: 0.5115 - val_binary_accuracy: 0.7882\n",
      "Epoch 72/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4608 - binary_accuracy: 0.8333 - val_loss: 0.5115 - val_binary_accuracy: 0.7882\n",
      "Epoch 73/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4602 - binary_accuracy: 0.8333 - val_loss: 0.5116 - val_binary_accuracy: 0.7882\n",
      "Epoch 74/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4596 - binary_accuracy: 0.8333 - val_loss: 0.5117 - val_binary_accuracy: 0.7882\n",
      "Epoch 75/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4590 - binary_accuracy: 0.8333 - val_loss: 0.5118 - val_binary_accuracy: 0.7882\n",
      "Epoch 76/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4585 - binary_accuracy: 0.8333 - val_loss: 0.5119 - val_binary_accuracy: 0.7882\n",
      "Epoch 77/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4580 - binary_accuracy: 0.8333 - val_loss: 0.5121 - val_binary_accuracy: 0.7882\n",
      "Epoch 78/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4575 - binary_accuracy: 0.8333 - val_loss: 0.5123 - val_binary_accuracy: 0.7882\n",
      "Epoch 79/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4570 - binary_accuracy: 0.8333 - val_loss: 0.5124 - val_binary_accuracy: 0.7882\n",
      "Epoch 80/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4566 - binary_accuracy: 0.8333 - val_loss: 0.5126 - val_binary_accuracy: 0.7882\n",
      "Epoch 81/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4561 - binary_accuracy: 0.8333 - val_loss: 0.5128 - val_binary_accuracy: 0.7882\n",
      "Epoch 82/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4557 - binary_accuracy: 0.8333 - val_loss: 0.5130 - val_binary_accuracy: 0.7882\n",
      "Epoch 83/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4553 - binary_accuracy: 0.8333 - val_loss: 0.5133 - val_binary_accuracy: 0.7882\n",
      "Epoch 84/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4550 - binary_accuracy: 0.8333 - val_loss: 0.5135 - val_binary_accuracy: 0.7882\n",
      "Epoch 85/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4546 - binary_accuracy: 0.8333 - val_loss: 0.5137 - val_binary_accuracy: 0.7882\n",
      "Epoch 86/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4543 - binary_accuracy: 0.8333 - val_loss: 0.5139 - val_binary_accuracy: 0.7882\n",
      "Epoch 87/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4539 - binary_accuracy: 0.8333 - val_loss: 0.5141 - val_binary_accuracy: 0.7882\n",
      "Epoch 88/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4536 - binary_accuracy: 0.8333 - val_loss: 0.5143 - val_binary_accuracy: 0.7882\n",
      "Epoch 89/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4533 - binary_accuracy: 0.8333 - val_loss: 0.5145 - val_binary_accuracy: 0.7882\n",
      "Epoch 90/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4530 - binary_accuracy: 0.8333 - val_loss: 0.5147 - val_binary_accuracy: 0.7882\n",
      "Epoch 91/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4527 - binary_accuracy: 0.8333 - val_loss: 0.5149 - val_binary_accuracy: 0.7882\n",
      "Epoch 92/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4524 - binary_accuracy: 0.8333 - val_loss: 0.5151 - val_binary_accuracy: 0.7882\n",
      "Epoch 93/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4522 - binary_accuracy: 0.8333 - val_loss: 0.5153 - val_binary_accuracy: 0.7882\n",
      "Epoch 94/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4519 - binary_accuracy: 0.8333 - val_loss: 0.5155 - val_binary_accuracy: 0.7882\n",
      "Epoch 95/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4517 - binary_accuracy: 0.8333 - val_loss: 0.5157 - val_binary_accuracy: 0.7882\n",
      "Epoch 96/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4515 - binary_accuracy: 0.8333 - val_loss: 0.5158 - val_binary_accuracy: 0.7882\n",
      "Epoch 97/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4512 - binary_accuracy: 0.8333 - val_loss: 0.5160 - val_binary_accuracy: 0.7882\n",
      "Epoch 98/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4510 - binary_accuracy: 0.8333 - val_loss: 0.5162 - val_binary_accuracy: 0.7882\n",
      "Epoch 99/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4508 - binary_accuracy: 0.8333 - val_loss: 0.5163 - val_binary_accuracy: 0.7882\n",
      "Epoch 100/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4506 - binary_accuracy: 0.8333 - val_loss: 0.5165 - val_binary_accuracy: 0.7882\n",
      "Epoch 101/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4504 - binary_accuracy: 0.8333 - val_loss: 0.5166 - val_binary_accuracy: 0.7882\n",
      "Epoch 102/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4502 - binary_accuracy: 0.8333 - val_loss: 0.5168 - val_binary_accuracy: 0.7882\n",
      "Epoch 103/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4500 - binary_accuracy: 0.8333 - val_loss: 0.5169 - val_binary_accuracy: 0.7882\n",
      "Epoch 104/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4499 - binary_accuracy: 0.8333 - val_loss: 0.5171 - val_binary_accuracy: 0.7882\n",
      "Epoch 105/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4497 - binary_accuracy: 0.8333 - val_loss: 0.5172 - val_binary_accuracy: 0.7882\n",
      "Epoch 106/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4496 - binary_accuracy: 0.8333 - val_loss: 0.5173 - val_binary_accuracy: 0.7882\n",
      "Epoch 107/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.4494 - binary_accuracy: 0.8333 - val_loss: 0.5175 - val_binary_accuracy: 0.7882\n",
      "Epoch 108/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4492 - binary_accuracy: 0.8333 - val_loss: 0.5176 - val_binary_accuracy: 0.7882\n",
      "Epoch 109/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4491 - binary_accuracy: 0.8333 - val_loss: 0.5177 - val_binary_accuracy: 0.7882\n",
      "Epoch 110/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4490 - binary_accuracy: 0.8333 - val_loss: 0.5179 - val_binary_accuracy: 0.7882\n",
      "Epoch 111/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.4488 - binary_accuracy: 0.8333 - val_loss: 0.5180 - val_binary_accuracy: 0.7882\n",
      "Epoch 112/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.4487 - binary_accuracy: 0.8333 - val_loss: 0.5181 - val_binary_accuracy: 0.7882\n",
      "Epoch 113/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.4486 - binary_accuracy: 0.8333 - val_loss: 0.5182 - val_binary_accuracy: 0.7882\n",
      "Epoch 114/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4484 - binary_accuracy: 0.8333 - val_loss: 0.5183 - val_binary_accuracy: 0.7882\n",
      "Epoch 115/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4483 - binary_accuracy: 0.8333 - val_loss: 0.5184 - val_binary_accuracy: 0.7882\n",
      "Epoch 116/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4482 - binary_accuracy: 0.8333 - val_loss: 0.5186 - val_binary_accuracy: 0.7882\n",
      "Epoch 117/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4481 - binary_accuracy: 0.8333 - val_loss: 0.5187 - val_binary_accuracy: 0.7882\n",
      "Epoch 118/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4480 - binary_accuracy: 0.8333 - val_loss: 0.5188 - val_binary_accuracy: 0.7882\n",
      "Epoch 119/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4479 - binary_accuracy: 0.8333 - val_loss: 0.5189 - val_binary_accuracy: 0.7882\n",
      "Epoch 120/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4478 - binary_accuracy: 0.8333 - val_loss: 0.5190 - val_binary_accuracy: 0.7882\n",
      "Epoch 121/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4476 - binary_accuracy: 0.8333 - val_loss: 0.5191 - val_binary_accuracy: 0.7882\n",
      "Epoch 122/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4475 - binary_accuracy: 0.8333 - val_loss: 0.5192 - val_binary_accuracy: 0.7882\n",
      "Epoch 123/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4474 - binary_accuracy: 0.8333 - val_loss: 0.5193 - val_binary_accuracy: 0.7882\n",
      "Epoch 124/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4474 - binary_accuracy: 0.8333 - val_loss: 0.5194 - val_binary_accuracy: 0.7882\n",
      "Epoch 125/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4472 - binary_accuracy: 0.8333 - val_loss: 0.5195 - val_binary_accuracy: 0.7882\n",
      "Epoch 126/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.4471 - binary_accuracy: 0.8333 - val_loss: 0.5196 - val_binary_accuracy: 0.7882\n",
      "Epoch 127/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.4470 - binary_accuracy: 0.8333 - val_loss: 0.5198 - val_binary_accuracy: 0.7882\n",
      "Epoch 128/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.4468 - binary_accuracy: 0.8333 - val_loss: 0.5200 - val_binary_accuracy: 0.7882\n",
      "Epoch 129/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4485 - binary_accuracy: 0.8333 - val_loss: 0.5202 - val_binary_accuracy: 0.7882\n",
      "Epoch 130/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4467 - binary_accuracy: 0.8333 - val_loss: 0.5203 - val_binary_accuracy: 0.7882\n",
      "Epoch 131/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4467 - binary_accuracy: 0.8333 - val_loss: 0.5206 - val_binary_accuracy: 0.7882\n",
      "Epoch 132/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4466 - binary_accuracy: 0.8333 - val_loss: 0.5208 - val_binary_accuracy: 0.7882\n",
      "Epoch 133/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4465 - binary_accuracy: 0.8333 - val_loss: 0.5210 - val_binary_accuracy: 0.7882\n",
      "Epoch 134/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4464 - binary_accuracy: 0.8333 - val_loss: 0.5212 - val_binary_accuracy: 0.7882\n",
      "Epoch 135/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4463 - binary_accuracy: 0.8333 - val_loss: 0.5214 - val_binary_accuracy: 0.7882\n",
      "Epoch 136/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4461 - binary_accuracy: 0.8333 - val_loss: 0.5215 - val_binary_accuracy: 0.7882\n",
      "Epoch 137/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4460 - binary_accuracy: 0.8333 - val_loss: 0.5216 - val_binary_accuracy: 0.7882\n",
      "Epoch 138/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4458 - binary_accuracy: 0.8333 - val_loss: 0.5218 - val_binary_accuracy: 0.7882\n",
      "Epoch 139/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4456 - binary_accuracy: 0.8333 - val_loss: 0.5219 - val_binary_accuracy: 0.7882\n",
      "Epoch 140/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4455 - binary_accuracy: 0.8333 - val_loss: 0.5220 - val_binary_accuracy: 0.7882\n",
      "Epoch 141/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4453 - binary_accuracy: 0.8333 - val_loss: 0.5221 - val_binary_accuracy: 0.7882\n",
      "Epoch 142/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4452 - binary_accuracy: 0.8333 - val_loss: 0.5222 - val_binary_accuracy: 0.7882\n",
      "Epoch 143/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4450 - binary_accuracy: 0.8333 - val_loss: 0.5224 - val_binary_accuracy: 0.7882\n",
      "Epoch 144/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4449 - binary_accuracy: 0.8333 - val_loss: 0.5225 - val_binary_accuracy: 0.7882\n",
      "Epoch 145/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4447 - binary_accuracy: 0.8333 - val_loss: 0.5226 - val_binary_accuracy: 0.7882\n",
      "Epoch 146/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4446 - binary_accuracy: 0.8333 - val_loss: 0.5227 - val_binary_accuracy: 0.7882\n",
      "Epoch 147/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4444 - binary_accuracy: 0.8333 - val_loss: 0.5228 - val_binary_accuracy: 0.7882\n",
      "Epoch 148/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4443 - binary_accuracy: 0.8333 - val_loss: 0.5229 - val_binary_accuracy: 0.7882\n",
      "Epoch 149/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4441 - binary_accuracy: 0.8333 - val_loss: 0.5230 - val_binary_accuracy: 0.7882\n",
      "Epoch 150/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4440 - binary_accuracy: 0.8333 - val_loss: 0.5230 - val_binary_accuracy: 0.7882\n",
      "Epoch 151/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4439 - binary_accuracy: 0.8333 - val_loss: 0.5231 - val_binary_accuracy: 0.7882\n",
      "Epoch 152/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4438 - binary_accuracy: 0.8333 - val_loss: 0.5232 - val_binary_accuracy: 0.7882\n",
      "Epoch 153/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4436 - binary_accuracy: 0.8333 - val_loss: 0.5233 - val_binary_accuracy: 0.7882\n",
      "Epoch 154/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4435 - binary_accuracy: 0.8333 - val_loss: 0.5234 - val_binary_accuracy: 0.7882\n",
      "Epoch 155/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4434 - binary_accuracy: 0.8333 - val_loss: 0.5235 - val_binary_accuracy: 0.7882\n",
      "Epoch 156/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4433 - binary_accuracy: 0.8333 - val_loss: 0.5236 - val_binary_accuracy: 0.7882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 157/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.4432 - binary_accuracy: 0.8333 - val_loss: 0.5236 - val_binary_accuracy: 0.7882\n",
      "Epoch 158/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.4431 - binary_accuracy: 0.8333 - val_loss: 0.5237 - val_binary_accuracy: 0.7882\n",
      "Epoch 159/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.4430 - binary_accuracy: 0.8333 - val_loss: 0.5238 - val_binary_accuracy: 0.7882\n",
      "Epoch 160/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.4429 - binary_accuracy: 0.8333 - val_loss: 0.5239 - val_binary_accuracy: 0.7882\n",
      "Epoch 161/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.4428 - binary_accuracy: 0.8333 - val_loss: 0.5239 - val_binary_accuracy: 0.7882\n",
      "Epoch 162/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.4427 - binary_accuracy: 0.8333 - val_loss: 0.5240 - val_binary_accuracy: 0.7882\n",
      "Epoch 163/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.4426 - binary_accuracy: 0.8333 - val_loss: 0.5240 - val_binary_accuracy: 0.7882\n",
      "Epoch 164/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4426 - binary_accuracy: 0.8333 - val_loss: 0.5241 - val_binary_accuracy: 0.7882\n",
      "Epoch 165/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.4425 - binary_accuracy: 0.8333 - val_loss: 0.5241 - val_binary_accuracy: 0.7882\n",
      "Epoch 166/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4424 - binary_accuracy: 0.8333 - val_loss: 0.5242 - val_binary_accuracy: 0.7882\n",
      "Epoch 167/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4423 - binary_accuracy: 0.8333 - val_loss: 0.5242 - val_binary_accuracy: 0.7882\n",
      "Epoch 168/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.4422 - binary_accuracy: 0.8333 - val_loss: 0.5242 - val_binary_accuracy: 0.7882\n",
      "Epoch 169/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.4421 - binary_accuracy: 0.8333 - val_loss: 0.5242 - val_binary_accuracy: 0.7882\n",
      "Epoch 170/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4420 - binary_accuracy: 0.8333 - val_loss: 0.5242 - val_binary_accuracy: 0.7882\n",
      "Epoch 171/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4420 - binary_accuracy: 0.8333 - val_loss: 0.5242 - val_binary_accuracy: 0.7882\n",
      "Epoch 172/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.4419 - binary_accuracy: 0.8333 - val_loss: 0.5242 - val_binary_accuracy: 0.7882\n",
      "Epoch 173/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4418 - binary_accuracy: 0.8333 - val_loss: 0.5242 - val_binary_accuracy: 0.7882\n",
      "Epoch 174/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.4417 - binary_accuracy: 0.8333 - val_loss: 0.5241 - val_binary_accuracy: 0.7882\n",
      "Epoch 175/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4416 - binary_accuracy: 0.8333 - val_loss: 0.5240 - val_binary_accuracy: 0.7882\n",
      "Epoch 176/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.4416 - binary_accuracy: 0.8333 - val_loss: 0.5239 - val_binary_accuracy: 0.7882\n",
      "Epoch 177/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.4415 - binary_accuracy: 0.8333 - val_loss: 0.5238 - val_binary_accuracy: 0.7882\n",
      "Epoch 178/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.4414 - binary_accuracy: 0.8333 - val_loss: 0.5236 - val_binary_accuracy: 0.7882\n",
      "Epoch 179/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.4413 - binary_accuracy: 0.8333 - val_loss: 0.5234 - val_binary_accuracy: 0.7882\n",
      "Epoch 180/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4412 - binary_accuracy: 0.8333 - val_loss: 0.5231 - val_binary_accuracy: 0.7882\n",
      "Epoch 181/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.4412 - binary_accuracy: 0.8333 - val_loss: 0.5228 - val_binary_accuracy: 0.7882\n",
      "Epoch 182/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4411 - binary_accuracy: 0.8333 - val_loss: 0.5225 - val_binary_accuracy: 0.7882\n",
      "Epoch 183/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.4410 - binary_accuracy: 0.8333 - val_loss: 0.5220 - val_binary_accuracy: 0.7882\n",
      "Epoch 184/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4410 - binary_accuracy: 0.8333 - val_loss: 0.5215 - val_binary_accuracy: 0.7882\n",
      "Epoch 185/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.4409 - binary_accuracy: 0.8333 - val_loss: 0.5209 - val_binary_accuracy: 0.7882\n",
      "Epoch 186/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4408 - binary_accuracy: 0.8333 - val_loss: 0.5202 - val_binary_accuracy: 0.7882\n",
      "Epoch 187/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.4407 - binary_accuracy: 0.8333 - val_loss: 0.5195 - val_binary_accuracy: 0.7882\n",
      "Epoch 188/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.4407 - binary_accuracy: 0.8333 - val_loss: 0.5191 - val_binary_accuracy: 0.7882\n",
      "Epoch 189/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4417 - binary_accuracy: 0.8333 - val_loss: 0.5224 - val_binary_accuracy: 0.7882\n",
      "Epoch 190/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4407 - binary_accuracy: 0.8333 - val_loss: 0.5233 - val_binary_accuracy: 0.7882\n",
      "Epoch 191/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.4422 - binary_accuracy: 0.8333 - val_loss: 0.5174 - val_binary_accuracy: 0.7882\n",
      "Epoch 192/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4406 - binary_accuracy: 0.8333 - val_loss: 0.5239 - val_binary_accuracy: 0.7882\n",
      "Epoch 193/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.4409 - binary_accuracy: 0.8333 - val_loss: 0.5255 - val_binary_accuracy: 0.7882\n",
      "Epoch 194/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.4411 - binary_accuracy: 0.8333 - val_loss: 0.5207 - val_binary_accuracy: 0.7882\n",
      "Epoch 195/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4405 - binary_accuracy: 0.8333 - val_loss: 0.5250 - val_binary_accuracy: 0.7882\n",
      "Epoch 196/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.4405 - binary_accuracy: 0.8333 - val_loss: 0.5236 - val_binary_accuracy: 0.7882\n",
      "Epoch 197/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4404 - binary_accuracy: 0.8333 - val_loss: 0.5253 - val_binary_accuracy: 0.7882\n",
      "Epoch 198/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4407 - binary_accuracy: 0.8333 - val_loss: 0.5221 - val_binary_accuracy: 0.7882\n",
      "Epoch 199/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4403 - binary_accuracy: 0.8333 - val_loss: 0.5253 - val_binary_accuracy: 0.7882\n",
      "Epoch 200/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4403 - binary_accuracy: 0.8333 - val_loss: 0.5234 - val_binary_accuracy: 0.7882\n",
      "Epoch 201/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4402 - binary_accuracy: 0.8333 - val_loss: 0.5253 - val_binary_accuracy: 0.7882\n",
      "Epoch 202/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.4403 - binary_accuracy: 0.8333 - val_loss: 0.5229 - val_binary_accuracy: 0.7882\n",
      "Epoch 203/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4401 - binary_accuracy: 0.8333 - val_loss: 0.5253 - val_binary_accuracy: 0.7882\n",
      "Epoch 204/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4402 - binary_accuracy: 0.8333 - val_loss: 0.5230 - val_binary_accuracy: 0.7882\n",
      "Epoch 205/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4400 - binary_accuracy: 0.8333 - val_loss: 0.5253 - val_binary_accuracy: 0.7882\n",
      "Epoch 206/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4401 - binary_accuracy: 0.8333 - val_loss: 0.5230 - val_binary_accuracy: 0.7882\n",
      "Epoch 207/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4399 - binary_accuracy: 0.8333 - val_loss: 0.5253 - val_binary_accuracy: 0.7882\n",
      "Epoch 208/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.4400 - binary_accuracy: 0.8333 - val_loss: 0.5229 - val_binary_accuracy: 0.7882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.4398 - binary_accuracy: 0.8333 - val_loss: 0.5253 - val_binary_accuracy: 0.7882\n",
      "Epoch 210/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4399 - binary_accuracy: 0.8333 - val_loss: 0.5228 - val_binary_accuracy: 0.7882\n",
      "Epoch 211/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4397 - binary_accuracy: 0.8333 - val_loss: 0.5253 - val_binary_accuracy: 0.7882\n",
      "Epoch 212/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4398 - binary_accuracy: 0.8333 - val_loss: 0.5227 - val_binary_accuracy: 0.7882\n",
      "Epoch 213/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4396 - binary_accuracy: 0.8333 - val_loss: 0.5252 - val_binary_accuracy: 0.7882\n",
      "Epoch 214/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.4397 - binary_accuracy: 0.8333 - val_loss: 0.5226 - val_binary_accuracy: 0.7882\n",
      "Epoch 215/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.4395 - binary_accuracy: 0.8333 - val_loss: 0.5252 - val_binary_accuracy: 0.7882\n",
      "Epoch 216/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4396 - binary_accuracy: 0.8333 - val_loss: 0.5226 - val_binary_accuracy: 0.7882\n",
      "Epoch 217/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.4394 - binary_accuracy: 0.8333 - val_loss: 0.5252 - val_binary_accuracy: 0.7882\n",
      "Epoch 218/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4395 - binary_accuracy: 0.8333 - val_loss: 0.5225 - val_binary_accuracy: 0.7882\n",
      "Epoch 219/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4393 - binary_accuracy: 0.8333 - val_loss: 0.5252 - val_binary_accuracy: 0.7882\n",
      "Epoch 220/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.4394 - binary_accuracy: 0.8333 - val_loss: 0.5225 - val_binary_accuracy: 0.7882\n",
      "Epoch 221/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4392 - binary_accuracy: 0.8333 - val_loss: 0.5252 - val_binary_accuracy: 0.7882\n",
      "Epoch 222/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4393 - binary_accuracy: 0.8333 - val_loss: 0.5224 - val_binary_accuracy: 0.7882\n",
      "Epoch 223/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4391 - binary_accuracy: 0.8333 - val_loss: 0.5252 - val_binary_accuracy: 0.7882\n",
      "Epoch 224/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.4392 - binary_accuracy: 0.8333 - val_loss: 0.5224 - val_binary_accuracy: 0.7882\n",
      "Epoch 225/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.4390 - binary_accuracy: 0.8333 - val_loss: 0.5251 - val_binary_accuracy: 0.7882\n",
      "Epoch 226/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4391 - binary_accuracy: 0.8333 - val_loss: 0.5224 - val_binary_accuracy: 0.7882\n",
      "Epoch 227/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4389 - binary_accuracy: 0.8333 - val_loss: 0.5251 - val_binary_accuracy: 0.7882\n",
      "Epoch 228/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4390 - binary_accuracy: 0.8333 - val_loss: 0.5224 - val_binary_accuracy: 0.7882\n",
      "Epoch 229/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.4388 - binary_accuracy: 0.8333 - val_loss: 0.5251 - val_binary_accuracy: 0.7882\n",
      "Epoch 230/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.4389 - binary_accuracy: 0.8333 - val_loss: 0.5224 - val_binary_accuracy: 0.7882\n",
      "Epoch 231/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.4387 - binary_accuracy: 0.8333 - val_loss: 0.5251 - val_binary_accuracy: 0.7882\n",
      "Epoch 232/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.4388 - binary_accuracy: 0.8333 - val_loss: 0.5224 - val_binary_accuracy: 0.7882\n",
      "Epoch 233/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.4387 - binary_accuracy: 0.8333 - val_loss: 0.5251 - val_binary_accuracy: 0.7882\n",
      "Epoch 234/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4387 - binary_accuracy: 0.8333 - val_loss: 0.5224 - val_binary_accuracy: 0.7882\n",
      "Epoch 235/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4386 - binary_accuracy: 0.8333 - val_loss: 0.5251 - val_binary_accuracy: 0.7882\n",
      "Epoch 236/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4386 - binary_accuracy: 0.8333 - val_loss: 0.5224 - val_binary_accuracy: 0.7882\n",
      "Epoch 237/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4385 - binary_accuracy: 0.8333 - val_loss: 0.5251 - val_binary_accuracy: 0.7882\n",
      "Epoch 238/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4386 - binary_accuracy: 0.8333 - val_loss: 0.5224 - val_binary_accuracy: 0.7882\n",
      "Epoch 239/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.4384 - binary_accuracy: 0.8333 - val_loss: 0.5251 - val_binary_accuracy: 0.7882\n",
      "Epoch 240/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.4385 - binary_accuracy: 0.8333 - val_loss: 0.5225 - val_binary_accuracy: 0.7882\n",
      "Epoch 241/400\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.4383 - binary_accuracy: 0.8333 - val_loss: 0.5251 - val_binary_accuracy: 0.7882\n",
      "Epoch 242/400\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.4384 - binary_accuracy: 0.8333 - val_loss: 0.5226 - val_binary_accuracy: 0.7882\n",
      "Epoch 243/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.4382 - binary_accuracy: 0.8333 - val_loss: 0.5251 - val_binary_accuracy: 0.7882\n",
      "Epoch 244/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.4383 - binary_accuracy: 0.8333 - val_loss: 0.5227 - val_binary_accuracy: 0.7882\n",
      "Epoch 245/400\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.4381 - binary_accuracy: 0.8333 - val_loss: 0.5252 - val_binary_accuracy: 0.7882\n",
      "Epoch 246/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.4382 - binary_accuracy: 0.8333 - val_loss: 0.5229 - val_binary_accuracy: 0.7882\n",
      "Epoch 247/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.4379 - binary_accuracy: 0.8333 - val_loss: 0.5253 - val_binary_accuracy: 0.7882\n",
      "Epoch 248/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.4380 - binary_accuracy: 0.8333 - val_loss: 0.5231 - val_binary_accuracy: 0.7882\n",
      "Epoch 249/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.4378 - binary_accuracy: 0.8333 - val_loss: 0.5254 - val_binary_accuracy: 0.7882\n",
      "Epoch 250/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.4378 - binary_accuracy: 0.8333 - val_loss: 0.5236 - val_binary_accuracy: 0.7882\n",
      "Epoch 251/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.4375 - binary_accuracy: 0.8333 - val_loss: 0.5257 - val_binary_accuracy: 0.7882\n",
      "Epoch 252/400\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.4375 - binary_accuracy: 0.8333 - val_loss: 0.5242 - val_binary_accuracy: 0.7882\n",
      "Epoch 253/400\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.4372 - binary_accuracy: 0.8333 - val_loss: 0.5259 - val_binary_accuracy: 0.7882\n",
      "Epoch 254/400\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.4372 - binary_accuracy: 0.8333 - val_loss: 0.5246 - val_binary_accuracy: 0.7882\n",
      "Epoch 255/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.4370 - binary_accuracy: 0.8333 - val_loss: 0.5261 - val_binary_accuracy: 0.7882\n",
      "Epoch 256/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.4371 - binary_accuracy: 0.8333 - val_loss: 0.5247 - val_binary_accuracy: 0.7882\n",
      "Epoch 257/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.4369 - binary_accuracy: 0.8333 - val_loss: 0.5263 - val_binary_accuracy: 0.7882\n",
      "Epoch 258/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.4370 - binary_accuracy: 0.8333 - val_loss: 0.5248 - val_binary_accuracy: 0.7882\n",
      "Epoch 259/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.4367 - binary_accuracy: 0.8333 - val_loss: 0.5264 - val_binary_accuracy: 0.7882\n",
      "Epoch 260/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.4368 - binary_accuracy: 0.8333 - val_loss: 0.5249 - val_binary_accuracy: 0.7882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 261/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4364 - binary_accuracy: 0.8333 - val_loss: 0.5265 - val_binary_accuracy: 0.7882\n",
      "Epoch 262/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.4357 - binary_accuracy: 0.8333 - val_loss: 0.5252 - val_binary_accuracy: 0.7882\n",
      "Epoch 263/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4338 - binary_accuracy: 0.8333 - val_loss: 0.5266 - val_binary_accuracy: 0.7882\n",
      "Epoch 264/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4325 - binary_accuracy: 0.8333 - val_loss: 0.5263 - val_binary_accuracy: 0.7882\n",
      "Epoch 265/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.4322 - binary_accuracy: 0.8333 - val_loss: 0.5270 - val_binary_accuracy: 0.7882\n",
      "Epoch 266/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4324 - binary_accuracy: 0.8333 - val_loss: 0.5261 - val_binary_accuracy: 0.7882\n",
      "Epoch 267/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.4323 - binary_accuracy: 0.8333 - val_loss: 0.5273 - val_binary_accuracy: 0.7882\n",
      "Epoch 268/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4329 - binary_accuracy: 0.8333 - val_loss: 0.5253 - val_binary_accuracy: 0.7882\n",
      "Epoch 269/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.4319 - binary_accuracy: 0.8333 - val_loss: 0.5273 - val_binary_accuracy: 0.7882\n",
      "Epoch 270/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4318 - binary_accuracy: 0.8333 - val_loss: 0.5271 - val_binary_accuracy: 0.7882\n",
      "Epoch 271/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4318 - binary_accuracy: 0.8333 - val_loss: 0.5272 - val_binary_accuracy: 0.7882\n",
      "Epoch 272/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.4317 - binary_accuracy: 0.8333 - val_loss: 0.5271 - val_binary_accuracy: 0.7882\n",
      "Epoch 273/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.4316 - binary_accuracy: 0.8333 - val_loss: 0.5271 - val_binary_accuracy: 0.7882\n",
      "Epoch 274/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4316 - binary_accuracy: 0.8333 - val_loss: 0.5269 - val_binary_accuracy: 0.7882\n",
      "Epoch 275/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4315 - binary_accuracy: 0.8333 - val_loss: 0.5271 - val_binary_accuracy: 0.7882\n",
      "Epoch 276/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4316 - binary_accuracy: 0.8333 - val_loss: 0.5265 - val_binary_accuracy: 0.7882\n",
      "Epoch 277/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.4317 - binary_accuracy: 0.8333 - val_loss: 0.5276 - val_binary_accuracy: 0.7882\n",
      "Epoch 278/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.4327 - binary_accuracy: 0.8333 - val_loss: 0.5247 - val_binary_accuracy: 0.7882\n",
      "Epoch 279/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.4313 - binary_accuracy: 0.8333 - val_loss: 0.5275 - val_binary_accuracy: 0.7882\n",
      "Epoch 280/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.4315 - binary_accuracy: 0.8333 - val_loss: 0.5281 - val_binary_accuracy: 0.7882\n",
      "Epoch 281/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.4322 - binary_accuracy: 0.8333 - val_loss: 0.5259 - val_binary_accuracy: 0.7882\n",
      "Epoch 282/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4311 - binary_accuracy: 0.8333 - val_loss: 0.5280 - val_binary_accuracy: 0.7882\n",
      "Epoch 283/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.4310 - binary_accuracy: 0.8333 - val_loss: 0.5281 - val_binary_accuracy: 0.7882\n",
      "Epoch 284/400\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.4311 - binary_accuracy: 0.8333 - val_loss: 0.5275 - val_binary_accuracy: 0.7882\n",
      "Epoch 285/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.4311 - binary_accuracy: 0.8333 - val_loss: 0.5283 - val_binary_accuracy: 0.7882\n",
      "Epoch 286/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.4315 - binary_accuracy: 0.8333 - val_loss: 0.5268 - val_binary_accuracy: 0.7882\n",
      "Epoch 287/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.4310 - binary_accuracy: 0.8333 - val_loss: 0.5285 - val_binary_accuracy: 0.7882\n",
      "Epoch 288/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4313 - binary_accuracy: 0.8333 - val_loss: 0.5271 - val_binary_accuracy: 0.7882\n",
      "Epoch 289/400\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.4309 - binary_accuracy: 0.8333 - val_loss: 0.5286 - val_binary_accuracy: 0.7882\n",
      "Epoch 290/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4310 - binary_accuracy: 0.8333 - val_loss: 0.5275 - val_binary_accuracy: 0.7882\n",
      "Epoch 291/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.4307 - binary_accuracy: 0.8333 - val_loss: 0.5287 - val_binary_accuracy: 0.7882\n",
      "Epoch 292/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.4310 - binary_accuracy: 0.8333 - val_loss: 0.5275 - val_binary_accuracy: 0.7882\n",
      "Epoch 293/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4306 - binary_accuracy: 0.8333 - val_loss: 0.5288 - val_binary_accuracy: 0.7882\n",
      "Epoch 294/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.4308 - binary_accuracy: 0.8333 - val_loss: 0.5276 - val_binary_accuracy: 0.7882\n",
      "Epoch 295/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.4305 - binary_accuracy: 0.8333 - val_loss: 0.5288 - val_binary_accuracy: 0.7882\n",
      "Epoch 296/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4307 - binary_accuracy: 0.8333 - val_loss: 0.5277 - val_binary_accuracy: 0.7882\n",
      "Epoch 297/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4304 - binary_accuracy: 0.8333 - val_loss: 0.5289 - val_binary_accuracy: 0.7882\n",
      "Epoch 298/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4305 - binary_accuracy: 0.8333 - val_loss: 0.5277 - val_binary_accuracy: 0.7882\n",
      "Epoch 299/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.4303 - binary_accuracy: 0.8333 - val_loss: 0.5289 - val_binary_accuracy: 0.7882\n",
      "Epoch 300/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.4304 - binary_accuracy: 0.8333 - val_loss: 0.5278 - val_binary_accuracy: 0.7882\n",
      "Epoch 301/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.4302 - binary_accuracy: 0.8333 - val_loss: 0.5289 - val_binary_accuracy: 0.7882\n",
      "Epoch 302/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4303 - binary_accuracy: 0.8333 - val_loss: 0.5278 - val_binary_accuracy: 0.7882\n",
      "Epoch 303/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.4301 - binary_accuracy: 0.8333 - val_loss: 0.5290 - val_binary_accuracy: 0.7882\n",
      "Epoch 304/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.4302 - binary_accuracy: 0.8333 - val_loss: 0.5278 - val_binary_accuracy: 0.7882\n",
      "Epoch 305/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.4299 - binary_accuracy: 0.8333 - val_loss: 0.5290 - val_binary_accuracy: 0.7882\n",
      "Epoch 306/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.4301 - binary_accuracy: 0.8333 - val_loss: 0.5278 - val_binary_accuracy: 0.7882\n",
      "Epoch 307/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.4298 - binary_accuracy: 0.8333 - val_loss: 0.5290 - val_binary_accuracy: 0.7882\n",
      "Epoch 308/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.4300 - binary_accuracy: 0.8333 - val_loss: 0.5279 - val_binary_accuracy: 0.7882\n",
      "Epoch 309/400\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.4297 - binary_accuracy: 0.8333 - val_loss: 0.5290 - val_binary_accuracy: 0.7882\n",
      "Epoch 310/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4298 - binary_accuracy: 0.8333 - val_loss: 0.5279 - val_binary_accuracy: 0.7882\n",
      "Epoch 311/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4296 - binary_accuracy: 0.8333 - val_loss: 0.5290 - val_binary_accuracy: 0.7882\n",
      "Epoch 312/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4297 - binary_accuracy: 0.8333 - val_loss: 0.5279 - val_binary_accuracy: 0.7882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 313/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.4295 - binary_accuracy: 0.8333 - val_loss: 0.5290 - val_binary_accuracy: 0.7882\n",
      "Epoch 314/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4296 - binary_accuracy: 0.8333 - val_loss: 0.5279 - val_binary_accuracy: 0.7882\n",
      "Epoch 315/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.4294 - binary_accuracy: 0.8333 - val_loss: 0.5290 - val_binary_accuracy: 0.7882\n",
      "Epoch 316/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.4295 - binary_accuracy: 0.8333 - val_loss: 0.5279 - val_binary_accuracy: 0.7882\n",
      "Epoch 317/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.4293 - binary_accuracy: 0.8333 - val_loss: 0.5290 - val_binary_accuracy: 0.7882\n",
      "Epoch 318/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.4294 - binary_accuracy: 0.8333 - val_loss: 0.5279 - val_binary_accuracy: 0.7882\n",
      "Epoch 319/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.4292 - binary_accuracy: 0.8333 - val_loss: 0.5289 - val_binary_accuracy: 0.7882\n",
      "Epoch 320/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4293 - binary_accuracy: 0.8333 - val_loss: 0.5279 - val_binary_accuracy: 0.7882\n",
      "Epoch 321/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.4290 - binary_accuracy: 0.8333 - val_loss: 0.5289 - val_binary_accuracy: 0.7882\n",
      "Epoch 322/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.4291 - binary_accuracy: 0.8333 - val_loss: 0.5279 - val_binary_accuracy: 0.7882\n",
      "Epoch 323/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.4289 - binary_accuracy: 0.8333 - val_loss: 0.5289 - val_binary_accuracy: 0.7882\n",
      "Epoch 324/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.4290 - binary_accuracy: 0.8333 - val_loss: 0.5279 - val_binary_accuracy: 0.7882\n",
      "Epoch 325/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.4288 - binary_accuracy: 0.8333 - val_loss: 0.5288 - val_binary_accuracy: 0.7882\n",
      "Epoch 326/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4289 - binary_accuracy: 0.8333 - val_loss: 0.5279 - val_binary_accuracy: 0.7882\n",
      "Epoch 327/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4287 - binary_accuracy: 0.8333 - val_loss: 0.5288 - val_binary_accuracy: 0.7882\n",
      "Epoch 328/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.4288 - binary_accuracy: 0.8333 - val_loss: 0.5279 - val_binary_accuracy: 0.7882\n",
      "Epoch 329/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.4286 - binary_accuracy: 0.8333 - val_loss: 0.5288 - val_binary_accuracy: 0.7882\n",
      "Epoch 330/400\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.4287 - binary_accuracy: 0.8333 - val_loss: 0.5279 - val_binary_accuracy: 0.7882\n",
      "Epoch 331/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.4285 - binary_accuracy: 0.8333 - val_loss: 0.5287 - val_binary_accuracy: 0.7882\n",
      "Epoch 332/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.4285 - binary_accuracy: 0.8333 - val_loss: 0.5278 - val_binary_accuracy: 0.7882\n",
      "Epoch 333/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4283 - binary_accuracy: 0.8333 - val_loss: 0.5287 - val_binary_accuracy: 0.7882\n",
      "Epoch 334/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.4284 - binary_accuracy: 0.8333 - val_loss: 0.5278 - val_binary_accuracy: 0.7882\n",
      "Epoch 335/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.4282 - binary_accuracy: 0.8333 - val_loss: 0.5286 - val_binary_accuracy: 0.7882\n",
      "Epoch 336/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.4283 - binary_accuracy: 0.8333 - val_loss: 0.5278 - val_binary_accuracy: 0.7882\n",
      "Epoch 337/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.4281 - binary_accuracy: 0.8333 - val_loss: 0.5286 - val_binary_accuracy: 0.7882\n",
      "Epoch 338/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4281 - binary_accuracy: 0.8333 - val_loss: 0.5277 - val_binary_accuracy: 0.7882\n",
      "Epoch 339/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.4280 - binary_accuracy: 0.8333 - val_loss: 0.5285 - val_binary_accuracy: 0.7882\n",
      "Epoch 340/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4280 - binary_accuracy: 0.8333 - val_loss: 0.5277 - val_binary_accuracy: 0.7882\n",
      "Epoch 341/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4278 - binary_accuracy: 0.8333 - val_loss: 0.5284 - val_binary_accuracy: 0.7882\n",
      "Epoch 342/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.4278 - binary_accuracy: 0.8333 - val_loss: 0.5277 - val_binary_accuracy: 0.7882\n",
      "Epoch 343/400\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.4276 - binary_accuracy: 0.8333 - val_loss: 0.5283 - val_binary_accuracy: 0.7882\n",
      "Epoch 344/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.4275 - binary_accuracy: 0.8333 - val_loss: 0.5277 - val_binary_accuracy: 0.7882\n",
      "Epoch 345/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.4274 - binary_accuracy: 0.8333 - val_loss: 0.5281 - val_binary_accuracy: 0.7882\n",
      "Epoch 346/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.4273 - binary_accuracy: 0.8333 - val_loss: 0.5277 - val_binary_accuracy: 0.7882\n",
      "Epoch 347/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.4272 - binary_accuracy: 0.8333 - val_loss: 0.5278 - val_binary_accuracy: 0.7882\n",
      "Epoch 348/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4272 - binary_accuracy: 0.8333 - val_loss: 0.5276 - val_binary_accuracy: 0.7882\n",
      "Epoch 349/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.4271 - binary_accuracy: 0.8333 - val_loss: 0.5276 - val_binary_accuracy: 0.7882\n",
      "Epoch 350/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4270 - binary_accuracy: 0.8333 - val_loss: 0.5274 - val_binary_accuracy: 0.7882\n",
      "Epoch 351/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4270 - binary_accuracy: 0.8333 - val_loss: 0.5274 - val_binary_accuracy: 0.7882\n",
      "Epoch 352/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4269 - binary_accuracy: 0.8333 - val_loss: 0.5273 - val_binary_accuracy: 0.7882\n",
      "Epoch 353/400\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.4268 - binary_accuracy: 0.8333 - val_loss: 0.5271 - val_binary_accuracy: 0.7882\n",
      "Epoch 354/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.4268 - binary_accuracy: 0.8333 - val_loss: 0.5270 - val_binary_accuracy: 0.7882\n",
      "Epoch 355/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4267 - binary_accuracy: 0.8333 - val_loss: 0.5269 - val_binary_accuracy: 0.7882\n",
      "Epoch 356/400\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.4267 - binary_accuracy: 0.8333 - val_loss: 0.5268 - val_binary_accuracy: 0.7882\n",
      "Epoch 357/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.4266 - binary_accuracy: 0.8333 - val_loss: 0.5267 - val_binary_accuracy: 0.7882\n",
      "Epoch 358/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.4265 - binary_accuracy: 0.8333 - val_loss: 0.5266 - val_binary_accuracy: 0.7882\n",
      "Epoch 359/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.4265 - binary_accuracy: 0.8333 - val_loss: 0.5265 - val_binary_accuracy: 0.7882\n",
      "Epoch 360/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.4264 - binary_accuracy: 0.8365 - val_loss: 0.5264 - val_binary_accuracy: 0.7882\n",
      "Epoch 361/400\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.4263 - binary_accuracy: 0.8365 - val_loss: 0.5264 - val_binary_accuracy: 0.7882\n",
      "Epoch 362/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4263 - binary_accuracy: 0.8365 - val_loss: 0.5263 - val_binary_accuracy: 0.7882\n",
      "Epoch 363/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.4262 - binary_accuracy: 0.8365 - val_loss: 0.5262 - val_binary_accuracy: 0.7882\n",
      "Epoch 364/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4261 - binary_accuracy: 0.8365 - val_loss: 0.5261 - val_binary_accuracy: 0.7882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 365/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.4261 - binary_accuracy: 0.8365 - val_loss: 0.5260 - val_binary_accuracy: 0.7882\n",
      "Epoch 366/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.4260 - binary_accuracy: 0.8365 - val_loss: 0.5259 - val_binary_accuracy: 0.7882\n",
      "Epoch 367/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4260 - binary_accuracy: 0.8365 - val_loss: 0.5258 - val_binary_accuracy: 0.7882\n",
      "Epoch 368/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.4259 - binary_accuracy: 0.8365 - val_loss: 0.5258 - val_binary_accuracy: 0.7882\n",
      "Epoch 369/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.4258 - binary_accuracy: 0.8365 - val_loss: 0.5257 - val_binary_accuracy: 0.7882\n",
      "Epoch 370/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.4258 - binary_accuracy: 0.8365 - val_loss: 0.5256 - val_binary_accuracy: 0.7882\n",
      "Epoch 371/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.4257 - binary_accuracy: 0.8365 - val_loss: 0.5255 - val_binary_accuracy: 0.7882\n",
      "Epoch 372/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.4257 - binary_accuracy: 0.8365 - val_loss: 0.5255 - val_binary_accuracy: 0.7882\n",
      "Epoch 373/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.4257 - binary_accuracy: 0.8396 - val_loss: 0.5253 - val_binary_accuracy: 0.7882\n",
      "Epoch 374/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.4258 - binary_accuracy: 0.8365 - val_loss: 0.5255 - val_binary_accuracy: 0.7882\n",
      "Epoch 375/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4262 - binary_accuracy: 0.8396 - val_loss: 0.5250 - val_binary_accuracy: 0.7882\n",
      "Epoch 376/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4288 - binary_accuracy: 0.8365 - val_loss: 0.5278 - val_binary_accuracy: 0.7882\n",
      "Epoch 377/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4290 - binary_accuracy: 0.8365 - val_loss: 0.5273 - val_binary_accuracy: 0.7882\n",
      "Epoch 378/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.4258 - binary_accuracy: 0.8396 - val_loss: 0.5261 - val_binary_accuracy: 0.7882\n",
      "Epoch 379/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.4322 - binary_accuracy: 0.8302 - val_loss: 0.5235 - val_binary_accuracy: 0.7882\n",
      "Epoch 380/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.4328 - binary_accuracy: 0.8302 - val_loss: 0.5294 - val_binary_accuracy: 0.7882\n",
      "Epoch 381/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4285 - binary_accuracy: 0.8428 - val_loss: 0.5262 - val_binary_accuracy: 0.7882\n",
      "Epoch 382/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.4278 - binary_accuracy: 0.8365 - val_loss: 0.5286 - val_binary_accuracy: 0.7882\n",
      "Epoch 383/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.4293 - binary_accuracy: 0.8396 - val_loss: 0.5238 - val_binary_accuracy: 0.7882\n",
      "Epoch 384/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.4314 - binary_accuracy: 0.8396 - val_loss: 0.5239 - val_binary_accuracy: 0.7882\n",
      "Epoch 385/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4290 - binary_accuracy: 0.8396 - val_loss: 0.5292 - val_binary_accuracy: 0.7882\n",
      "Epoch 386/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.4260 - binary_accuracy: 0.8365 - val_loss: 0.5294 - val_binary_accuracy: 0.7882\n",
      "Epoch 387/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.4261 - binary_accuracy: 0.8365 - val_loss: 0.5295 - val_binary_accuracy: 0.7882\n",
      "Epoch 388/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.4253 - binary_accuracy: 0.8396 - val_loss: 0.5290 - val_binary_accuracy: 0.7882\n",
      "Epoch 389/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.4253 - binary_accuracy: 0.8365 - val_loss: 0.5293 - val_binary_accuracy: 0.7882\n",
      "Epoch 390/400\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.4250 - binary_accuracy: 0.8365 - val_loss: 0.5292 - val_binary_accuracy: 0.7882\n",
      "Epoch 391/400\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.4222 - binary_accuracy: 0.839 - 0s 17ms/step - loss: 0.4250 - binary_accuracy: 0.8396 - val_loss: 0.5290 - val_binary_accuracy: 0.7882\n",
      "Epoch 392/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.4249 - binary_accuracy: 0.8396 - val_loss: 0.5290 - val_binary_accuracy: 0.7882\n",
      "Epoch 393/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4248 - binary_accuracy: 0.8396 - val_loss: 0.5289 - val_binary_accuracy: 0.7882\n",
      "Epoch 394/400\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.4248 - binary_accuracy: 0.8396 - val_loss: 0.5288 - val_binary_accuracy: 0.7882\n",
      "Epoch 395/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.4247 - binary_accuracy: 0.8396 - val_loss: 0.5287 - val_binary_accuracy: 0.7882\n",
      "Epoch 396/400\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.4247 - binary_accuracy: 0.8396 - val_loss: 0.5286 - val_binary_accuracy: 0.7882\n",
      "Epoch 397/400\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.4246 - binary_accuracy: 0.8396 - val_loss: 0.5285 - val_binary_accuracy: 0.7882\n",
      "Epoch 398/400\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.4246 - binary_accuracy: 0.8396 - val_loss: 0.5284 - val_binary_accuracy: 0.7882\n",
      "Epoch 399/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.4245 - binary_accuracy: 0.8396 - val_loss: 0.5283 - val_binary_accuracy: 0.7882\n",
      "Epoch 400/400\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.4244 - binary_accuracy: 0.8396 - val_loss: 0.5283 - val_binary_accuracy: 0.7882\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x_train, binary_y_train,\n",
    "    batch_size=28,\n",
    "    epochs=400,\n",
    "    validation_data = (x_val, binary_y_val),\n",
    "    shuffle=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78a152b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5418 - binary_accuracy: 0.7143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5417856574058533, 0.7142857313156128]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = model.predict(x_test)\n",
    "predictions = (preds>0.5)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(range(len(predictions)),predictions, c='r')\n",
    "plt.scatter(range(len(binary_y_test)), binary_y_test, c='b')\n",
    "\n",
    "model.evaluate(x_test, binary_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c98e9206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['val_loss'])\n",
    "plt.plot(history.history['val_binary_accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8a1281",
   "metadata": {},
   "source": [
    "# Kerastuner to determine how many hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d1840d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(hp.Int('units', 8, 64, 4, default=8), \n",
    "                   return_sequences=True, \n",
    "                   input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "    \n",
    "    #determine if we want any hidden layers to increase accuracies\n",
    "    for i in range(hp.Int(\"No. of hidden layers\", min_value=0, max_value=3)):\n",
    "        model.add(LSTM(hp.Int('hidden nodes', 8, 64, 4, default=8), \n",
    "                       return_sequences=True)) #return sequences set to true will return a 3D tensor which allows the network to be stacked\n",
    "        model.add(Dropout(0.2))\n",
    "        \n",
    "    model.add(LSTM(50, return_sequences=False))\n",
    "\n",
    "    #include dropout layers\n",
    "    model.add(Dropout(hp.Float(\n",
    "                    'dropout',\n",
    "                    min_value=0.1,\n",
    "                    max_value=0.8,\n",
    "                    step=0.1)))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e44cf79c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project C://Users//TeyK//Desktop//EQ major down prediction\\EQ Major Down using KT\\oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from C://Users//TeyK//Desktop//EQ major down prediction\\EQ Major Down using KT\\tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.RandomSearch(build_model,\n",
    "                     objective='val_binary_accuracy',\n",
    "                     max_trials=3,\n",
    "                     directory='C://Users//TeyK//Desktop//EQ major down prediction',\n",
    "                     project_name='EQ Major Down using KT')\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_binary_accuracy', patience=5)\n",
    "\n",
    "#each model will be trained for 30 epochs and 2 iterations of hyperband search will be run\n",
    "#model will stop training when callbacks condition is reached to speed up the training process\n",
    "tuner.search(x_train, binary_y_train, epochs=30, validation_data=(x_val, binary_y_val), callbacks=[stop_early]) \n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f2c9536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 28, 56)            17024     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 50)                21400     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 38,475\n",
      "Trainable params: 38,475\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ae5d17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "10/10 [==============================] - 8s 240ms/step - loss: 0.6151 - binary_accuracy: 0.6824 - val_loss: 0.5445 - val_binary_accuracy: 0.7882\n",
      "Epoch 2/30\n",
      "10/10 [==============================] - 0s 37ms/step - loss: 0.4920 - binary_accuracy: 0.8333 - val_loss: 0.5602 - val_binary_accuracy: 0.7882\n",
      "Epoch 3/30\n",
      "10/10 [==============================] - 0s 46ms/step - loss: 0.4731 - binary_accuracy: 0.8333 - val_loss: 0.5479 - val_binary_accuracy: 0.7882\n",
      "Epoch 4/30\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 0.4588 - binary_accuracy: 0.8333 - val_loss: 0.5401 - val_binary_accuracy: 0.7882\n",
      "Epoch 5/30\n",
      "10/10 [==============================] - 1s 58ms/step - loss: 0.4697 - binary_accuracy: 0.8302 - val_loss: 0.5352 - val_binary_accuracy: 0.7882\n",
      "Epoch 6/30\n",
      "10/10 [==============================] - 0s 50ms/step - loss: 0.4620 - binary_accuracy: 0.8302 - val_loss: 0.5336 - val_binary_accuracy: 0.7882\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = best_model.fit(x_train, binary_y_train, epochs=30, \n",
    "                         validation_data=(x_val, binary_y_val), callbacks =[stop_early])\n",
    "\n",
    "\n",
    "fig, (ax1, ax2)= plt.subplots(2)\n",
    "ax1.plot(history.history['binary_accuracy'], 'b-')\n",
    "ax1.plot(history.history['val_binary_accuracy'], 'r-')\n",
    "ax1.set_title('Accuracy')\n",
    "\n",
    "ax2.plot(history.history['loss'], 'b-')\n",
    "ax2.plot(history.history['val_loss'], 'r-')\n",
    "ax2.set_title('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54051ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6446 - binary_accuracy: 0.7143\n",
      "[test loss, test binary accuracy]: [0.644554853439331, 0.7142857313156128]\n"
     ]
    }
   ],
   "source": [
    "eval_result = best_model.evaluate(x_test, binary_y_test)\n",
    "print(\"[test loss, test binary accuracy]:\", eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04483b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TeyK\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7142857142857143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTM_preds = best_model.predict_classes(x_test)\n",
    "print(len([ele for ele in y_test if ele ==0])/len(LSTM_preds))\n",
    "\n",
    "LSTM_preds = np.reshape(LSTM_preds, (LSTM_preds.shape[0],))\n",
    "LSTM_preds, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe79def",
   "metadata": {},
   "source": [
    "# Conv 1D layer to recognize sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b1b7fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### first find out what parameters to use using keras tuner\n",
    "def make_model(hp):\n",
    "    num_layers = hp.Int(\"num_layers\", 1, 3)\n",
    "    lr = hp.Choice(\"learning_rate\", [1e-3, 5e-4])\n",
    "    inputs = Input(shape=(x_train.shape[1:])) #input_shape =(batch size, timestamp, no. of features)\n",
    "    x=inputs\n",
    "    \n",
    "    for idx in range(num_layers):\n",
    "        idx = str(idx)\n",
    "\n",
    "        filters = hp.Int(\"filters_\" + idx, 32, 256, step=32, default=64)\n",
    "        x = Conv1D(filters=filters, kernel_size=3, padding=\"same\", activation=\"relu\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        \n",
    "    gap = keras.layers.GlobalAveragePooling1D()(x)\n",
    "    output_layer = Dense(1, activation=\"sigmoid\")(gap)\n",
    "    \n",
    "    model = keras.Model(inputs, output_layer)\n",
    "    model.compile(optimizer=optimizers.Adam(lr), loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa79bf18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project .\\Conv1D tuner search\\oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from .\\Conv1D tuner search\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.RandomSearch(\n",
    "            make_model,\n",
    "            objective='val_binary_accuracy',\n",
    "            max_trials = 3,\n",
    "            project_name='Conv1D tuner search'\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23a9af47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n",
      "Results summary\n",
      "Results in .\\Conv1D tuner search\n",
      "Showing 10 best trials\n",
      "Objective(name='val_binary_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 3\n",
      "learning_rate: 0.001\n",
      "filters_0: 64\n",
      "filters_1: 224\n",
      "filters_2: 64\n",
      "Score: 0.800000011920929\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 2\n",
      "learning_rate: 0.0005\n",
      "filters_0: 160\n",
      "filters_1: 64\n",
      "Score: 0.800000011920929\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 3\n",
      "learning_rate: 0.0005\n",
      "filters_0: 32\n",
      "filters_1: 64\n",
      "filters_2: 64\n",
      "Score: 0.7882353067398071\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 30\n",
    "stopearly = EarlyStopping(monitor=\"val_loss\", patience=50, verbose=1)\n",
    "checkpoint = ModelCheckpoint(\"best_model.h5\", save_best_only=True, monitor=\"val_loss\")\n",
    "\n",
    "tuner.search(x_train, binary_y_train, batch_size = BATCH_SIZE, epochs = EPOCHS, validation_data=(x_val, binary_y_val), callbacks=[checkpoint, stopearly])\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d774254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 19)]          0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 28, 160)           9280      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 28, 160)           640       \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 28, 64)            30784     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 28, 64)            256       \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 41,025\n",
      "Trainable params: 40,577\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model = load_model('best_model.h5')\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51863084",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "10/10 [==============================] - 2s 61ms/step - loss: 0.3733 - binary_accuracy: 0.8648 - val_loss: 0.5527 - val_binary_accuracy: 0.7882\n",
      "Epoch 2/30\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3718 - binary_accuracy: 0.8616 - val_loss: 0.5523 - val_binary_accuracy: 0.7882\n",
      "Epoch 3/30\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.3651 - binary_accuracy: 0.8679 - val_loss: 0.5532 - val_binary_accuracy: 0.7882\n",
      "Epoch 4/30\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.3540 - binary_accuracy: 0.8836 - val_loss: 0.5719 - val_binary_accuracy: 0.7882\n",
      "Epoch 5/30\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.3446 - binary_accuracy: 0.8742 - val_loss: 0.5517 - val_binary_accuracy: 0.7882\n",
      "Epoch 6/30\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3427 - binary_accuracy: 0.8648 - val_loss: 0.5660 - val_binary_accuracy: 0.7882\n",
      "Epoch 7/30\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.3381 - binary_accuracy: 0.8648 - val_loss: 0.5779 - val_binary_accuracy: 0.7882\n",
      "Epoch 8/30\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.3277 - binary_accuracy: 0.8711 - val_loss: 0.5643 - val_binary_accuracy: 0.7882\n",
      "Epoch 9/30\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.3255 - binary_accuracy: 0.8679 - val_loss: 0.5981 - val_binary_accuracy: 0.7882\n",
      "Epoch 10/30\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.3237 - binary_accuracy: 0.8648 - val_loss: 0.5985 - val_binary_accuracy: 0.7882\n",
      "Epoch 11/30\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.3240 - binary_accuracy: 0.8711 - val_loss: 0.5682 - val_binary_accuracy: 0.7882\n",
      "Epoch 12/30\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.3101 - binary_accuracy: 0.8742 - val_loss: 0.6130 - val_binary_accuracy: 0.7882\n",
      "Epoch 13/30\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.3136 - binary_accuracy: 0.8805 - val_loss: 0.5868 - val_binary_accuracy: 0.7882\n",
      "Epoch 14/30\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3080 - binary_accuracy: 0.8836 - val_loss: 0.5962 - val_binary_accuracy: 0.7882\n",
      "Epoch 15/30\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.3165 - binary_accuracy: 0.8742 - val_loss: 0.6022 - val_binary_accuracy: 0.7882\n",
      "Epoch 16/30\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.3090 - binary_accuracy: 0.8742 - val_loss: 0.6014 - val_binary_accuracy: 0.7882\n",
      "Epoch 17/30\n",
      "10/10 [==============================] - 0s 36ms/step - loss: 0.3164 - binary_accuracy: 0.8742 - val_loss: 0.6222 - val_binary_accuracy: 0.7882\n",
      "Epoch 18/30\n",
      "10/10 [==============================] - 0s 37ms/step - loss: 0.2987 - binary_accuracy: 0.8868 - val_loss: 0.6294 - val_binary_accuracy: 0.7529\n",
      "Epoch 19/30\n",
      "10/10 [==============================] - 0s 33ms/step - loss: 0.3231 - binary_accuracy: 0.8742 - val_loss: 0.6446 - val_binary_accuracy: 0.7882\n",
      "Epoch 20/30\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.3035 - binary_accuracy: 0.8679 - val_loss: 0.6157 - val_binary_accuracy: 0.7529\n",
      "Epoch 21/30\n",
      "10/10 [==============================] - 0s 39ms/step - loss: 0.3011 - binary_accuracy: 0.8805 - val_loss: 0.6247 - val_binary_accuracy: 0.7882\n",
      "Epoch 22/30\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.3012 - binary_accuracy: 0.8742 - val_loss: 0.6186 - val_binary_accuracy: 0.7882\n",
      "Epoch 23/30\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.3024 - binary_accuracy: 0.8711 - val_loss: 0.6120 - val_binary_accuracy: 0.7882\n",
      "Epoch 24/30\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2913 - binary_accuracy: 0.8774 - val_loss: 0.6313 - val_binary_accuracy: 0.7882\n",
      "Epoch 25/30\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.2848 - binary_accuracy: 0.8805 - val_loss: 0.6306 - val_binary_accuracy: 0.7882\n",
      "Epoch 26/30\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.2840 - binary_accuracy: 0.8836 - val_loss: 0.6527 - val_binary_accuracy: 0.7529\n",
      "Epoch 27/30\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2910 - binary_accuracy: 0.8711 - val_loss: 0.6368 - val_binary_accuracy: 0.7882\n",
      "Epoch 28/30\n",
      "10/10 [==============================] - 0s 42ms/step - loss: 0.2785 - binary_accuracy: 0.8836 - val_loss: 0.7528 - val_binary_accuracy: 0.6353\n",
      "Epoch 29/30\n",
      "10/10 [==============================] - 0s 33ms/step - loss: 0.2848 - binary_accuracy: 0.8931 - val_loss: 0.6578 - val_binary_accuracy: 0.7412\n",
      "Epoch 30/30\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.2708 - binary_accuracy: 0.8836 - val_loss: 0.7288 - val_binary_accuracy: 0.6353\n"
     ]
    }
   ],
   "source": [
    "history = best_model.fit(x_train, binary_y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, \n",
    "                         validation_data=(x_val,binary_y_val), callbacks=[checkpoint, stopearly])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b608a523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2)= plt.subplots(2)\n",
    "ax1.plot(history.history['binary_accuracy'], 'b-')\n",
    "ax1.plot(history.history['val_binary_accuracy'], 'r-')\n",
    "ax1.set_title('Accuracy')\n",
    "\n",
    "ax2.plot(history.history['loss'], 'b-')\n",
    "ax2.plot(history.history['val_loss'], 'r-')\n",
    "ax2.set_title('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "baf36622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8487 - binary_accuracy: 0.7143\n",
      "Test loss:  0.8487259745597839  Test acc:  0.7142857313156128\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = best_model.evaluate(x_test, binary_y_test)\n",
    "print(\"Test loss: \", test_loss, \" Test acc: \", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "784b36ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7142857142857143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONV1D_preds = best_model.predict(x_test)\n",
    "new_CONV1D_preds = (CONV1D_preds > 0.5).astype('int32')\n",
    "print(len([ele for ele in y_test if ele ==0])/len(new_CONV1D_preds))\n",
    "\n",
    "new_CONV1D_preds = np.reshape(new_CONV1D_preds, (new_CONV1D_preds.shape[0],))\n",
    "new_CONV1D_preds, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48a41e9",
   "metadata": {},
   "source": [
    "# Predict using CNN (ignore sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "42a1c8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 313, 1: 313})\n",
      "Counter({1: 257, 0: 243})\n"
     ]
    }
   ],
   "source": [
    "data = res2.drop(['Input_Time_Window_Start', 'Input_Time_Window_End', \n",
    "                  'Target_Time_Window_Start', 'Target_Time_Window_End', 'NoMajorDown'], axis=1)\n",
    "target = convert_to_binary(res2['NoMajorDown'])\n",
    "\n",
    "TEST_SPLIT = 0.1 \n",
    "VAL_SPLIT = 0.2\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, target, test_size=TEST_SPLIT, random_state=42)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "x_train, y_train = sm.fit_resample(x_train, y_train)\n",
    "print(Counter(y_train))\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=VAL_SPLIT, random_state=42)\n",
    "print(Counter(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "be5952f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, x_test = np.array(x_train), np.array(x_val), np.array(x_test)\n",
    "y_train, y_val, y_test = np.array(y_train), np.array(y_val), np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c3d6729a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(hp.Int('Input neurons',32,256,32), activation='relu', \n",
    "                    input_shape=(x_train.shape[1],)))\n",
    "    \n",
    "    for i in range(hp.Int(\"No. hidden layers\", 0,3)):\n",
    "        model.add(Dense(hp.Int('Input neurons',32,256,32), activation='relu'))\n",
    "    \n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "                  \n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "79d1df53",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.RandomSearch(build_model,\n",
    "                     objective='val_binary_accuracy',\n",
    "                     max_trials=3,\n",
    "                     directory='C://Users//TeyK//Desktop//EQ major down prediction',\n",
    "                     project_name='Dense Classification')\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_binary_accuracy', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7b81ea55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 Complete [00h 00m 16s]\n",
      "val_binary_accuracy: 0.7777777910232544\n",
      "\n",
      "Best val_binary_accuracy So Far: 0.8015872836112976\n",
      "Total elapsed time: 00h 00m 53s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Results summary\n",
      "Results in C://Users//TeyK//Desktop//EQ major down prediction\\Dense Classification\n",
      "Showing 10 best trials\n",
      "Objective(name='val_binary_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "Input neurons: 160\n",
      "No. hidden layers: 0\n",
      "Score: 0.8015872836112976\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "Input neurons: 32\n",
      "No. hidden layers: 1\n",
      "Score: 0.7777777910232544\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "Input neurons: 128\n",
      "No. hidden layers: 0\n",
      "Score: 0.738095223903656\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100\n",
    "stopearly = EarlyStopping(monitor=\"val_loss\", patience=50, verbose=1)\n",
    "checkpoint = ModelCheckpoint(\"best_dense_model.h5\", save_best_only=True, monitor=\"val_loss\")\n",
    "\n",
    "tuner.search(x_train, y_train, batch_size = BATCH_SIZE, epochs = EPOCHS, validation_data=(x_val, y_val), callbacks=[checkpoint, stopearly])\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8217cdf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "16/16 [==============================] - 1s 14ms/step - loss: 0.4065 - binary_accuracy: 0.7840 - val_loss: 0.5046 - val_binary_accuracy: 0.7460\n",
      "Epoch 2/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3940 - binary_accuracy: 0.8200 - val_loss: 0.5016 - val_binary_accuracy: 0.7619\n",
      "Epoch 3/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3922 - binary_accuracy: 0.8220 - val_loss: 0.5203 - val_binary_accuracy: 0.7540\n",
      "Epoch 4/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3982 - binary_accuracy: 0.8180 - val_loss: 0.4999 - val_binary_accuracy: 0.7540\n",
      "Epoch 5/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4066 - binary_accuracy: 0.8080 - val_loss: 0.5205 - val_binary_accuracy: 0.7619\n",
      "Epoch 6/400\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4264 - binary_accuracy: 0.8020 - val_loss: 0.4908 - val_binary_accuracy: 0.7540\n",
      "Epoch 7/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4269 - binary_accuracy: 0.7820 - val_loss: 0.5290 - val_binary_accuracy: 0.7302\n",
      "Epoch 8/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4138 - binary_accuracy: 0.8120 - val_loss: 0.5402 - val_binary_accuracy: 0.7222\n",
      "Epoch 9/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4124 - binary_accuracy: 0.8020 - val_loss: 0.5374 - val_binary_accuracy: 0.7302\n",
      "Epoch 10/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3887 - binary_accuracy: 0.8140 - val_loss: 0.5005 - val_binary_accuracy: 0.7222\n",
      "Epoch 11/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3785 - binary_accuracy: 0.8120 - val_loss: 0.4981 - val_binary_accuracy: 0.7619\n",
      "Epoch 12/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4090 - binary_accuracy: 0.8000 - val_loss: 0.4929 - val_binary_accuracy: 0.7302\n",
      "Epoch 13/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4042 - binary_accuracy: 0.7980 - val_loss: 0.5298 - val_binary_accuracy: 0.6905\n",
      "Epoch 14/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4255 - binary_accuracy: 0.7880 - val_loss: 0.5408 - val_binary_accuracy: 0.7619\n",
      "Epoch 15/400\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3719 - binary_accuracy: 0.8120 - val_loss: 0.5242 - val_binary_accuracy: 0.7381\n",
      "Epoch 16/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4075 - binary_accuracy: 0.7840 - val_loss: 0.5415 - val_binary_accuracy: 0.7381\n",
      "Epoch 17/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3764 - binary_accuracy: 0.8160 - val_loss: 0.4846 - val_binary_accuracy: 0.7778\n",
      "Epoch 18/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3742 - binary_accuracy: 0.8280 - val_loss: 0.5193 - val_binary_accuracy: 0.7460\n",
      "Epoch 19/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3901 - binary_accuracy: 0.8120 - val_loss: 0.5209 - val_binary_accuracy: 0.7302\n",
      "Epoch 20/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3916 - binary_accuracy: 0.8180 - val_loss: 0.5113 - val_binary_accuracy: 0.7540\n",
      "Epoch 21/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4000 - binary_accuracy: 0.8020 - val_loss: 0.5273 - val_binary_accuracy: 0.7302\n",
      "Epoch 22/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3950 - binary_accuracy: 0.7980 - val_loss: 0.5069 - val_binary_accuracy: 0.7460\n",
      "Epoch 23/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3891 - binary_accuracy: 0.8160 - val_loss: 0.5101 - val_binary_accuracy: 0.7540\n",
      "Epoch 24/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3708 - binary_accuracy: 0.8220 - val_loss: 0.5236 - val_binary_accuracy: 0.7063\n",
      "Epoch 25/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3872 - binary_accuracy: 0.8020 - val_loss: 0.4744 - val_binary_accuracy: 0.7460\n",
      "Epoch 26/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3897 - binary_accuracy: 0.8100 - val_loss: 0.4843 - val_binary_accuracy: 0.7698\n",
      "Epoch 27/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3546 - binary_accuracy: 0.8340 - val_loss: 0.5129 - val_binary_accuracy: 0.7302\n",
      "Epoch 28/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3723 - binary_accuracy: 0.8300 - val_loss: 0.5148 - val_binary_accuracy: 0.7540\n",
      "Epoch 29/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3806 - binary_accuracy: 0.8320 - val_loss: 0.4941 - val_binary_accuracy: 0.7698\n",
      "Epoch 30/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3595 - binary_accuracy: 0.8580 - val_loss: 0.4909 - val_binary_accuracy: 0.7381\n",
      "Epoch 31/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3864 - binary_accuracy: 0.8220 - val_loss: 0.4943 - val_binary_accuracy: 0.7619\n",
      "Epoch 32/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3854 - binary_accuracy: 0.8200 - val_loss: 0.4928 - val_binary_accuracy: 0.7143\n",
      "Epoch 33/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3531 - binary_accuracy: 0.8200 - val_loss: 0.4897 - val_binary_accuracy: 0.7460\n",
      "Epoch 34/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3582 - binary_accuracy: 0.8400 - val_loss: 0.5009 - val_binary_accuracy: 0.7698\n",
      "Epoch 35/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3663 - binary_accuracy: 0.8420 - val_loss: 0.4856 - val_binary_accuracy: 0.7698\n",
      "Epoch 36/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3498 - binary_accuracy: 0.8400 - val_loss: 0.5432 - val_binary_accuracy: 0.7381\n",
      "Epoch 37/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3730 - binary_accuracy: 0.8200 - val_loss: 0.5221 - val_binary_accuracy: 0.7540\n",
      "Epoch 38/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3740 - binary_accuracy: 0.8100 - val_loss: 0.4801 - val_binary_accuracy: 0.7381\n",
      "Epoch 39/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3759 - binary_accuracy: 0.8120 - val_loss: 0.5217 - val_binary_accuracy: 0.7460\n",
      "Epoch 40/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3665 - binary_accuracy: 0.8160 - val_loss: 0.5120 - val_binary_accuracy: 0.7460\n",
      "Epoch 41/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3859 - binary_accuracy: 0.8240 - val_loss: 0.4898 - val_binary_accuracy: 0.7302\n",
      "Epoch 42/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3707 - binary_accuracy: 0.8160 - val_loss: 0.4668 - val_binary_accuracy: 0.7698\n",
      "Epoch 43/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3790 - binary_accuracy: 0.8060 - val_loss: 0.5159 - val_binary_accuracy: 0.7698\n",
      "Epoch 44/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3766 - binary_accuracy: 0.8220 - val_loss: 0.5241 - val_binary_accuracy: 0.7222\n",
      "Epoch 45/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3660 - binary_accuracy: 0.8340 - val_loss: 0.4843 - val_binary_accuracy: 0.7302\n",
      "Epoch 46/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3738 - binary_accuracy: 0.8260 - val_loss: 0.4672 - val_binary_accuracy: 0.7698\n",
      "Epoch 47/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3569 - binary_accuracy: 0.8200 - val_loss: 0.4844 - val_binary_accuracy: 0.7698\n",
      "Epoch 48/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3614 - binary_accuracy: 0.8160 - val_loss: 0.4630 - val_binary_accuracy: 0.7381\n",
      "Epoch 49/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3749 - binary_accuracy: 0.8340 - val_loss: 0.5376 - val_binary_accuracy: 0.7381\n",
      "Epoch 50/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4090 - binary_accuracy: 0.8060 - val_loss: 0.4717 - val_binary_accuracy: 0.7619\n",
      "Epoch 51/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3970 - binary_accuracy: 0.8060 - val_loss: 0.4582 - val_binary_accuracy: 0.7857\n",
      "Epoch 52/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3778 - binary_accuracy: 0.8280 - val_loss: 0.4743 - val_binary_accuracy: 0.7540\n",
      "Epoch 53/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3958 - binary_accuracy: 0.8080 - val_loss: 0.4776 - val_binary_accuracy: 0.7619\n",
      "Epoch 54/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3470 - binary_accuracy: 0.8360 - val_loss: 0.4902 - val_binary_accuracy: 0.7222\n",
      "Epoch 55/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3396 - binary_accuracy: 0.8380 - val_loss: 0.5027 - val_binary_accuracy: 0.7698\n",
      "Epoch 56/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3405 - binary_accuracy: 0.8380 - val_loss: 0.5012 - val_binary_accuracy: 0.7778\n",
      "Epoch 57/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3401 - binary_accuracy: 0.8460 - val_loss: 0.5136 - val_binary_accuracy: 0.7698\n",
      "Epoch 58/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3575 - binary_accuracy: 0.8320 - val_loss: 0.4914 - val_binary_accuracy: 0.7698\n",
      "Epoch 59/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3377 - binary_accuracy: 0.8560 - val_loss: 0.5040 - val_binary_accuracy: 0.7540\n",
      "Epoch 60/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3623 - binary_accuracy: 0.8360 - val_loss: 0.4989 - val_binary_accuracy: 0.7698\n",
      "Epoch 61/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3291 - binary_accuracy: 0.8600 - val_loss: 0.5268 - val_binary_accuracy: 0.7778\n",
      "Epoch 62/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3575 - binary_accuracy: 0.8280 - val_loss: 0.5230 - val_binary_accuracy: 0.7619\n",
      "Epoch 63/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3444 - binary_accuracy: 0.8620 - val_loss: 0.4559 - val_binary_accuracy: 0.7857\n",
      "Epoch 64/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3470 - binary_accuracy: 0.8200 - val_loss: 0.4914 - val_binary_accuracy: 0.7540\n",
      "Epoch 65/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3434 - binary_accuracy: 0.8220 - val_loss: 0.5098 - val_binary_accuracy: 0.7381\n",
      "Epoch 66/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3336 - binary_accuracy: 0.8400 - val_loss: 0.4896 - val_binary_accuracy: 0.7619\n",
      "Epoch 67/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3274 - binary_accuracy: 0.8460 - val_loss: 0.4734 - val_binary_accuracy: 0.8016\n",
      "Epoch 68/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3194 - binary_accuracy: 0.8560 - val_loss: 0.4713 - val_binary_accuracy: 0.7460\n",
      "Epoch 69/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3142 - binary_accuracy: 0.8580 - val_loss: 0.4993 - val_binary_accuracy: 0.7778\n",
      "Epoch 70/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3450 - binary_accuracy: 0.8360 - val_loss: 0.5036 - val_binary_accuracy: 0.7619\n",
      "Epoch 71/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3577 - binary_accuracy: 0.8260 - val_loss: 0.4621 - val_binary_accuracy: 0.7778\n",
      "Epoch 72/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3572 - binary_accuracy: 0.8420 - val_loss: 0.4932 - val_binary_accuracy: 0.7540\n",
      "Epoch 73/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3975 - binary_accuracy: 0.8120 - val_loss: 0.4978 - val_binary_accuracy: 0.7381\n",
      "Epoch 74/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3566 - binary_accuracy: 0.8480 - val_loss: 0.5293 - val_binary_accuracy: 0.7460\n",
      "Epoch 75/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3801 - binary_accuracy: 0.8200 - val_loss: 0.4576 - val_binary_accuracy: 0.7540\n",
      "Epoch 76/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3496 - binary_accuracy: 0.8320 - val_loss: 0.4895 - val_binary_accuracy: 0.7778\n",
      "Epoch 77/400\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3506 - binary_accuracy: 0.8560 - val_loss: 0.4826 - val_binary_accuracy: 0.7619\n",
      "Epoch 78/400\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3199 - binary_accuracy: 0.8600 - val_loss: 0.4870 - val_binary_accuracy: 0.7619\n",
      "Epoch 79/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3439 - binary_accuracy: 0.8540 - val_loss: 0.4831 - val_binary_accuracy: 0.7619\n",
      "Epoch 80/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3304 - binary_accuracy: 0.8440 - val_loss: 0.4698 - val_binary_accuracy: 0.7857\n",
      "Epoch 81/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3225 - binary_accuracy: 0.8540 - val_loss: 0.4771 - val_binary_accuracy: 0.7619\n",
      "Epoch 82/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3397 - binary_accuracy: 0.8380 - val_loss: 0.4812 - val_binary_accuracy: 0.7540\n",
      "Epoch 83/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3256 - binary_accuracy: 0.8460 - val_loss: 0.4562 - val_binary_accuracy: 0.7619\n",
      "Epoch 84/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3292 - binary_accuracy: 0.8480 - val_loss: 0.4803 - val_binary_accuracy: 0.7778\n",
      "Epoch 85/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3382 - binary_accuracy: 0.8500 - val_loss: 0.4801 - val_binary_accuracy: 0.7460\n",
      "Epoch 86/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3256 - binary_accuracy: 0.8460 - val_loss: 0.4844 - val_binary_accuracy: 0.7698\n",
      "Epoch 87/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3278 - binary_accuracy: 0.8480 - val_loss: 0.5127 - val_binary_accuracy: 0.7698\n",
      "Epoch 88/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3462 - binary_accuracy: 0.8540 - val_loss: 0.4691 - val_binary_accuracy: 0.7619\n",
      "Epoch 89/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3498 - binary_accuracy: 0.8480 - val_loss: 0.4914 - val_binary_accuracy: 0.7460\n",
      "Epoch 90/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3275 - binary_accuracy: 0.8560 - val_loss: 0.4650 - val_binary_accuracy: 0.7857\n",
      "Epoch 91/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3117 - binary_accuracy: 0.8620 - val_loss: 0.4896 - val_binary_accuracy: 0.7540\n",
      "Epoch 92/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3176 - binary_accuracy: 0.8680 - val_loss: 0.5032 - val_binary_accuracy: 0.7619\n",
      "Epoch 93/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3223 - binary_accuracy: 0.8620 - val_loss: 0.4448 - val_binary_accuracy: 0.7857\n",
      "Epoch 94/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3522 - binary_accuracy: 0.8400 - val_loss: 0.4474 - val_binary_accuracy: 0.7540\n",
      "Epoch 95/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3489 - binary_accuracy: 0.8540 - val_loss: 0.4688 - val_binary_accuracy: 0.7540\n",
      "Epoch 96/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3562 - binary_accuracy: 0.8420 - val_loss: 0.4913 - val_binary_accuracy: 0.7619\n",
      "Epoch 97/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3260 - binary_accuracy: 0.8260 - val_loss: 0.4490 - val_binary_accuracy: 0.7698\n",
      "Epoch 98/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3268 - binary_accuracy: 0.8580 - val_loss: 0.4684 - val_binary_accuracy: 0.7619\n",
      "Epoch 99/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3149 - binary_accuracy: 0.8520 - val_loss: 0.4384 - val_binary_accuracy: 0.7857\n",
      "Epoch 100/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3232 - binary_accuracy: 0.8600 - val_loss: 0.4649 - val_binary_accuracy: 0.7619\n",
      "Epoch 101/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3169 - binary_accuracy: 0.8580 - val_loss: 0.4735 - val_binary_accuracy: 0.7619\n",
      "Epoch 102/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3430 - binary_accuracy: 0.8420 - val_loss: 0.4614 - val_binary_accuracy: 0.7619\n",
      "Epoch 103/400\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3117 - binary_accuracy: 0.8720 - val_loss: 0.4508 - val_binary_accuracy: 0.7698\n",
      "Epoch 104/400\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3309 - binary_accuracy: 0.8280 - val_loss: 0.4756 - val_binary_accuracy: 0.7381\n",
      "Epoch 105/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3453 - binary_accuracy: 0.8480 - val_loss: 0.4759 - val_binary_accuracy: 0.7460\n",
      "Epoch 106/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3478 - binary_accuracy: 0.8260 - val_loss: 0.4863 - val_binary_accuracy: 0.7698\n",
      "Epoch 107/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3147 - binary_accuracy: 0.8660 - val_loss: 0.4866 - val_binary_accuracy: 0.7698\n",
      "Epoch 108/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3410 - binary_accuracy: 0.8360 - val_loss: 0.4927 - val_binary_accuracy: 0.7302\n",
      "Epoch 109/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3365 - binary_accuracy: 0.8400 - val_loss: 0.4964 - val_binary_accuracy: 0.7540\n",
      "Epoch 110/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3274 - binary_accuracy: 0.8400 - val_loss: 0.4330 - val_binary_accuracy: 0.8095\n",
      "Epoch 111/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2961 - binary_accuracy: 0.8580 - val_loss: 0.4518 - val_binary_accuracy: 0.7857\n",
      "Epoch 112/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2970 - binary_accuracy: 0.8800 - val_loss: 0.4749 - val_binary_accuracy: 0.7619\n",
      "Epoch 113/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3370 - binary_accuracy: 0.8540 - val_loss: 0.5133 - val_binary_accuracy: 0.7619\n",
      "Epoch 114/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3785 - binary_accuracy: 0.8200 - val_loss: 0.4630 - val_binary_accuracy: 0.7460\n",
      "Epoch 115/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3358 - binary_accuracy: 0.8460 - val_loss: 0.5239 - val_binary_accuracy: 0.7540\n",
      "Epoch 116/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3299 - binary_accuracy: 0.8460 - val_loss: 0.4518 - val_binary_accuracy: 0.7619\n",
      "Epoch 117/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3407 - binary_accuracy: 0.8420 - val_loss: 0.4377 - val_binary_accuracy: 0.7857\n",
      "Epoch 118/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3193 - binary_accuracy: 0.8540 - val_loss: 0.4793 - val_binary_accuracy: 0.7460\n",
      "Epoch 119/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3343 - binary_accuracy: 0.8480 - val_loss: 0.5182 - val_binary_accuracy: 0.7540\n",
      "Epoch 120/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3511 - binary_accuracy: 0.8320 - val_loss: 0.5121 - val_binary_accuracy: 0.7540\n",
      "Epoch 121/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3096 - binary_accuracy: 0.8620 - val_loss: 0.5075 - val_binary_accuracy: 0.7540\n",
      "Epoch 122/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3103 - binary_accuracy: 0.8600 - val_loss: 0.4791 - val_binary_accuracy: 0.7619\n",
      "Epoch 123/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2990 - binary_accuracy: 0.8620 - val_loss: 0.4285 - val_binary_accuracy: 0.7778\n",
      "Epoch 124/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3154 - binary_accuracy: 0.8760 - val_loss: 0.4629 - val_binary_accuracy: 0.7857\n",
      "Epoch 125/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3122 - binary_accuracy: 0.8780 - val_loss: 0.4392 - val_binary_accuracy: 0.7619\n",
      "Epoch 126/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2961 - binary_accuracy: 0.8640 - val_loss: 0.4416 - val_binary_accuracy: 0.7857\n",
      "Epoch 127/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3125 - binary_accuracy: 0.8700 - val_loss: 0.4398 - val_binary_accuracy: 0.7778\n",
      "Epoch 128/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3109 - binary_accuracy: 0.8620 - val_loss: 0.4498 - val_binary_accuracy: 0.7778\n",
      "Epoch 129/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3084 - binary_accuracy: 0.8540 - val_loss: 0.4496 - val_binary_accuracy: 0.7540\n",
      "Epoch 130/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3228 - binary_accuracy: 0.8760 - val_loss: 0.4412 - val_binary_accuracy: 0.7698\n",
      "Epoch 131/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2953 - binary_accuracy: 0.8680 - val_loss: 0.4441 - val_binary_accuracy: 0.7540\n",
      "Epoch 132/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3057 - binary_accuracy: 0.8480 - val_loss: 0.4663 - val_binary_accuracy: 0.7619\n",
      "Epoch 133/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2878 - binary_accuracy: 0.8840 - val_loss: 0.4866 - val_binary_accuracy: 0.7619\n",
      "Epoch 134/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3009 - binary_accuracy: 0.8720 - val_loss: 0.4585 - val_binary_accuracy: 0.7540\n",
      "Epoch 135/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2943 - binary_accuracy: 0.8680 - val_loss: 0.5138 - val_binary_accuracy: 0.7619\n",
      "Epoch 136/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2783 - binary_accuracy: 0.8760 - val_loss: 0.4323 - val_binary_accuracy: 0.7778\n",
      "Epoch 137/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2987 - binary_accuracy: 0.8740 - val_loss: 0.4375 - val_binary_accuracy: 0.7540\n",
      "Epoch 138/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3131 - binary_accuracy: 0.8500 - val_loss: 0.4885 - val_binary_accuracy: 0.7778\n",
      "Epoch 139/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2958 - binary_accuracy: 0.8760 - val_loss: 0.4695 - val_binary_accuracy: 0.7778\n",
      "Epoch 140/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2998 - binary_accuracy: 0.8660 - val_loss: 0.4381 - val_binary_accuracy: 0.7857\n",
      "Epoch 141/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2946 - binary_accuracy: 0.8700 - val_loss: 0.4482 - val_binary_accuracy: 0.7778\n",
      "Epoch 142/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2930 - binary_accuracy: 0.8680 - val_loss: 0.4598 - val_binary_accuracy: 0.7937\n",
      "Epoch 143/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3110 - binary_accuracy: 0.8760 - val_loss: 0.4765 - val_binary_accuracy: 0.7778\n",
      "Epoch 144/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3154 - binary_accuracy: 0.8520 - val_loss: 0.4763 - val_binary_accuracy: 0.7619\n",
      "Epoch 145/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3048 - binary_accuracy: 0.8620 - val_loss: 0.4439 - val_binary_accuracy: 0.7778\n",
      "Epoch 146/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3029 - binary_accuracy: 0.8680 - val_loss: 0.4378 - val_binary_accuracy: 0.7778\n",
      "Epoch 147/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3024 - binary_accuracy: 0.8580 - val_loss: 0.4869 - val_binary_accuracy: 0.7698\n",
      "Epoch 148/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3110 - binary_accuracy: 0.8680 - val_loss: 0.4207 - val_binary_accuracy: 0.8333\n",
      "Epoch 149/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3074 - binary_accuracy: 0.8720 - val_loss: 0.4535 - val_binary_accuracy: 0.7698\n",
      "Epoch 150/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3358 - binary_accuracy: 0.8420 - val_loss: 0.5006 - val_binary_accuracy: 0.7540\n",
      "Epoch 151/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2694 - binary_accuracy: 0.8680 - val_loss: 0.5145 - val_binary_accuracy: 0.7857\n",
      "Epoch 152/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3011 - binary_accuracy: 0.8660 - val_loss: 0.4511 - val_binary_accuracy: 0.8016\n",
      "Epoch 153/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2962 - binary_accuracy: 0.8700 - val_loss: 0.4533 - val_binary_accuracy: 0.7778\n",
      "Epoch 154/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3178 - binary_accuracy: 0.8560 - val_loss: 0.4745 - val_binary_accuracy: 0.7937\n",
      "Epoch 155/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2862 - binary_accuracy: 0.8760 - val_loss: 0.4323 - val_binary_accuracy: 0.7698\n",
      "Epoch 156/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2733 - binary_accuracy: 0.8800 - val_loss: 0.4677 - val_binary_accuracy: 0.8016\n",
      "Epoch 157/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2692 - binary_accuracy: 0.8940 - val_loss: 0.4646 - val_binary_accuracy: 0.7619\n",
      "Epoch 158/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2771 - binary_accuracy: 0.8720 - val_loss: 0.4310 - val_binary_accuracy: 0.7857\n",
      "Epoch 159/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3003 - binary_accuracy: 0.8620 - val_loss: 0.4617 - val_binary_accuracy: 0.7857\n",
      "Epoch 160/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2820 - binary_accuracy: 0.8760 - val_loss: 0.4477 - val_binary_accuracy: 0.8016\n",
      "Epoch 161/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2886 - binary_accuracy: 0.8580 - val_loss: 0.4769 - val_binary_accuracy: 0.7540\n",
      "Epoch 162/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3003 - binary_accuracy: 0.8700 - val_loss: 0.4563 - val_binary_accuracy: 0.7619\n",
      "Epoch 163/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2989 - binary_accuracy: 0.8600 - val_loss: 0.5356 - val_binary_accuracy: 0.8016\n",
      "Epoch 164/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3627 - binary_accuracy: 0.8240 - val_loss: 0.5310 - val_binary_accuracy: 0.7698\n",
      "Epoch 165/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3547 - binary_accuracy: 0.8300 - val_loss: 0.5034 - val_binary_accuracy: 0.7619\n",
      "Epoch 166/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3036 - binary_accuracy: 0.8660 - val_loss: 0.4378 - val_binary_accuracy: 0.7540\n",
      "Epoch 167/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3187 - binary_accuracy: 0.8700 - val_loss: 0.4506 - val_binary_accuracy: 0.7937\n",
      "Epoch 168/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3053 - binary_accuracy: 0.8600 - val_loss: 0.4725 - val_binary_accuracy: 0.7698\n",
      "Epoch 169/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2784 - binary_accuracy: 0.8740 - val_loss: 0.4516 - val_binary_accuracy: 0.7857\n",
      "Epoch 170/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2945 - binary_accuracy: 0.8700 - val_loss: 0.4193 - val_binary_accuracy: 0.8254\n",
      "Epoch 171/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2632 - binary_accuracy: 0.8800 - val_loss: 0.4182 - val_binary_accuracy: 0.8016\n",
      "Epoch 172/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2620 - binary_accuracy: 0.8780 - val_loss: 0.4525 - val_binary_accuracy: 0.7937\n",
      "Epoch 173/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2918 - binary_accuracy: 0.8680 - val_loss: 0.4456 - val_binary_accuracy: 0.8095\n",
      "Epoch 174/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2878 - binary_accuracy: 0.8800 - val_loss: 0.4897 - val_binary_accuracy: 0.7381\n",
      "Epoch 175/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3319 - binary_accuracy: 0.8460 - val_loss: 0.4826 - val_binary_accuracy: 0.7698\n",
      "Epoch 176/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2963 - binary_accuracy: 0.8740 - val_loss: 0.5686 - val_binary_accuracy: 0.7302\n",
      "Epoch 177/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3392 - binary_accuracy: 0.8460 - val_loss: 0.4796 - val_binary_accuracy: 0.7540\n",
      "Epoch 178/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2917 - binary_accuracy: 0.8620 - val_loss: 0.4455 - val_binary_accuracy: 0.7698\n",
      "Epoch 179/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2980 - binary_accuracy: 0.8500 - val_loss: 0.4995 - val_binary_accuracy: 0.7540\n",
      "Epoch 180/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2682 - binary_accuracy: 0.8820 - val_loss: 0.4259 - val_binary_accuracy: 0.8175\n",
      "Epoch 181/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2853 - binary_accuracy: 0.8780 - val_loss: 0.4752 - val_binary_accuracy: 0.7857\n",
      "Epoch 182/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3256 - binary_accuracy: 0.8480 - val_loss: 0.4435 - val_binary_accuracy: 0.7540\n",
      "Epoch 183/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3233 - binary_accuracy: 0.8600 - val_loss: 0.4714 - val_binary_accuracy: 0.7698\n",
      "Epoch 184/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3153 - binary_accuracy: 0.8560 - val_loss: 0.4875 - val_binary_accuracy: 0.7857\n",
      "Epoch 185/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2700 - binary_accuracy: 0.8880 - val_loss: 0.4955 - val_binary_accuracy: 0.7698\n",
      "Epoch 186/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2961 - binary_accuracy: 0.8720 - val_loss: 0.4656 - val_binary_accuracy: 0.7857\n",
      "Epoch 187/400\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2707 - binary_accuracy: 0.8920 - val_loss: 0.4609 - val_binary_accuracy: 0.7698\n",
      "Epoch 188/400\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.2707 - binary_accuracy: 0.8720 - val_loss: 0.4814 - val_binary_accuracy: 0.8016\n",
      "Epoch 189/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2679 - binary_accuracy: 0.8900 - val_loss: 0.4749 - val_binary_accuracy: 0.8016\n",
      "Epoch 190/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2636 - binary_accuracy: 0.8980 - val_loss: 0.4334 - val_binary_accuracy: 0.7698\n",
      "Epoch 191/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2711 - binary_accuracy: 0.8800 - val_loss: 0.4281 - val_binary_accuracy: 0.7937\n",
      "Epoch 192/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2807 - binary_accuracy: 0.8660 - val_loss: 0.4937 - val_binary_accuracy: 0.7778\n",
      "Epoch 193/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2796 - binary_accuracy: 0.8680 - val_loss: 0.4378 - val_binary_accuracy: 0.8016\n",
      "Epoch 194/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2901 - binary_accuracy: 0.8840 - val_loss: 0.4831 - val_binary_accuracy: 0.7857\n",
      "Epoch 195/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2430 - binary_accuracy: 0.9060 - val_loss: 0.4463 - val_binary_accuracy: 0.7778\n",
      "Epoch 196/400\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.3308 - binary_accuracy: 0.843 - 0s 4ms/step - loss: 0.2812 - binary_accuracy: 0.8740 - val_loss: 0.4271 - val_binary_accuracy: 0.7778\n",
      "Epoch 197/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2655 - binary_accuracy: 0.8900 - val_loss: 0.4651 - val_binary_accuracy: 0.8095\n",
      "Epoch 198/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3236 - binary_accuracy: 0.8460 - val_loss: 0.5049 - val_binary_accuracy: 0.8095\n",
      "Epoch 199/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2863 - binary_accuracy: 0.8560 - val_loss: 0.5225 - val_binary_accuracy: 0.7460\n",
      "Epoch 200/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2739 - binary_accuracy: 0.8860 - val_loss: 0.4661 - val_binary_accuracy: 0.7778\n",
      "Epoch 201/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2926 - binary_accuracy: 0.8580 - val_loss: 0.4395 - val_binary_accuracy: 0.7937\n",
      "Epoch 202/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2678 - binary_accuracy: 0.8820 - val_loss: 0.4671 - val_binary_accuracy: 0.8095\n",
      "Epoch 203/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2863 - binary_accuracy: 0.8720 - val_loss: 0.4074 - val_binary_accuracy: 0.8016\n",
      "Epoch 204/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2595 - binary_accuracy: 0.8780 - val_loss: 0.5402 - val_binary_accuracy: 0.7857\n",
      "Epoch 205/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2857 - binary_accuracy: 0.8600 - val_loss: 0.4168 - val_binary_accuracy: 0.8095\n",
      "Epoch 206/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2692 - binary_accuracy: 0.8860 - val_loss: 0.4363 - val_binary_accuracy: 0.7937\n",
      "Epoch 207/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2661 - binary_accuracy: 0.8860 - val_loss: 0.4553 - val_binary_accuracy: 0.7698\n",
      "Epoch 208/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2742 - binary_accuracy: 0.8720 - val_loss: 0.4598 - val_binary_accuracy: 0.7937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2850 - binary_accuracy: 0.8660 - val_loss: 0.4456 - val_binary_accuracy: 0.7937\n",
      "Epoch 210/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2602 - binary_accuracy: 0.8820 - val_loss: 0.4420 - val_binary_accuracy: 0.7937\n",
      "Epoch 211/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2733 - binary_accuracy: 0.8700 - val_loss: 0.4544 - val_binary_accuracy: 0.8016\n",
      "Epoch 212/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2706 - binary_accuracy: 0.8740 - val_loss: 0.4632 - val_binary_accuracy: 0.8016\n",
      "Epoch 213/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2634 - binary_accuracy: 0.8760 - val_loss: 0.4560 - val_binary_accuracy: 0.8016\n",
      "Epoch 214/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2576 - binary_accuracy: 0.8860 - val_loss: 0.4135 - val_binary_accuracy: 0.7778\n",
      "Epoch 215/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2382 - binary_accuracy: 0.8960 - val_loss: 0.4819 - val_binary_accuracy: 0.8016\n",
      "Epoch 216/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2979 - binary_accuracy: 0.8560 - val_loss: 0.4800 - val_binary_accuracy: 0.7937\n",
      "Epoch 217/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2992 - binary_accuracy: 0.8760 - val_loss: 0.5379 - val_binary_accuracy: 0.7857\n",
      "Epoch 218/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3292 - binary_accuracy: 0.8580 - val_loss: 0.4691 - val_binary_accuracy: 0.7857\n",
      "Epoch 219/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2998 - binary_accuracy: 0.8640 - val_loss: 0.5155 - val_binary_accuracy: 0.7619\n",
      "Epoch 220/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2828 - binary_accuracy: 0.8800 - val_loss: 0.4652 - val_binary_accuracy: 0.7857\n",
      "Epoch 221/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2649 - binary_accuracy: 0.8720 - val_loss: 0.4601 - val_binary_accuracy: 0.8095\n",
      "Epoch 222/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2564 - binary_accuracy: 0.8900 - val_loss: 0.4634 - val_binary_accuracy: 0.7857\n",
      "Epoch 223/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2659 - binary_accuracy: 0.8860 - val_loss: 0.4431 - val_binary_accuracy: 0.7857\n",
      "Epoch 224/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2553 - binary_accuracy: 0.8980 - val_loss: 0.4701 - val_binary_accuracy: 0.7778\n",
      "Epoch 225/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2572 - binary_accuracy: 0.8840 - val_loss: 0.3993 - val_binary_accuracy: 0.7937\n",
      "Epoch 226/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2439 - binary_accuracy: 0.9100 - val_loss: 0.4720 - val_binary_accuracy: 0.7778\n",
      "Epoch 227/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3042 - binary_accuracy: 0.8640 - val_loss: 0.5277 - val_binary_accuracy: 0.7619\n",
      "Epoch 228/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3030 - binary_accuracy: 0.8600 - val_loss: 0.3915 - val_binary_accuracy: 0.7857\n",
      "Epoch 229/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2541 - binary_accuracy: 0.9000 - val_loss: 0.4428 - val_binary_accuracy: 0.7778\n",
      "Epoch 230/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2391 - binary_accuracy: 0.8960 - val_loss: 0.4732 - val_binary_accuracy: 0.8016\n",
      "Epoch 231/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2449 - binary_accuracy: 0.8980 - val_loss: 0.3942 - val_binary_accuracy: 0.8095\n",
      "Epoch 232/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2781 - binary_accuracy: 0.8740 - val_loss: 0.4273 - val_binary_accuracy: 0.8095\n",
      "Epoch 233/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2788 - binary_accuracy: 0.8840 - val_loss: 0.4336 - val_binary_accuracy: 0.7857\n",
      "Epoch 234/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2610 - binary_accuracy: 0.8960 - val_loss: 0.4122 - val_binary_accuracy: 0.8333\n",
      "Epoch 235/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2519 - binary_accuracy: 0.8900 - val_loss: 0.4031 - val_binary_accuracy: 0.8016\n",
      "Epoch 236/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2602 - binary_accuracy: 0.8860 - val_loss: 0.4358 - val_binary_accuracy: 0.8254\n",
      "Epoch 237/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2474 - binary_accuracy: 0.8980 - val_loss: 0.5182 - val_binary_accuracy: 0.7778\n",
      "Epoch 238/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2497 - binary_accuracy: 0.8980 - val_loss: 0.4433 - val_binary_accuracy: 0.8095\n",
      "Epoch 239/400\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2754 - binary_accuracy: 0.8700 - val_loss: 0.4362 - val_binary_accuracy: 0.8175\n",
      "Epoch 240/400\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2797 - binary_accuracy: 0.8640 - val_loss: 0.4084 - val_binary_accuracy: 0.8016\n",
      "Epoch 241/400\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2770 - binary_accuracy: 0.8720 - val_loss: 0.4187 - val_binary_accuracy: 0.8095\n",
      "Epoch 242/400\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2658 - binary_accuracy: 0.8940 - val_loss: 0.4077 - val_binary_accuracy: 0.8333\n",
      "Epoch 243/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2637 - binary_accuracy: 0.8820 - val_loss: 0.4482 - val_binary_accuracy: 0.7857\n",
      "Epoch 244/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2617 - binary_accuracy: 0.8940 - val_loss: 0.4072 - val_binary_accuracy: 0.8413\n",
      "Epoch 245/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2311 - binary_accuracy: 0.9120 - val_loss: 0.4222 - val_binary_accuracy: 0.8175\n",
      "Epoch 246/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2394 - binary_accuracy: 0.9060 - val_loss: 0.4462 - val_binary_accuracy: 0.8016\n",
      "Epoch 247/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2492 - binary_accuracy: 0.8920 - val_loss: 0.4571 - val_binary_accuracy: 0.8175\n",
      "Epoch 248/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2422 - binary_accuracy: 0.9040 - val_loss: 0.3938 - val_binary_accuracy: 0.8095\n",
      "Epoch 249/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2563 - binary_accuracy: 0.8940 - val_loss: 0.4327 - val_binary_accuracy: 0.7937\n",
      "Epoch 250/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3080 - binary_accuracy: 0.8580 - val_loss: 0.4927 - val_binary_accuracy: 0.7619\n",
      "Epoch 251/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2681 - binary_accuracy: 0.8780 - val_loss: 0.3951 - val_binary_accuracy: 0.8095\n",
      "Epoch 252/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2364 - binary_accuracy: 0.9060 - val_loss: 0.4781 - val_binary_accuracy: 0.7778\n",
      "Epoch 253/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2579 - binary_accuracy: 0.8840 - val_loss: 0.4156 - val_binary_accuracy: 0.7937\n",
      "Epoch 254/400\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.2508 - binary_accuracy: 0.875 - 0s 3ms/step - loss: 0.2737 - binary_accuracy: 0.8760 - val_loss: 0.4323 - val_binary_accuracy: 0.8016\n",
      "Epoch 255/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2807 - binary_accuracy: 0.8700 - val_loss: 0.4291 - val_binary_accuracy: 0.8175\n",
      "Epoch 256/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2336 - binary_accuracy: 0.9000 - val_loss: 0.4592 - val_binary_accuracy: 0.7778\n",
      "Epoch 257/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2367 - binary_accuracy: 0.9040 - val_loss: 0.4365 - val_binary_accuracy: 0.8333\n",
      "Epoch 258/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2416 - binary_accuracy: 0.9060 - val_loss: 0.5090 - val_binary_accuracy: 0.8016\n",
      "Epoch 259/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2404 - binary_accuracy: 0.9040 - val_loss: 0.5505 - val_binary_accuracy: 0.7778\n",
      "Epoch 260/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2602 - binary_accuracy: 0.8800 - val_loss: 0.5727 - val_binary_accuracy: 0.7698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 261/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3356 - binary_accuracy: 0.8760 - val_loss: 0.4395 - val_binary_accuracy: 0.7857\n",
      "Epoch 262/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2880 - binary_accuracy: 0.8700 - val_loss: 0.4837 - val_binary_accuracy: 0.7619\n",
      "Epoch 263/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3441 - binary_accuracy: 0.8540 - val_loss: 0.5453 - val_binary_accuracy: 0.7619\n",
      "Epoch 264/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3134 - binary_accuracy: 0.8640 - val_loss: 0.4326 - val_binary_accuracy: 0.8175\n",
      "Epoch 265/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3161 - binary_accuracy: 0.8660 - val_loss: 0.4849 - val_binary_accuracy: 0.7937\n",
      "Epoch 266/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2864 - binary_accuracy: 0.8780 - val_loss: 0.4068 - val_binary_accuracy: 0.8333\n",
      "Epoch 267/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2798 - binary_accuracy: 0.8620 - val_loss: 0.4202 - val_binary_accuracy: 0.8095\n",
      "Epoch 268/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2493 - binary_accuracy: 0.8900 - val_loss: 0.4895 - val_binary_accuracy: 0.7937\n",
      "Epoch 269/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2815 - binary_accuracy: 0.8760 - val_loss: 0.4424 - val_binary_accuracy: 0.8175\n",
      "Epoch 270/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2667 - binary_accuracy: 0.9020 - val_loss: 0.4124 - val_binary_accuracy: 0.8333\n",
      "Epoch 271/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3076 - binary_accuracy: 0.8760 - val_loss: 0.3948 - val_binary_accuracy: 0.8095\n",
      "Epoch 272/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2562 - binary_accuracy: 0.8940 - val_loss: 0.4047 - val_binary_accuracy: 0.8095\n",
      "Epoch 273/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2526 - binary_accuracy: 0.8880 - val_loss: 0.3925 - val_binary_accuracy: 0.8492\n",
      "Epoch 274/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2992 - binary_accuracy: 0.8640 - val_loss: 0.4260 - val_binary_accuracy: 0.8016\n",
      "Epoch 275/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2362 - binary_accuracy: 0.9040 - val_loss: 0.4237 - val_binary_accuracy: 0.8016\n",
      "Epoch 276/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2240 - binary_accuracy: 0.9000 - val_loss: 0.4504 - val_binary_accuracy: 0.7937\n",
      "Epoch 277/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2571 - binary_accuracy: 0.8880 - val_loss: 0.4786 - val_binary_accuracy: 0.8016\n",
      "Epoch 278/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2559 - binary_accuracy: 0.8820 - val_loss: 0.4090 - val_binary_accuracy: 0.7778\n",
      "Epoch 279/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2317 - binary_accuracy: 0.9040 - val_loss: 0.4424 - val_binary_accuracy: 0.7857\n",
      "Epoch 280/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2486 - binary_accuracy: 0.8900 - val_loss: 0.4487 - val_binary_accuracy: 0.8175\n",
      "Epoch 281/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2421 - binary_accuracy: 0.8940 - val_loss: 0.4804 - val_binary_accuracy: 0.7937\n",
      "Epoch 282/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2578 - binary_accuracy: 0.8880 - val_loss: 0.4392 - val_binary_accuracy: 0.8016\n",
      "Epoch 283/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2750 - binary_accuracy: 0.8680 - val_loss: 0.5164 - val_binary_accuracy: 0.7619\n",
      "Epoch 284/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2767 - binary_accuracy: 0.8580 - val_loss: 0.4720 - val_binary_accuracy: 0.8175\n",
      "Epoch 285/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2369 - binary_accuracy: 0.9100 - val_loss: 0.4049 - val_binary_accuracy: 0.8095\n",
      "Epoch 286/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2506 - binary_accuracy: 0.8920 - val_loss: 0.3943 - val_binary_accuracy: 0.7937\n",
      "Epoch 287/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2455 - binary_accuracy: 0.8980 - val_loss: 0.4336 - val_binary_accuracy: 0.8254\n",
      "Epoch 288/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2292 - binary_accuracy: 0.9060 - val_loss: 0.4460 - val_binary_accuracy: 0.7857\n",
      "Epoch 289/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2312 - binary_accuracy: 0.8840 - val_loss: 0.4473 - val_binary_accuracy: 0.8175\n",
      "Epoch 290/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2601 - binary_accuracy: 0.8740 - val_loss: 0.4413 - val_binary_accuracy: 0.8016\n",
      "Epoch 291/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2358 - binary_accuracy: 0.8940 - val_loss: 0.4269 - val_binary_accuracy: 0.8095\n",
      "Epoch 292/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2637 - binary_accuracy: 0.8820 - val_loss: 0.3912 - val_binary_accuracy: 0.8333\n",
      "Epoch 293/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2409 - binary_accuracy: 0.8880 - val_loss: 0.4155 - val_binary_accuracy: 0.8175\n",
      "Epoch 294/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2568 - binary_accuracy: 0.8860 - val_loss: 0.4303 - val_binary_accuracy: 0.8095\n",
      "Epoch 295/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2484 - binary_accuracy: 0.9000 - val_loss: 0.3779 - val_binary_accuracy: 0.8175\n",
      "Epoch 296/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2698 - binary_accuracy: 0.8740 - val_loss: 0.3983 - val_binary_accuracy: 0.8095\n",
      "Epoch 297/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2347 - binary_accuracy: 0.9120 - val_loss: 0.4318 - val_binary_accuracy: 0.8016\n",
      "Epoch 298/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2567 - binary_accuracy: 0.8740 - val_loss: 0.4510 - val_binary_accuracy: 0.7937\n",
      "Epoch 299/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2449 - binary_accuracy: 0.8960 - val_loss: 0.4269 - val_binary_accuracy: 0.8016\n",
      "Epoch 300/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2528 - binary_accuracy: 0.8880 - val_loss: 0.3878 - val_binary_accuracy: 0.8413\n",
      "Epoch 301/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2703 - binary_accuracy: 0.8780 - val_loss: 0.3978 - val_binary_accuracy: 0.8016\n",
      "Epoch 302/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2387 - binary_accuracy: 0.9020 - val_loss: 0.4160 - val_binary_accuracy: 0.8095\n",
      "Epoch 303/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2475 - binary_accuracy: 0.9040 - val_loss: 0.3794 - val_binary_accuracy: 0.8254\n",
      "Epoch 304/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2109 - binary_accuracy: 0.9160 - val_loss: 0.4345 - val_binary_accuracy: 0.7937\n",
      "Epoch 305/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2255 - binary_accuracy: 0.9020 - val_loss: 0.4299 - val_binary_accuracy: 0.8095\n",
      "Epoch 306/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1960 - binary_accuracy: 0.9240 - val_loss: 0.4319 - val_binary_accuracy: 0.8095\n",
      "Epoch 307/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2216 - binary_accuracy: 0.8920 - val_loss: 0.4523 - val_binary_accuracy: 0.8095\n",
      "Epoch 308/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2393 - binary_accuracy: 0.8840 - val_loss: 0.5030 - val_binary_accuracy: 0.7698\n",
      "Epoch 309/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2308 - binary_accuracy: 0.9020 - val_loss: 0.4036 - val_binary_accuracy: 0.8254\n",
      "Epoch 310/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2356 - binary_accuracy: 0.8980 - val_loss: 0.4133 - val_binary_accuracy: 0.7778\n",
      "Epoch 311/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2351 - binary_accuracy: 0.9040 - val_loss: 0.4083 - val_binary_accuracy: 0.8016\n",
      "Epoch 312/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2222 - binary_accuracy: 0.9040 - val_loss: 0.4724 - val_binary_accuracy: 0.8333\n",
      "Epoch 313/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2380 - binary_accuracy: 0.8920 - val_loss: 0.4233 - val_binary_accuracy: 0.8175\n",
      "Epoch 314/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2295 - binary_accuracy: 0.8980 - val_loss: 0.4401 - val_binary_accuracy: 0.7937\n",
      "Epoch 315/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2896 - binary_accuracy: 0.8800 - val_loss: 0.4191 - val_binary_accuracy: 0.7857\n",
      "Epoch 316/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2572 - binary_accuracy: 0.8880 - val_loss: 0.4117 - val_binary_accuracy: 0.8254\n",
      "Epoch 317/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2464 - binary_accuracy: 0.8980 - val_loss: 0.4308 - val_binary_accuracy: 0.8016\n",
      "Epoch 318/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2336 - binary_accuracy: 0.9120 - val_loss: 0.5073 - val_binary_accuracy: 0.7937\n",
      "Epoch 319/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2210 - binary_accuracy: 0.9080 - val_loss: 0.4038 - val_binary_accuracy: 0.7937\n",
      "Epoch 320/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2325 - binary_accuracy: 0.9160 - val_loss: 0.4195 - val_binary_accuracy: 0.7698\n",
      "Epoch 321/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2417 - binary_accuracy: 0.8900 - val_loss: 0.4373 - val_binary_accuracy: 0.8413\n",
      "Epoch 322/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2160 - binary_accuracy: 0.9240 - val_loss: 0.4471 - val_binary_accuracy: 0.8413\n",
      "Epoch 323/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2054 - binary_accuracy: 0.9020 - val_loss: 0.4106 - val_binary_accuracy: 0.8016\n",
      "Epoch 324/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2297 - binary_accuracy: 0.8880 - val_loss: 0.4239 - val_binary_accuracy: 0.8095\n",
      "Epoch 325/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2490 - binary_accuracy: 0.8940 - val_loss: 0.4016 - val_binary_accuracy: 0.7937\n",
      "Epoch 326/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2729 - binary_accuracy: 0.8740 - val_loss: 0.4444 - val_binary_accuracy: 0.7778\n",
      "Epoch 327/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2505 - binary_accuracy: 0.8940 - val_loss: 0.3905 - val_binary_accuracy: 0.8254\n",
      "Epoch 328/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2323 - binary_accuracy: 0.8940 - val_loss: 0.4374 - val_binary_accuracy: 0.8016\n",
      "Epoch 329/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2472 - binary_accuracy: 0.9020 - val_loss: 0.4089 - val_binary_accuracy: 0.8254\n",
      "Epoch 330/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2264 - binary_accuracy: 0.9020 - val_loss: 0.3986 - val_binary_accuracy: 0.8254\n",
      "Epoch 331/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2323 - binary_accuracy: 0.8960 - val_loss: 0.4563 - val_binary_accuracy: 0.7857\n",
      "Epoch 332/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2130 - binary_accuracy: 0.9100 - val_loss: 0.3871 - val_binary_accuracy: 0.8333\n",
      "Epoch 333/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2389 - binary_accuracy: 0.9000 - val_loss: 0.4398 - val_binary_accuracy: 0.8095\n",
      "Epoch 334/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2294 - binary_accuracy: 0.9080 - val_loss: 0.4356 - val_binary_accuracy: 0.8254\n",
      "Epoch 335/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2165 - binary_accuracy: 0.9080 - val_loss: 0.4077 - val_binary_accuracy: 0.8254\n",
      "Epoch 336/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2443 - binary_accuracy: 0.8880 - val_loss: 0.3950 - val_binary_accuracy: 0.8254\n",
      "Epoch 337/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2280 - binary_accuracy: 0.8960 - val_loss: 0.4173 - val_binary_accuracy: 0.8175\n",
      "Epoch 338/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2333 - binary_accuracy: 0.9040 - val_loss: 0.4777 - val_binary_accuracy: 0.7857\n",
      "Epoch 339/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2511 - binary_accuracy: 0.8880 - val_loss: 0.4135 - val_binary_accuracy: 0.8016\n",
      "Epoch 340/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2383 - binary_accuracy: 0.8940 - val_loss: 0.3850 - val_binary_accuracy: 0.8095\n",
      "Epoch 341/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2523 - binary_accuracy: 0.8860 - val_loss: 0.4199 - val_binary_accuracy: 0.8175\n",
      "Epoch 342/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2099 - binary_accuracy: 0.9120 - val_loss: 0.3999 - val_binary_accuracy: 0.8333\n",
      "Epoch 343/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2215 - binary_accuracy: 0.9040 - val_loss: 0.4171 - val_binary_accuracy: 0.8175\n",
      "Epoch 344/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2088 - binary_accuracy: 0.9260 - val_loss: 0.4394 - val_binary_accuracy: 0.8333\n",
      "Epoch 345/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2413 - binary_accuracy: 0.8960 - val_loss: 0.4000 - val_binary_accuracy: 0.7857\n",
      "Epoch 346/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2440 - binary_accuracy: 0.8900 - val_loss: 0.4401 - val_binary_accuracy: 0.8413\n",
      "Epoch 347/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2158 - binary_accuracy: 0.9120 - val_loss: 0.4462 - val_binary_accuracy: 0.7857\n",
      "Epoch 348/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2119 - binary_accuracy: 0.9100 - val_loss: 0.5057 - val_binary_accuracy: 0.8016\n",
      "Epoch 349/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2181 - binary_accuracy: 0.9160 - val_loss: 0.4574 - val_binary_accuracy: 0.8254\n",
      "Epoch 350/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2446 - binary_accuracy: 0.8960 - val_loss: 0.4313 - val_binary_accuracy: 0.8095\n",
      "Epoch 351/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2218 - binary_accuracy: 0.8900 - val_loss: 0.5189 - val_binary_accuracy: 0.8254\n",
      "Epoch 352/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2159 - binary_accuracy: 0.9080 - val_loss: 0.4063 - val_binary_accuracy: 0.8175\n",
      "Epoch 353/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1973 - binary_accuracy: 0.9280 - val_loss: 0.4715 - val_binary_accuracy: 0.8254\n",
      "Epoch 354/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2185 - binary_accuracy: 0.9080 - val_loss: 0.4035 - val_binary_accuracy: 0.8413\n",
      "Epoch 355/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2133 - binary_accuracy: 0.9220 - val_loss: 0.4700 - val_binary_accuracy: 0.7857\n",
      "Epoch 356/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2482 - binary_accuracy: 0.8860 - val_loss: 0.4768 - val_binary_accuracy: 0.8095\n",
      "Epoch 357/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2209 - binary_accuracy: 0.9020 - val_loss: 0.4255 - val_binary_accuracy: 0.8254\n",
      "Epoch 358/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2178 - binary_accuracy: 0.9160 - val_loss: 0.3964 - val_binary_accuracy: 0.8016\n",
      "Epoch 359/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2039 - binary_accuracy: 0.9080 - val_loss: 0.3830 - val_binary_accuracy: 0.8095\n",
      "Epoch 360/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2081 - binary_accuracy: 0.9180 - val_loss: 0.3740 - val_binary_accuracy: 0.8175\n",
      "Epoch 361/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2516 - binary_accuracy: 0.8920 - val_loss: 0.3980 - val_binary_accuracy: 0.8095\n",
      "Epoch 362/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2142 - binary_accuracy: 0.9040 - val_loss: 0.4498 - val_binary_accuracy: 0.8016\n",
      "Epoch 363/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2306 - binary_accuracy: 0.8940 - val_loss: 0.3886 - val_binary_accuracy: 0.7937\n",
      "Epoch 364/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2293 - binary_accuracy: 0.8920 - val_loss: 0.4445 - val_binary_accuracy: 0.7857\n",
      "Epoch 365/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2099 - binary_accuracy: 0.9180 - val_loss: 0.3749 - val_binary_accuracy: 0.8095\n",
      "Epoch 366/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2288 - binary_accuracy: 0.8840 - val_loss: 0.4024 - val_binary_accuracy: 0.8254\n",
      "Epoch 367/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2393 - binary_accuracy: 0.9040 - val_loss: 0.3966 - val_binary_accuracy: 0.8175\n",
      "Epoch 368/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2014 - binary_accuracy: 0.9240 - val_loss: 0.4195 - val_binary_accuracy: 0.8413\n",
      "Epoch 369/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1957 - binary_accuracy: 0.9220 - val_loss: 0.3640 - val_binary_accuracy: 0.8413\n",
      "Epoch 370/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1965 - binary_accuracy: 0.9120 - val_loss: 0.4115 - val_binary_accuracy: 0.8175\n",
      "Epoch 371/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2239 - binary_accuracy: 0.8980 - val_loss: 0.4279 - val_binary_accuracy: 0.8254\n",
      "Epoch 372/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2165 - binary_accuracy: 0.9180 - val_loss: 0.3928 - val_binary_accuracy: 0.8175\n",
      "Epoch 373/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2070 - binary_accuracy: 0.9160 - val_loss: 0.3608 - val_binary_accuracy: 0.8333\n",
      "Epoch 374/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2004 - binary_accuracy: 0.9180 - val_loss: 0.4052 - val_binary_accuracy: 0.8016\n",
      "Epoch 375/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2267 - binary_accuracy: 0.8980 - val_loss: 0.3934 - val_binary_accuracy: 0.8175\n",
      "Epoch 376/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2084 - binary_accuracy: 0.9160 - val_loss: 0.3835 - val_binary_accuracy: 0.8095\n",
      "Epoch 377/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2090 - binary_accuracy: 0.9140 - val_loss: 0.4010 - val_binary_accuracy: 0.8254\n",
      "Epoch 378/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2018 - binary_accuracy: 0.9120 - val_loss: 0.3974 - val_binary_accuracy: 0.8016\n",
      "Epoch 379/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2289 - binary_accuracy: 0.9000 - val_loss: 0.4835 - val_binary_accuracy: 0.7778\n",
      "Epoch 380/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2549 - binary_accuracy: 0.9100 - val_loss: 0.4730 - val_binary_accuracy: 0.8095\n",
      "Epoch 381/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2087 - binary_accuracy: 0.9220 - val_loss: 0.4522 - val_binary_accuracy: 0.8095\n",
      "Epoch 382/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2354 - binary_accuracy: 0.9000 - val_loss: 0.4005 - val_binary_accuracy: 0.8413\n",
      "Epoch 383/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2318 - binary_accuracy: 0.8900 - val_loss: 0.4167 - val_binary_accuracy: 0.8175\n",
      "Epoch 384/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2435 - binary_accuracy: 0.9000 - val_loss: 0.4535 - val_binary_accuracy: 0.7778\n",
      "Epoch 385/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2157 - binary_accuracy: 0.9160 - val_loss: 0.4823 - val_binary_accuracy: 0.8016\n",
      "Epoch 386/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2003 - binary_accuracy: 0.9200 - val_loss: 0.4147 - val_binary_accuracy: 0.8413\n",
      "Epoch 387/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2322 - binary_accuracy: 0.9040 - val_loss: 0.4108 - val_binary_accuracy: 0.8095\n",
      "Epoch 388/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2167 - binary_accuracy: 0.9060 - val_loss: 0.4707 - val_binary_accuracy: 0.8175\n",
      "Epoch 389/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2263 - binary_accuracy: 0.9080 - val_loss: 0.3855 - val_binary_accuracy: 0.7937\n",
      "Epoch 390/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2003 - binary_accuracy: 0.9160 - val_loss: 0.4628 - val_binary_accuracy: 0.8254\n",
      "Epoch 391/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2086 - binary_accuracy: 0.9180 - val_loss: 0.3668 - val_binary_accuracy: 0.8175\n",
      "Epoch 392/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2115 - binary_accuracy: 0.9060 - val_loss: 0.3700 - val_binary_accuracy: 0.8175\n",
      "Epoch 393/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2158 - binary_accuracy: 0.9100 - val_loss: 0.3775 - val_binary_accuracy: 0.8254\n",
      "Epoch 394/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2156 - binary_accuracy: 0.9020 - val_loss: 0.4122 - val_binary_accuracy: 0.8333\n",
      "Epoch 395/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2286 - binary_accuracy: 0.8980 - val_loss: 0.4427 - val_binary_accuracy: 0.8016\n",
      "Epoch 396/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2207 - binary_accuracy: 0.9000 - val_loss: 0.4097 - val_binary_accuracy: 0.8175\n",
      "Epoch 397/400\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2173 - binary_accuracy: 0.9080 - val_loss: 0.3826 - val_binary_accuracy: 0.8413\n",
      "Epoch 398/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1933 - binary_accuracy: 0.9260 - val_loss: 0.3890 - val_binary_accuracy: 0.8333\n",
      "Epoch 399/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2036 - binary_accuracy: 0.9120 - val_loss: 0.4899 - val_binary_accuracy: 0.8175\n",
      "Epoch 400/400\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2349 - binary_accuracy: 0.8900 - val_loss: 0.3746 - val_binary_accuracy: 0.8175\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 2.0254 - binary_accuracy: 0.7209\n",
      "Test loss:  2.0253641605377197  Test binary accuracy:  0.7209302186965942\n"
     ]
    }
   ],
   "source": [
    "model = load_model('best_dense_model.h5')\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size = BATCH_SIZE, epochs = EPOCHS, validation_data=(x_val, y_val))\n",
    "fig, (ax1, ax2)= plt.subplots(2)\n",
    "ax1.plot(history.history['binary_accuracy'], 'b-')\n",
    "ax1.plot(history.history['val_binary_accuracy'], 'r-')\n",
    "ax1.set_title('Accuracy')\n",
    "\n",
    "ax2.plot(history.history['loss'], 'b-')\n",
    "ax2.plot(history.history['val_loss'], 'r-')\n",
    "ax2.set_title('Loss')\n",
    "plt.show()\n",
    "\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(\"Test loss: \", loss, \" Test binary accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fb4e495b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TeyK\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict_classes(x_test)\n",
    "len([ele for ele in y_test if ele ==0])/len(preds)\n",
    "\n",
    "preds = np.reshape(preds, (preds.shape[0],))\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "405e5484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "70b59449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 32)                800       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,889\n",
      "Trainable params: 1,889\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cd45d1",
   "metadata": {},
   "source": [
    "# Dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "59909a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list down all the features\n",
    "# anova, correlation matrix, fft(show relationsip between column and label)\n",
    "\n",
    "\n",
    "# make this a binary classification question\n",
    "# exactly when the major down will happen (shorten the target time window)\n",
    "# multiple output prediction (what kind of major down, when it happens, and what is the state name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
