{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e516e46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization, \\\n",
    "                                    Input, Embedding, Masking, Bidirectional, Conv1D, Flatten, \\\n",
    "                                    MaxPooling1D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "from sklearn.utils import class_weight, shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 300\n",
    "\n",
    "from datetime import datetime, timedelta, date\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cx_Oracle\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "class seven_days_LSTM:\n",
    "    def __init__(self, eq_id, alarm_table, hour_horizontal, hour_vertical):\n",
    "        self.eq_id = eq_id\n",
    "        self.alarm_table = alarm_table\n",
    "        self.status_table = self.query_status()\n",
    "        self.hour_horizontal = hour_horizontal\n",
    "        self.hour_vertical = hour_vertical\n",
    "        \n",
    "        status_start = self.status_table.iloc[0][\"TIMESTAMP_START\"].date() + timedelta(days=1)\n",
    "        status_end = self.status_table.iloc[len(self.status_table)-1][\"TIMESTAMP_START\"].date()\n",
    "        alarm_start = self.alarm_table.iloc[0][\"DT_SET\"].date() + timedelta(days=1) # add one day to make it start from 00:00:00\n",
    "        alarm_end = self.alarm_table.iloc[len(self.alarm_table)-1][\"DT_SET\"].date()\n",
    "        self.start_date = max(status_start, alarm_start)\n",
    "        self.end_date = min(status_end, alarm_end)\n",
    "        \n",
    "        self.timeframe_table = self.generate_time(self.start_date.strftime(\"%d/%m/%Y\"), self.end_date.strftime(\"%d/%m/%Y\"), \\\n",
    "                                                  self.hour_horizontal, self.hour_vertical)\n",
    "        \n",
    "        self.major_down_arr = self.major_down(self.timeframe_table, self.status_table, 6, 3600)\n",
    "\n",
    "        self.X_seq = self.alarm_breakdown_pattern(self.timeframe_table, self.alarm_table, self.status_table, self.hour_horizontal)\n",
    "        \n",
    "    def generate_time(self, start_date:str, end_date:str, hours_row:int, hour:int):\n",
    "        start = datetime.strptime(start_date, '%d/%m/%Y')\n",
    "        end = datetime.strptime(end_date, '%d/%m/%Y')\n",
    "\n",
    "        dates = []\n",
    "        while start+timedelta(hours=hours_row)<=end:\n",
    "            row = [start, start+timedelta(hours=hours_row)]\n",
    "            dates.append(row)\n",
    "            start += timedelta(hours=hour)\n",
    "\n",
    "        return pd.DataFrame(dates, columns=['TIMESTAMP_START', 'TIMESTAMP_END'])\n",
    "\n",
    "    \n",
    "    def alarm_breakdown_pattern(self, datetime_table, alarm_table, status_table, hour):\n",
    "        ORIG_ALARMS = []\n",
    "        \n",
    "        #validate alarm table date\n",
    "        if alarm_table.iloc[0]['DT_SET'] < status_table.iloc[0]['TIMESTAMP_START'] or \\\n",
    "            alarm_table.iloc[len(alarm_table)-1]['DT_SET'] > status_table.iloc[len(status_table)-1]['TIMESTAMP_START']:\n",
    "            raise ValueError(\"Alarm table date must be within the range of status table date\")\n",
    "\n",
    "        for idx, row in datetime_table.iterrows():\n",
    "            start = row['TIMESTAMP_START']\n",
    "            end = row['TIMESTAMP_END']\n",
    "\n",
    "            table = alarm_table[(alarm_table['DT_SET']>=start) & (alarm_table['DT_SET']<=end)]\n",
    "            new_table = table[[\"Alarm ID\"]]\n",
    "            \n",
    "            tmp2 = []\n",
    "            for n in new_table.values: # this part is needed to achieve the data structure in X_seq, else it would fail\n",
    "                tmp2.append(n[0])\n",
    "            ORIG_ALARMS.append(tmp2)\n",
    "\n",
    "        return np.array(ORIG_ALARMS)\n",
    "    \n",
    "    def query_status(self):\n",
    "        try:\n",
    "            oracle_string = \"oracle+cx_oracle://{username}:{password}@{hostname}:{port}/{database}\"\n",
    "            engine = create_engine(\n",
    "                oracle_string.format(\n",
    "                    username = 'TFM4CEBERUS',\n",
    "                    password = 'TFM4CEBERUS',\n",
    "                    hostname = 'ome-db.bth.infineon.com',\n",
    "                    port = '1538',\n",
    "                    database = 'ome'\n",
    "                    )\n",
    "                )\n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "\n",
    "        query = f\"\"\"select EQ_ID, TIMESTAMP_START, TIMESTAMP_END, DURATION, LEVEL3_NAME, LEVEL3 \n",
    "                from (SELECT\n",
    "                  eq.eq_id, eq.name, eq.eq_type_ident\n",
    "                , data.timestamp_start,data.timestamp_end\n",
    "                , ROUND((data.timestamp_end - data.timestamp_start)*24*60*60,0) AS Duration\n",
    "                , data.tr25_3_status,data.tr25_4_status,data.tr25_5_status,data.eq_status\n",
    "                , level5s.state_name\n",
    "                , level5.state_name Level5_Name, level5.state_sign Level5\n",
    "                , level4.state_name Level4_Name, level4.state_sign Level4\n",
    "                , level3.state_name Level3_Name, level3.state_sign Level3\n",
    "                ,mh.device\n",
    "                ,mh.package,\n",
    "                mh.lotid as lot,\n",
    "                mh.product,\n",
    "                mh.operation\n",
    "\n",
    "                FROM OMEDATA.EQUIPMENT_STATE_HISTORY data\n",
    "                , OMEADMIN.EQUIPMENT_INSTANCES eq\n",
    "                , V_EQ_STATES level5s\n",
    "                , OMEADMIN.DEF_STANDARD_STATEMODEL level5\n",
    "                , OMEADMIN.DEF_STANDARD_STATEMODEL level4\n",
    "                , OMEADMIN.DEF_STANDARD_STATEMODEL level3\n",
    "                , OMEDATA.METAKEY_HISTORY mh\n",
    "\n",
    "                WHERE data.eq_ident  = eq.eq_ident\n",
    "                AND  data.eq_status = level5s.state_ident(+)\n",
    "                AND level5.state_ident = data.tr25_5_status\n",
    "                AND level4.state_ident = data.tr25_4_status\n",
    "                AND level3.state_ident = data.tr25_3_status\n",
    "                AND  data.metakey_ident =mh.ident(+)\n",
    "                and data.timestamp_start > sysdate - 1500)\n",
    "                where eq_id = '{self.eq_id}'\n",
    "                ORDER BY TIMESTAMP_START\"\"\"\n",
    "\n",
    "        status = pd.read_sql(query, engine)\n",
    "        status.columns = map(lambda x: str(x).upper(), status.columns) \n",
    "\n",
    "        return status\n",
    "\n",
    "    def major_down(self, input_table, status_table, hour, threshold):\n",
    "        hour = pd.Timedelta(hours=hour)\n",
    "        major_down = []\n",
    "        \n",
    "        # timeframe table must be a subset of the status table to correctly determine major down\n",
    "        if status_table.iloc[0][\"TIMESTAMP_START\"] > input_table.iloc[0][\"TIMESTAMP_START\"]:\n",
    "            raise Exception(\"Timeframe table must be a subset of the status table\")\n",
    "        if status_table.iloc[len(status_table)-1][\"TIMESTAMP_START\"] <= input_table.iloc[len(input_table)-1][\"TIMESTAMP_START\"]:\n",
    "            raise Exception(\"Timeframe table must be a subset of the status table\")   \n",
    "            \n",
    "        for idx, row in input_table.iterrows():\n",
    "            start = row['TIMESTAMP_END']\n",
    "            end = start+hour\n",
    "            frame = status_table[(status_table['TIMESTAMP_START']>start) & (status_table['TIMESTAMP_START']<end)]\n",
    "            UD = frame.loc[frame['LEVEL3']=='UDT']\n",
    "\n",
    "            if len(UD) == 0: #no record within this 6 hours:\n",
    "                major_down.append(0)\n",
    "            else:\n",
    "                time_diff = (UD['TIMESTAMP_END']-UD['TIMESTAMP_START']).dt.seconds\n",
    "                if any(time_diff>threshold):\n",
    "                    major_down.append(1)\n",
    "                else:\n",
    "                    major_down.append(0)\n",
    "        return major_down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "baa2d728",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_full_alarm(eq_id, apc_alarm_table_path):\n",
    "    \n",
    "    alarm_apc = pd.read_excel(apc_alarm_table_path, engine=\"openpyxl\", usecols = \"B,C,D,F\")\n",
    "    start_date = sorted(alarm_apc[\"DT_SET\"].dt.date)[0]\n",
    "    start_date_STR = start_date.strftime(\"%d/%m/%Y\")\n",
    "    alarm_apc_new = alarm_apc.rename(columns={\"Equipment\": \"EQ_ID\", \"Alarm ID\": \"ALARM_ID\", \"DT_SET\": \"TIMESTAMP_START\", \"DT_CLEAR\":\"TIMESTAMP_END\"})\n",
    "    \n",
    "    try:\n",
    "        oracle_string = \"oracle+cx_oracle://{username}:{password}@{hostname}:{port}/{database}\"\n",
    "        engine = create_engine(\n",
    "            oracle_string.format(\n",
    "                username = 'TFM4CEBERUS',\n",
    "                password = 'TFM4CEBERUS',\n",
    "                hostname = 'ome-db.bth.infineon.com',\n",
    "                port = '1538',\n",
    "                database = 'ome'\n",
    "            )\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "\n",
    "    query = f\"\"\"SELECT * FROM (select ei.eq_id, ea.alarm_id, ac.name as alarm_class, ah.timestamp_start,ah.timestamp_end\n",
    "                from OMEADMIN.equipment_instances ei\n",
    "                join OMEADMIN.equipment_alarms ea on (ei.eq_type_ident(+) = ea.eq_type_ident)\n",
    "                join OMEDATA.ALARM_HISTORY ah on (ea.alarm_id = ah.alarm_id and ah.eq_ident = ei.eq_ident)\n",
    "                join OMEDATA.METAKEY_HISTORY mh on (ah.metakey_ident = mh.ident)\n",
    "                join OMEADMIN.EQUIPMENT_ALARM_CLASSES ac on (ac.IDENT = ea.ALARM_CLASS_IDENT and ac.eq_type_ident = ea.eq_type_ident)\n",
    "                where ah.timestamp_start > sysdate - 365\n",
    "                and ah.timestamp_start < sysdate -1)\n",
    "                WHERE EQ_ID = '{eq_id}'\n",
    "                ORDER BY TIMESTAMP_START\n",
    "                \"\"\"\n",
    "\n",
    "    alarm = pd.read_sql(query, engine)\n",
    "    alarm.columns = map(lambda x: str(x).upper(), alarm.columns)\n",
    "    \n",
    "    #map the alarm class\n",
    "    all_alarm_id = alarm[\"ALARM_ID\"].unique().tolist()\n",
    "    all_alarm_dict = dict.fromkeys(all_alarm_id, None)\n",
    "    \n",
    "    for key in all_alarm_dict.keys():\n",
    "        alarm_class = alarm[alarm.ALARM_ID ==key].iloc[0][\"ALARM_CLASS\"]\n",
    "        all_alarm_dict[key] = alarm_class\n",
    "    \n",
    "    alarm_apc_new[\"ALARM_CLASS\"] = alarm_apc_new[\"ALARM_ID\"].map(all_alarm_dict)\n",
    "    alarm_apc_new[\"ALARM_CLASS\"] = alarm_apc_new[\"ALARM_CLASS\"].fillna(value=\"Important Alarms\") #those alarms cannot be found in TFM must be the important alarms\n",
    "    \n",
    "    filtered_alarm = alarm.loc[alarm[\"TIMESTAMP_START\"].dt.date < start_date] # in case TFM have more data than APC, for earlier data, take from TFM\n",
    "    return pd.concat([filtered_alarm, alarm_apc_new], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7329595b",
   "metadata": {},
   "source": [
    "# 1. Padding the alarm sequence to max length to help achieve consistent input length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d0c4a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wba124_fullalarm = find_full_alarm(\"WBA124\", \"Data/WBA124_FullAlarm.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7be09286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training by looking back 12 hours of alarm data\n",
      "Epoch 1/150\n",
      "189/189 [==============================] - 96s 490ms/step - loss: 0.6948 - accuracy: 0.5970 - val_loss: 0.6766 - val_accuracy: 0.8396\n",
      "Epoch 2/150\n",
      "189/189 [==============================] - 92s 487ms/step - loss: 0.6943 - accuracy: 0.5607 - val_loss: 0.7032 - val_accuracy: 0.1604\n",
      "Epoch 3/150\n",
      "189/189 [==============================] - 91s 483ms/step - loss: 0.6951 - accuracy: 0.6291 - val_loss: 0.6885 - val_accuracy: 0.8396\n",
      "Epoch 4/150\n",
      "189/189 [==============================] - 91s 482ms/step - loss: 0.6944 - accuracy: 0.5687 - val_loss: 0.7131 - val_accuracy: 0.1604\n",
      "Epoch 5/150\n",
      "189/189 [==============================] - 91s 482ms/step - loss: 0.6936 - accuracy: 0.3570 - val_loss: 0.6986 - val_accuracy: 0.1604\n",
      "Epoch 6/150\n",
      "189/189 [==============================] - 91s 483ms/step - loss: 0.6941 - accuracy: 0.2842 - val_loss: 0.6927 - val_accuracy: 0.8396\n",
      "Epoch 7/150\n",
      "189/189 [==============================] - 91s 481ms/step - loss: 0.6931 - accuracy: 0.4571 - val_loss: 0.6966 - val_accuracy: 0.1604\n",
      "Epoch 8/150\n",
      "189/189 [==============================] - 91s 482ms/step - loss: 0.6931 - accuracy: 0.2829 - val_loss: 0.6941 - val_accuracy: 0.1604\n",
      "Epoch 9/150\n",
      "189/189 [==============================] - 91s 483ms/step - loss: 0.6931 - accuracy: 0.2304 - val_loss: 0.6932 - val_accuracy: 0.1604\n",
      "Epoch 10/150\n",
      "189/189 [==============================] - 91s 480ms/step - loss: 0.6930 - accuracy: 0.7405 - val_loss: 0.6917 - val_accuracy: 0.8396\n",
      "Epoch 11/150\n",
      "189/189 [==============================] - 91s 480ms/step - loss: 0.6931 - accuracy: 0.7194 - val_loss: 0.6949 - val_accuracy: 0.1604\n",
      "Epoch 12/150\n",
      "189/189 [==============================] - 91s 484ms/step - loss: 0.6930 - accuracy: 0.2590 - val_loss: 0.6847 - val_accuracy: 0.8396\n",
      "Epoch 13/150\n",
      "189/189 [==============================] - 91s 481ms/step - loss: 0.6933 - accuracy: 0.7432 - val_loss: 0.6940 - val_accuracy: 0.1604\n",
      "Epoch 14/150\n",
      "189/189 [==============================] - 91s 481ms/step - loss: 0.6933 - accuracy: 0.2464 - val_loss: 0.6852 - val_accuracy: 0.8396\n",
      "Epoch 15/150\n",
      "189/189 [==============================] - 91s 483ms/step - loss: 0.6945 - accuracy: 0.4197 - val_loss: 0.6936 - val_accuracy: 0.1604\n",
      "Epoch 16/150\n",
      "189/189 [==============================] - 92s 487ms/step - loss: 0.6931 - accuracy: 0.3020 - val_loss: 0.6976 - val_accuracy: 0.1604\n",
      "Epoch 17/150\n",
      "189/189 [==============================] - 91s 484ms/step - loss: 0.6933 - accuracy: 0.4893 - val_loss: 0.6910 - val_accuracy: 0.8396\n",
      "Epoch 18/150\n",
      "189/189 [==============================] - 91s 483ms/step - loss: 0.6939 - accuracy: 0.5954 - val_loss: 0.7039 - val_accuracy: 0.1604\n",
      "Epoch 19/150\n",
      "189/189 [==============================] - 91s 483ms/step - loss: 0.6933 - accuracy: 0.2120 - val_loss: 0.6038 - val_accuracy: 0.8396\n",
      "Epoch 20/150\n",
      "189/189 [==============================] - 91s 483ms/step - loss: 0.6972 - accuracy: 0.5257 - val_loss: 0.6965 - val_accuracy: 0.1604\n",
      "Epoch 21/150\n",
      "189/189 [==============================] - 91s 483ms/step - loss: 0.6934 - accuracy: 0.6394 - val_loss: 0.6867 - val_accuracy: 0.8396\n",
      "Epoch 22/150\n",
      "189/189 [==============================] - 91s 484ms/step - loss: 0.6933 - accuracy: 0.7689 - val_loss: 0.6873 - val_accuracy: 0.8396\n",
      "Epoch 23/150\n",
      "189/189 [==============================] - 91s 482ms/step - loss: 0.6932 - accuracy: 0.3487 - val_loss: 0.6927 - val_accuracy: 0.8396\n",
      "Epoch 24/150\n",
      "189/189 [==============================] - 91s 482ms/step - loss: 0.6930 - accuracy: 0.5102 - val_loss: 0.6915 - val_accuracy: 0.8396\n",
      "Epoch 25/150\n",
      "189/189 [==============================] - 91s 482ms/step - loss: 0.6931 - accuracy: 0.2241 - val_loss: 0.6911 - val_accuracy: 0.8396\n",
      "Epoch 26/150\n",
      "189/189 [==============================] - 91s 483ms/step - loss: 0.6930 - accuracy: 0.8604 - val_loss: 0.6928 - val_accuracy: 0.8396\n",
      "Epoch 27/150\n",
      "189/189 [==============================] - 91s 484ms/step - loss: 0.6931 - accuracy: 0.3952 - val_loss: 0.6956 - val_accuracy: 0.1604\n",
      "Epoch 28/150\n",
      "189/189 [==============================] - 91s 483ms/step - loss: 0.6930 - accuracy: 0.5917 - val_loss: 0.6947 - val_accuracy: 0.1604\n",
      "Epoch 29/150\n",
      "189/189 [==============================] - 91s 484ms/step - loss: 0.6931 - accuracy: 0.1672 - val_loss: 0.6946 - val_accuracy: 0.1604\n",
      "Epoch 30/150\n",
      "189/189 [==============================] - 91s 483ms/step - loss: 0.6931 - accuracy: 0.4383 - val_loss: 0.6936 - val_accuracy: 0.1604\n",
      "Epoch 31/150\n",
      "189/189 [==============================] - 92s 485ms/step - loss: 0.6931 - accuracy: 0.2085 - val_loss: 0.6930 - val_accuracy: 0.8396\n",
      "Epoch 32/150\n",
      "189/189 [==============================] - 92s 488ms/step - loss: 0.6931 - accuracy: 0.7166 - val_loss: 0.6936 - val_accuracy: 0.1604\n",
      "Epoch 33/150\n",
      "189/189 [==============================] - 92s 487ms/step - loss: 0.6933 - accuracy: 0.8614 - val_loss: 0.6927 - val_accuracy: 0.8396\n",
      "Epoch 34/150\n",
      "189/189 [==============================] - 91s 483ms/step - loss: 0.6930 - accuracy: 0.3140 - val_loss: 0.6945 - val_accuracy: 0.1604\n",
      "Epoch 35/150\n",
      "189/189 [==============================] - 92s 485ms/step - loss: 0.6930 - accuracy: 0.4976 - val_loss: 0.6929 - val_accuracy: 0.8396\n",
      "Epoch 36/150\n",
      "189/189 [==============================] - 92s 484ms/step - loss: 0.6930 - accuracy: 0.1650 - val_loss: 0.6927 - val_accuracy: 0.8396\n",
      "Epoch 37/150\n",
      "189/189 [==============================] - 91s 481ms/step - loss: 0.6931 - accuracy: 0.7840 - val_loss: 0.6932 - val_accuracy: 0.1604\n",
      "Epoch 38/150\n",
      "189/189 [==============================] - 91s 481ms/step - loss: 0.6930 - accuracy: 0.8713 - val_loss: 0.6925 - val_accuracy: 0.8396\n",
      "Epoch 39/150\n",
      "189/189 [==============================] - 91s 482ms/step - loss: 0.6933 - accuracy: 0.3367 - val_loss: 0.6704 - val_accuracy: 0.8396\n",
      "Epoch 40/150\n",
      "189/189 [==============================] - 91s 482ms/step - loss: 0.6938 - accuracy: 0.5109 - val_loss: 0.6890 - val_accuracy: 0.8396\n",
      "Epoch 41/150\n",
      "189/189 [==============================] - 91s 483ms/step - loss: 0.6932 - accuracy: 0.7933 - val_loss: 0.6901 - val_accuracy: 0.8396\n",
      "Epoch 42/150\n",
      "189/189 [==============================] - 91s 480ms/step - loss: 0.6930 - accuracy: 0.2283 - val_loss: 0.6934 - val_accuracy: 0.1604\n",
      "Epoch 43/150\n",
      "189/189 [==============================] - 91s 481ms/step - loss: 0.6935 - accuracy: 0.7606 - val_loss: 0.6924 - val_accuracy: 0.8396\n",
      "Epoch 44/150\n",
      "189/189 [==============================] - 91s 481ms/step - loss: 0.6930 - accuracy: 0.2092 - val_loss: 0.6932 - val_accuracy: 0.1604\n",
      "Epoch 45/150\n",
      "189/189 [==============================] - 91s 482ms/step - loss: 0.6934 - accuracy: 0.2525 - val_loss: 0.6879 - val_accuracy: 0.8396\n",
      "Epoch 46/150\n",
      "189/189 [==============================] - 91s 484ms/step - loss: 0.6933 - accuracy: 0.4561 - val_loss: 0.6916 - val_accuracy: 0.8396\n",
      "Epoch 47/150\n",
      "189/189 [==============================] - 91s 481ms/step - loss: 0.6940 - accuracy: 0.7081 - val_loss: 0.6952 - val_accuracy: 0.1604\n",
      "Epoch 48/150\n",
      "189/189 [==============================] - 91s 481ms/step - loss: 0.6931 - accuracy: 0.4297 - val_loss: 0.6947 - val_accuracy: 0.1604\n",
      "Epoch 49/150\n",
      "189/189 [==============================] - 91s 479ms/step - loss: 0.6930 - accuracy: 0.3360 - val_loss: 0.6951 - val_accuracy: 0.1604\n",
      "Epoch 50/150\n",
      "189/189 [==============================] - 92s 488ms/step - loss: 0.6930 - accuracy: 0.1147 - val_loss: 0.6975 - val_accuracy: 0.1604\n",
      "Epoch 51/150\n",
      "189/189 [==============================] - 91s 482ms/step - loss: 0.6930 - accuracy: 0.0933 - val_loss: 0.6943 - val_accuracy: 0.1604\n",
      "Epoch 52/150\n",
      "189/189 [==============================] - 91s 483ms/step - loss: 0.6930 - accuracy: 0.3651 - val_loss: 0.6946 - val_accuracy: 0.1604\n",
      "Epoch 53/150\n",
      "189/189 [==============================] - 91s 483ms/step - loss: 0.6930 - accuracy: 0.6445 - val_loss: 0.6954 - val_accuracy: 0.1604\n",
      "Epoch 54/150\n",
      "189/189 [==============================] - 91s 481ms/step - loss: 0.6930 - accuracy: 0.2482 - val_loss: 0.6945 - val_accuracy: 0.1604\n",
      "Epoch 55/150\n",
      "189/189 [==============================] - 91s 481ms/step - loss: 0.6931 - accuracy: 0.6354 - val_loss: 0.6937 - val_accuracy: 0.1604\n",
      "Epoch 56/150\n",
      "189/189 [==============================] - 91s 484ms/step - loss: 0.6930 - accuracy: 0.1953 - val_loss: 0.6935 - val_accuracy: 0.1604\n",
      "Epoch 57/150\n",
      "189/189 [==============================] - 92s 485ms/step - loss: 0.6930 - accuracy: 0.2597 - val_loss: 0.6936 - val_accuracy: 0.1604\n",
      "Epoch 58/150\n",
      "189/189 [==============================] - 91s 480ms/step - loss: 0.6931 - accuracy: 0.8582 - val_loss: 0.6939 - val_accuracy: 0.1604\n",
      "Epoch 59/150\n",
      "189/189 [==============================] - 91s 484ms/step - loss: 0.6930 - accuracy: 0.0936 - val_loss: 0.6947 - val_accuracy: 0.1604\n",
      "Epoch 60/150\n",
      "189/189 [==============================] - 92s 486ms/step - loss: 0.6930 - accuracy: 0.0931 - val_loss: 0.6937 - val_accuracy: 0.1604\n",
      "Epoch 61/150\n",
      "189/189 [==============================] - 91s 481ms/step - loss: 0.6931 - accuracy: 0.5258 - val_loss: 0.6912 - val_accuracy: 0.8396\n",
      "Epoch 62/150\n",
      "189/189 [==============================] - 91s 482ms/step - loss: 0.7305 - accuracy: 0.7251 - val_loss: 0.6830 - val_accuracy: 0.8396\n",
      "Epoch 63/150\n",
      "189/189 [==============================] - 91s 480ms/step - loss: 0.6971 - accuracy: 0.3648 - val_loss: 0.7019 - val_accuracy: 0.1604\n",
      "Epoch 64/150\n",
      "189/189 [==============================] - 91s 481ms/step - loss: 0.6936 - accuracy: 0.2396 - val_loss: 0.6940 - val_accuracy: 0.1604\n",
      "Epoch 65/150\n",
      "189/189 [==============================] - 91s 483ms/step - loss: 0.6935 - accuracy: 0.5569 - val_loss: 0.6920 - val_accuracy: 0.8396\n",
      "Epoch 66/150\n",
      "189/189 [==============================] - 91s 482ms/step - loss: 0.6933 - accuracy: 0.4900 - val_loss: 0.6873 - val_accuracy: 0.8396\n",
      "Epoch 67/150\n",
      "189/189 [==============================] - 91s 482ms/step - loss: 0.6930 - accuracy: 0.4991 - val_loss: 0.6893 - val_accuracy: 0.8396\n",
      "Epoch 68/150\n",
      "189/189 [==============================] - 92s 485ms/step - loss: 0.6939 - accuracy: 0.5472 - val_loss: 0.6887 - val_accuracy: 0.8396\n",
      "Epoch 69/150\n",
      "189/189 [==============================] - 92s 485ms/step - loss: 0.6935 - accuracy: 0.7226 - val_loss: 0.6892 - val_accuracy: 0.8396\n",
      "Epoch 70/150\n",
      "189/189 [==============================] - 92s 485ms/step - loss: 0.6939 - accuracy: 0.4621 - val_loss: 0.6931 - val_accuracy: 0.1673\n",
      "Epoch 71/150\n",
      "189/189 [==============================] - 91s 482ms/step - loss: 0.6935 - accuracy: 0.4413 - val_loss: 0.6919 - val_accuracy: 0.8396\n",
      "Epoch 72/150\n",
      "189/189 [==============================] - 91s 484ms/step - loss: 0.6941 - accuracy: 0.5081 - val_loss: 0.6889 - val_accuracy: 0.8396\n",
      "Epoch 73/150\n",
      "189/189 [==============================] - 91s 483ms/step - loss: 0.6932 - accuracy: 0.5514 - val_loss: 0.7058 - val_accuracy: 0.1604\n",
      "Epoch 74/150\n",
      "189/189 [==============================] - 91s 483ms/step - loss: 0.6942 - accuracy: 0.5280 - val_loss: 0.6962 - val_accuracy: 0.1604\n",
      "Epoch 75/150\n",
      "189/189 [==============================] - 91s 482ms/step - loss: 0.6936 - accuracy: 0.3631 - val_loss: 0.6920 - val_accuracy: 0.8396\n",
      "Epoch 76/150\n",
      "189/189 [==============================] - 91s 483ms/step - loss: 0.6940 - accuracy: 0.4315 - val_loss: 0.6999 - val_accuracy: 0.1604\n",
      "Epoch 77/150\n",
      "189/189 [==============================] - 92s 487ms/step - loss: 0.6928 - accuracy: 0.3696 - val_loss: 0.6675 - val_accuracy: 0.8396\n",
      "Epoch 78/150\n",
      "189/189 [==============================] - 92s 485ms/step - loss: 0.6944 - accuracy: 0.3721 - val_loss: 0.7025 - val_accuracy: 0.1604\n",
      "Epoch 79/150\n",
      "189/189 [==============================] - 92s 487ms/step - loss: 0.6936 - accuracy: 0.3712 - val_loss: 0.6944 - val_accuracy: 0.1604\n",
      "Epoch 80/150\n",
      "189/189 [==============================] - 92s 485ms/step - loss: 0.6933 - accuracy: 0.2344 - val_loss: 0.6963 - val_accuracy: 0.1604\n",
      "Epoch 81/150\n",
      "189/189 [==============================] - 92s 485ms/step - loss: 0.6932 - accuracy: 0.5633 - val_loss: 0.6979 - val_accuracy: 0.1604\n",
      "Epoch 82/150\n",
      "189/189 [==============================] - 92s 485ms/step - loss: 0.6934 - accuracy: 0.1275 - val_loss: 0.6948 - val_accuracy: 0.1604\n",
      "Epoch 83/150\n",
      "189/189 [==============================] - 92s 485ms/step - loss: 0.6931 - accuracy: 0.5816 - val_loss: 0.6953 - val_accuracy: 0.1604\n",
      "Epoch 84/150\n",
      "189/189 [==============================] - 92s 485ms/step - loss: 0.6935 - accuracy: 0.5618 - val_loss: 0.6933 - val_accuracy: 0.1604\n",
      "Epoch 85/150\n",
      "189/189 [==============================] - 91s 484ms/step - loss: 0.6933 - accuracy: 0.5555 - val_loss: 0.6973 - val_accuracy: 0.1604\n",
      "Epoch 86/150\n",
      "189/189 [==============================] - 92s 486ms/step - loss: 0.6938 - accuracy: 0.2090 - val_loss: 0.6969 - val_accuracy: 0.1604\n",
      "Epoch 87/150\n",
      "189/189 [==============================] - 91s 484ms/step - loss: 0.6930 - accuracy: 0.3583 - val_loss: 0.6985 - val_accuracy: 0.1604\n",
      "Epoch 88/150\n",
      "189/189 [==============================] - 91s 480ms/step - loss: 0.6937 - accuracy: 0.3741 - val_loss: 0.6968 - val_accuracy: 0.1604\n",
      "Epoch 89/150\n",
      "189/189 [==============================] - 92s 485ms/step - loss: 0.6930 - accuracy: 0.1971 - val_loss: 0.6959 - val_accuracy: 0.1604\n",
      "Epoch 90/150\n",
      "189/189 [==============================] - 91s 483ms/step - loss: 0.6932 - accuracy: 0.2339 - val_loss: 0.6941 - val_accuracy: 0.1604\n",
      "Epoch 91/150\n",
      "189/189 [==============================] - 92s 488ms/step - loss: 0.6934 - accuracy: 0.3628 - val_loss: 0.6890 - val_accuracy: 0.8396\n",
      "Epoch 92/150\n",
      "189/189 [==============================] - 92s 489ms/step - loss: 0.6930 - accuracy: 0.5283 - val_loss: 0.6918 - val_accuracy: 0.8396\n",
      "Epoch 93/150\n",
      "189/189 [==============================] - 92s 489ms/step - loss: 0.6930 - accuracy: 0.8614 - val_loss: 0.6930 - val_accuracy: 0.8396\n",
      "Epoch 94/150\n",
      "189/189 [==============================] - 91s 481ms/step - loss: 0.6931 - accuracy: 0.5021 - val_loss: 0.6914 - val_accuracy: 0.8396\n",
      "Epoch 95/150\n",
      "189/189 [==============================] - 91s 484ms/step - loss: 0.6932 - accuracy: 0.6020 - val_loss: 0.6939 - val_accuracy: 0.1604\n",
      "Epoch 96/150\n",
      "189/189 [==============================] - 93s 490ms/step - loss: 0.6930 - accuracy: 0.7163 - val_loss: 0.6941 - val_accuracy: 0.1604\n",
      "Epoch 97/150\n",
      "189/189 [==============================] - 92s 487ms/step - loss: 0.6938 - accuracy: 0.2459 - val_loss: 0.6960 - val_accuracy: 0.1604\n",
      "Epoch 98/150\n",
      "189/189 [==============================] - 91s 484ms/step - loss: 0.6931 - accuracy: 0.4777 - val_loss: 0.6953 - val_accuracy: 0.1604\n",
      "Epoch 99/150\n",
      "189/189 [==============================] - 91s 484ms/step - loss: 0.6935 - accuracy: 0.2424 - val_loss: 0.6960 - val_accuracy: 0.1604\n",
      "Epoch 100/150\n",
      "189/189 [==============================] - 92s 488ms/step - loss: 0.6933 - accuracy: 0.6298 - val_loss: 0.6926 - val_accuracy: 0.8396\n",
      "Epoch 101/150\n",
      "189/189 [==============================] - 92s 487ms/step - loss: 0.6928 - accuracy: 0.2401 - val_loss: 0.6987 - val_accuracy: 0.1604\n",
      "Epoch 102/150\n",
      "189/189 [==============================] - 92s 488ms/step - loss: 0.6942 - accuracy: 0.2490 - val_loss: 0.6446 - val_accuracy: 0.8396\n",
      "Epoch 103/150\n",
      "189/189 [==============================] - 92s 487ms/step - loss: 0.6934 - accuracy: 0.1997 - val_loss: 0.7028 - val_accuracy: 0.1604\n",
      "Epoch 104/150\n",
      "189/189 [==============================] - 92s 485ms/step - loss: 0.6932 - accuracy: 0.1569 - val_loss: 0.6973 - val_accuracy: 0.1604\n",
      "Epoch 105/150\n",
      "189/189 [==============================] - 91s 484ms/step - loss: 0.6928 - accuracy: 0.3621 - val_loss: 0.7018 - val_accuracy: 0.1604\n",
      "Epoch 106/150\n",
      "189/189 [==============================] - 92s 485ms/step - loss: 0.6928 - accuracy: 0.3940 - val_loss: 0.7122 - val_accuracy: 0.1604\n",
      "Epoch 107/150\n",
      "189/189 [==============================] - 92s 488ms/step - loss: 0.6932 - accuracy: 0.2175 - val_loss: 0.7059 - val_accuracy: 0.1604\n",
      "Epoch 108/150\n",
      "189/189 [==============================] - 92s 487ms/step - loss: 0.6939 - accuracy: 0.2202 - val_loss: 0.7017 - val_accuracy: 0.1604\n",
      "Epoch 109/150\n",
      "189/189 [==============================] - 92s 485ms/step - loss: 0.6936 - accuracy: 0.3023 - val_loss: 0.6980 - val_accuracy: 0.1604\n",
      "Epoch 110/150\n",
      "189/189 [==============================] - 92s 486ms/step - loss: 0.6922 - accuracy: 0.2457 - val_loss: 0.7008 - val_accuracy: 0.1604\n",
      "Epoch 111/150\n",
      "189/189 [==============================] - 93s 495ms/step - loss: 0.6943 - accuracy: 0.3624 - val_loss: 0.7027 - val_accuracy: 0.1604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/150\n",
      "189/189 [==============================] - 91s 484ms/step - loss: 0.6934 - accuracy: 0.3350 - val_loss: 0.7025 - val_accuracy: 0.1604\n",
      "Epoch 113/150\n",
      "189/189 [==============================] - 90s 479ms/step - loss: 0.6930 - accuracy: 0.2720 - val_loss: 0.7009 - val_accuracy: 0.1604\n",
      "Epoch 114/150\n",
      "189/189 [==============================] - 78s 412ms/step - loss: 0.6931 - accuracy: 0.3246 - val_loss: 0.6988 - val_accuracy: 0.1604\n",
      "Epoch 115/150\n",
      "189/189 [==============================] - 78s 414ms/step - loss: 0.6932 - accuracy: 0.1602 - val_loss: 0.6963 - val_accuracy: 0.1604\n",
      "Epoch 116/150\n",
      "189/189 [==============================] - 87s 461ms/step - loss: 0.6931 - accuracy: 0.1753 - val_loss: 0.6938 - val_accuracy: 0.1604\n",
      "Epoch 117/150\n",
      "189/189 [==============================] - 92s 486ms/step - loss: 0.6930 - accuracy: 0.6674 - val_loss: 0.6929 - val_accuracy: 0.8396\n",
      "Epoch 118/150\n",
      "189/189 [==============================] - 92s 485ms/step - loss: 0.6936 - accuracy: 0.5743 - val_loss: 0.6954 - val_accuracy: 0.1604\n",
      "Epoch 119/150\n",
      "189/189 [==============================] - 91s 482ms/step - loss: 0.6930 - accuracy: 0.4011 - val_loss: 0.6949 - val_accuracy: 0.1604\n",
      "Epoch 120/150\n",
      "189/189 [==============================] - 91s 480ms/step - loss: 0.6935 - accuracy: 0.7534 - val_loss: 0.6965 - val_accuracy: 0.1604\n",
      "Epoch 121/150\n",
      "189/189 [==============================] - 92s 487ms/step - loss: 0.6931 - accuracy: 0.2796 - val_loss: 0.6985 - val_accuracy: 0.1604\n",
      "Epoch 122/150\n",
      "189/189 [==============================] - 92s 484ms/step - loss: 0.6932 - accuracy: 0.3849 - val_loss: 0.6955 - val_accuracy: 0.1604\n",
      "Epoch 123/150\n",
      "189/189 [==============================] - 91s 484ms/step - loss: 0.6929 - accuracy: 0.1091 - val_loss: 0.6945 - val_accuracy: 0.1604\n",
      "Epoch 124/150\n",
      "189/189 [==============================] - 92s 486ms/step - loss: 0.6933 - accuracy: 0.3045 - val_loss: 0.6925 - val_accuracy: 0.8396\n",
      "Epoch 125/150\n",
      "189/189 [==============================] - 92s 485ms/step - loss: 0.6933 - accuracy: 0.8094 - val_loss: 0.6940 - val_accuracy: 0.1604\n",
      "Epoch 126/150\n",
      "189/189 [==============================] - 92s 486ms/step - loss: 0.6935 - accuracy: 0.2824 - val_loss: 0.6985 - val_accuracy: 0.1604\n",
      "Epoch 127/150\n",
      "189/189 [==============================] - 91s 479ms/step - loss: 0.6942 - accuracy: 0.4513 - val_loss: 0.7017 - val_accuracy: 0.1604\n",
      "Epoch 128/150\n",
      "189/189 [==============================] - 91s 483ms/step - loss: 0.6936 - accuracy: 0.1698 - val_loss: 0.7065 - val_accuracy: 0.1604\n",
      "Epoch 129/150\n",
      "189/189 [==============================] - 91s 482ms/step - loss: 0.6933 - accuracy: 0.2258 - val_loss: 0.6961 - val_accuracy: 0.1604\n",
      "Epoch 130/150\n",
      "189/189 [==============================] - 91s 482ms/step - loss: 0.6933 - accuracy: 0.6361 - val_loss: 0.6981 - val_accuracy: 0.1604\n",
      "Epoch 131/150\n",
      "189/189 [==============================] - 92s 486ms/step - loss: 0.6931 - accuracy: 0.1511 - val_loss: 0.6980 - val_accuracy: 0.1604\n",
      "Epoch 132/150\n",
      "189/189 [==============================] - 91s 484ms/step - loss: 0.6922 - accuracy: 0.6429 - val_loss: 0.6939 - val_accuracy: 0.1604\n",
      "Epoch 133/150\n",
      "189/189 [==============================] - 91s 482ms/step - loss: 0.6939 - accuracy: 0.3678 - val_loss: 0.7025 - val_accuracy: 0.1604\n",
      "Epoch 134/150\n",
      "189/189 [==============================] - 92s 486ms/step - loss: 0.6947 - accuracy: 0.2248 - val_loss: 0.7023 - val_accuracy: 0.1604\n",
      "Epoch 135/150\n",
      "189/189 [==============================] - 91s 481ms/step - loss: 0.6934 - accuracy: 0.1325 - val_loss: 0.6967 - val_accuracy: 0.1604\n",
      "Epoch 136/150\n",
      "189/189 [==============================] - 92s 485ms/step - loss: 0.6933 - accuracy: 0.3349 - val_loss: 0.6952 - val_accuracy: 0.1604\n",
      "Epoch 137/150\n",
      "189/189 [==============================] - 91s 484ms/step - loss: 0.6930 - accuracy: 0.1171 - val_loss: 0.6948 - val_accuracy: 0.1604\n",
      "Epoch 138/150\n",
      "189/189 [==============================] - 92s 485ms/step - loss: 0.6930 - accuracy: 0.3734 - val_loss: 0.6949 - val_accuracy: 0.1604\n",
      "Epoch 139/150\n",
      "189/189 [==============================] - 91s 481ms/step - loss: 0.6930 - accuracy: 0.3151 - val_loss: 0.6966 - val_accuracy: 0.1604\n",
      "Epoch 140/150\n",
      "189/189 [==============================] - 92s 487ms/step - loss: 0.6936 - accuracy: 0.3121 - val_loss: 0.6959 - val_accuracy: 0.1604\n",
      "Epoch 141/150\n",
      "189/189 [==============================] - 92s 486ms/step - loss: 0.6931 - accuracy: 0.1290 - val_loss: 0.6942 - val_accuracy: 0.1604\n",
      "Epoch 142/150\n",
      "189/189 [==============================] - 91s 484ms/step - loss: 0.6930 - accuracy: 0.7242 - val_loss: 0.6940 - val_accuracy: 0.1604\n",
      "Epoch 143/150\n",
      "189/189 [==============================] - 92s 485ms/step - loss: 0.6931 - accuracy: 0.7637 - val_loss: 0.6952 - val_accuracy: 0.1604\n",
      "Epoch 144/150\n",
      "189/189 [==============================] - 91s 482ms/step - loss: 0.6932 - accuracy: 0.1491 - val_loss: 0.6951 - val_accuracy: 0.1604\n",
      "Epoch 145/150\n",
      "189/189 [==============================] - 91s 484ms/step - loss: 0.6933 - accuracy: 0.2735 - val_loss: 0.6934 - val_accuracy: 0.1604\n",
      "Epoch 146/150\n",
      "189/189 [==============================] - 91s 482ms/step - loss: 0.6931 - accuracy: 0.3701 - val_loss: 0.6921 - val_accuracy: 0.8396\n",
      "Epoch 147/150\n",
      "189/189 [==============================] - 92s 485ms/step - loss: 0.6929 - accuracy: 0.7163 - val_loss: 0.6957 - val_accuracy: 0.1604\n",
      "Epoch 148/150\n",
      "189/189 [==============================] - 92s 485ms/step - loss: 0.6933 - accuracy: 0.2984 - val_loss: 0.6950 - val_accuracy: 0.1604\n",
      "Epoch 149/150\n",
      "189/189 [==============================] - 91s 483ms/step - loss: 0.6931 - accuracy: 0.7008 - val_loss: 0.6935 - val_accuracy: 0.1604\n",
      "Epoch 150/150\n",
      "189/189 [==============================] - 92s 486ms/step - loss: 0.6931 - accuracy: 0.6631 - val_loss: 0.6956 - val_accuracy: 0.1604\n",
      "27/27 [==============================] - 4s 141ms/step - loss: 0.6961 - accuracy: 0.0894\n",
      "Training took a total of 13819 seconds\n"
     ]
    }
   ],
   "source": [
    "# seq_result = {}\n",
    "# lookback = [6,12,18,24,48,72]\n",
    "# for hour in lookback:\n",
    "hour = 12\n",
    "start = datetime.now()\n",
    "print(f\"Training by looking back {hour} hours of alarm data\")\n",
    "wba124 = seven_days_LSTM(\"WBA124\", wba124_fullalarm, hour, 3)\n",
    "\n",
    "# pad the alarm to train on LSTM\n",
    "unpadded_arr = wba124.X_seq\n",
    "padded_alarm = np.zeros([len(unpadded_arr),len(max(unpadded_arr,key = lambda x: len(x)))])\n",
    "for i,j in enumerate(unpadded_arr):\n",
    "     padded_alarm[i][0:len(j)] = j\n",
    "\n",
    "# scale training data for the model to learn faster, because max length is taking the model too long to train per epoch\n",
    "scaler = StandardScaler()\n",
    "scaled_X_seq = scaler.fit_transform(padded_alarm)\n",
    "\n",
    "#train_val_test split\n",
    "val_percentage = 0.2\n",
    "test_percentage = 0.1\n",
    "\n",
    "test_index = int(len(scaled_X_seq) * (1-test_percentage))\n",
    "val_index = int(len(scaled_X_seq) * (1- val_percentage - test_percentage))\n",
    "\n",
    "X_train_seq, X_val_seq, X_test_seq = scaled_X_seq[:val_index], scaled_X_seq[val_index:test_index], scaled_X_seq[test_index:]\n",
    "y_train_seq, y_val_seq, y_test_seq = wba124.y[:val_index], wba124.y[val_index:test_index], wba124.y[test_index:]\n",
    "\n",
    "X_train_seq = X_train_seq.reshape(X_train_seq.shape[0], X_train_seq.shape[1], 1)\n",
    "X_val_seq = X_val_seq.reshape(X_val_seq.shape[0], X_val_seq.shape[1], 1)\n",
    "X_test_seq = X_test_seq.reshape(X_test_seq.shape[0], X_test_seq.shape[1], 1)\n",
    "\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                             np.unique(y_train_seq),\n",
    "                                             y_train_seq)\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "\n",
    "#need to reinitialize the model because x_train_seq changes in shape\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(X_train_seq.shape[1:]), return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(LSTM(64, input_shape=(X_train_seq.shape[1:])))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(32, activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(2, activation = 'softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train_seq, y_train_seq, \n",
    "                batch_size=BATCH_SIZE, epochs=EPOCHS, \n",
    "                validation_data=(X_val_seq, y_val_seq), \n",
    "                class_weight=class_weights_dict)\n",
    "evaluate = model.evaluate(X_test_seq, y_test_seq) #loss, mse\n",
    "\n",
    "end = datetime.now()\n",
    "time = end - start\n",
    "print(f\"Training took a total of {time.seconds} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a9bed4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, [0.6960725784301758, 0.08943089097738266])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hour, evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28605e22",
   "metadata": {},
   "source": [
    "## 2. Padding the sequence with the average length\n",
    "#### https://towardsdatascience.com/using-tensorflow-ragged-tensors-2af07849a7bd\n",
    "#### Apparently can also greatly help boost accracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb3be33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wba124_fullalarm = find_full_alarm(\"WBA124\", \"Data/WBA124_FullAlarm.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70942ac3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training by looking back 6 hours of alarm data\n",
      "Epoch 1/150\n",
      "189/189 [==============================] - 7s 18ms/step - loss: 0.6948 - accuracy: 0.6301 - val_loss: 0.6975 - val_accuracy: 0.1649\n",
      "Epoch 2/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.6955 - accuracy: 0.4774 - val_loss: 0.6836 - val_accuracy: 0.7718\n",
      "Epoch 3/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.6945 - accuracy: 0.4411 - val_loss: 0.6766 - val_accuracy: 0.7816\n",
      "Epoch 4/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.6948 - accuracy: 0.4905 - val_loss: 0.6793 - val_accuracy: 0.7729\n",
      "Epoch 5/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.6951 - accuracy: 0.3723 - val_loss: 0.6520 - val_accuracy: 0.7898\n",
      "Epoch 6/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.6938 - accuracy: 0.3476 - val_loss: 0.7000 - val_accuracy: 0.1626\n",
      "Epoch 7/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.6943 - accuracy: 0.4866 - val_loss: 0.7106 - val_accuracy: 0.1603\n",
      "Epoch 8/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.6932 - accuracy: 0.3473 - val_loss: 0.6687 - val_accuracy: 0.8043\n",
      "Epoch 9/150\n",
      "189/189 [==============================] - 3s 13ms/step - loss: 0.6926 - accuracy: 0.5315 - val_loss: 0.6927 - val_accuracy: 0.7660\n",
      "Epoch 10/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.6938 - accuracy: 0.4047 - val_loss: 0.7122 - val_accuracy: 0.1597\n",
      "Epoch 11/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.6925 - accuracy: 0.4226 - val_loss: 0.6741 - val_accuracy: 0.7706\n",
      "Epoch 12/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.6936 - accuracy: 0.4879 - val_loss: 0.6809 - val_accuracy: 0.7741\n",
      "Epoch 13/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.6926 - accuracy: 0.4748 - val_loss: 0.6616 - val_accuracy: 0.8130\n",
      "Epoch 14/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.6934 - accuracy: 0.4992 - val_loss: 0.6717 - val_accuracy: 0.7956\n",
      "Epoch 15/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.6929 - accuracy: 0.5110 - val_loss: 0.6948 - val_accuracy: 0.7747\n",
      "Epoch 16/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.6950 - accuracy: 0.4482 - val_loss: 0.7011 - val_accuracy: 0.1597\n",
      "Epoch 17/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.6923 - accuracy: 0.3984 - val_loss: 0.6710 - val_accuracy: 0.7915\n",
      "Epoch 18/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.6932 - accuracy: 0.5045 - val_loss: 0.6752 - val_accuracy: 0.7863\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.6826 - accuracy: 0.6365\n",
      "Training took a total of 170 seconds\n",
      "Training by looking back 12 hours of alarm data\n",
      "Epoch 1/150\n",
      "189/189 [==============================] - 9s 31ms/step - loss: 0.6986 - accuracy: 0.4835 - val_loss: 0.7120 - val_accuracy: 0.2138\n",
      "Epoch 2/150\n",
      "189/189 [==============================] - 5s 26ms/step - loss: 0.6953 - accuracy: 0.5132 - val_loss: 0.7598 - val_accuracy: 0.1702\n",
      "Epoch 3/150\n",
      "189/189 [==============================] - 5s 26ms/step - loss: 0.6933 - accuracy: 0.5811 - val_loss: 0.6939 - val_accuracy: 0.1993\n",
      "Epoch 4/150\n",
      "189/189 [==============================] - 5s 26ms/step - loss: 0.6942 - accuracy: 0.4911 - val_loss: 0.6556 - val_accuracy: 0.8013\n",
      "Epoch 5/150\n",
      "189/189 [==============================] - 5s 25ms/step - loss: 0.6939 - accuracy: 0.6153 - val_loss: 0.6857 - val_accuracy: 0.7879\n",
      "Epoch 6/150\n",
      "189/189 [==============================] - 4s 23ms/step - loss: 0.6936 - accuracy: 0.5034 - val_loss: 0.7119 - val_accuracy: 0.1604\n",
      "Epoch 7/150\n",
      "189/189 [==============================] - 4s 23ms/step - loss: 0.6930 - accuracy: 0.4053 - val_loss: 0.6773 - val_accuracy: 0.8013\n",
      "Epoch 8/150\n",
      "189/189 [==============================] - 5s 24ms/step - loss: 0.6922 - accuracy: 0.6399 - val_loss: 0.6969 - val_accuracy: 0.7699\n",
      "Epoch 9/150\n",
      "189/189 [==============================] - 4s 23ms/step - loss: 0.6924 - accuracy: 0.5408 - val_loss: 0.6778 - val_accuracy: 0.7908\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.6906 - accuracy: 0.6156\n",
      "Training took a total of 181 seconds\n",
      "Training by looking back 18 hours of alarm data\n",
      "Epoch 1/150\n",
      "189/189 [==============================] - 11s 39ms/step - loss: 0.6987 - accuracy: 0.5272 - val_loss: 0.6318 - val_accuracy: 0.7936\n",
      "Epoch 2/150\n",
      "189/189 [==============================] - 6s 33ms/step - loss: 0.6946 - accuracy: 0.5586 - val_loss: 0.7075 - val_accuracy: 0.1605\n",
      "Epoch 3/150\n",
      "189/189 [==============================] - 6s 32ms/step - loss: 0.6932 - accuracy: 0.4993 - val_loss: 0.7159 - val_accuracy: 0.1622\n",
      "Epoch 4/150\n",
      "189/189 [==============================] - 6s 32ms/step - loss: 0.6935 - accuracy: 0.4824 - val_loss: 0.6240 - val_accuracy: 0.7890\n",
      "Epoch 5/150\n",
      "189/189 [==============================] - 6s 33ms/step - loss: 0.6924 - accuracy: 0.4560 - val_loss: 0.6927 - val_accuracy: 0.7698\n",
      "Epoch 6/150\n",
      "189/189 [==============================] - 6s 32ms/step - loss: 0.6929 - accuracy: 0.4777 - val_loss: 0.7067 - val_accuracy: 0.1640\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 0.7177 - accuracy: 0.0964\n",
      "Training took a total of 186 seconds\n",
      "Training by looking back 24 hours of alarm data\n",
      "Epoch 1/150\n",
      "189/189 [==============================] - 12s 48ms/step - loss: 0.6980 - accuracy: 0.6038 - val_loss: 0.7011 - val_accuracy: 0.1605\n",
      "Epoch 2/150\n",
      "189/189 [==============================] - 8s 44ms/step - loss: 0.6949 - accuracy: 0.4505 - val_loss: 0.6871 - val_accuracy: 0.7756\n",
      "Epoch 3/150\n",
      "189/189 [==============================] - 9s 46ms/step - loss: 0.6935 - accuracy: 0.5121 - val_loss: 0.6926 - val_accuracy: 0.2157\n",
      "Epoch 4/150\n",
      "189/189 [==============================] - 9s 46ms/step - loss: 0.6950 - accuracy: 0.5334 - val_loss: 0.7098 - val_accuracy: 0.1605\n",
      "Epoch 5/150\n",
      "189/189 [==============================] - 9s 48ms/step - loss: 0.6937 - accuracy: 0.2520 - val_loss: 0.6483 - val_accuracy: 0.7971\n",
      "Epoch 6/150\n",
      "189/189 [==============================] - 9s 48ms/step - loss: 0.6951 - accuracy: 0.5070 - val_loss: 0.6827 - val_accuracy: 0.8174\n",
      "Epoch 7/150\n",
      "189/189 [==============================] - 9s 48ms/step - loss: 0.6940 - accuracy: 0.5154 - val_loss: 0.6744 - val_accuracy: 0.7733\n",
      "Epoch 8/150\n",
      "189/189 [==============================] - 9s 48ms/step - loss: 0.6930 - accuracy: 0.5493 - val_loss: 0.6749 - val_accuracy: 0.7750\n",
      "Epoch 9/150\n",
      "189/189 [==============================] - 9s 48ms/step - loss: 0.6934 - accuracy: 0.4654 - val_loss: 0.7070 - val_accuracy: 0.1605\n",
      "Epoch 10/150\n",
      "189/189 [==============================] - 9s 48ms/step - loss: 0.6983 - accuracy: 0.2895 - val_loss: 0.6706 - val_accuracy: 0.7872\n",
      "Epoch 11/150\n",
      "189/189 [==============================] - 9s 47ms/step - loss: 0.6943 - accuracy: 0.4953 - val_loss: 0.7087 - val_accuracy: 0.1872\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.7061 - accuracy: 0.2602\n",
      "Training took a total of 250 seconds\n",
      "Training by looking back 48 hours of alarm data\n",
      "Epoch 1/150\n",
      "188/188 [==============================] - 21s 93ms/step - loss: 0.6977 - accuracy: 0.4881 - val_loss: 0.7178 - val_accuracy: 0.1595\n",
      "Epoch 2/150\n",
      "188/188 [==============================] - 17s 90ms/step - loss: 0.6938 - accuracy: 0.5109 - val_loss: 0.6980 - val_accuracy: 0.2002\n",
      "Epoch 3/150\n",
      "188/188 [==============================] - 16s 88ms/step - loss: 0.6942 - accuracy: 0.4994 - val_loss: 0.6886 - val_accuracy: 0.8399\n",
      "Epoch 4/150\n",
      "188/188 [==============================] - 16s 85ms/step - loss: 0.6938 - accuracy: 0.5832 - val_loss: 0.7020 - val_accuracy: 0.2381\n",
      "Epoch 5/150\n",
      "188/188 [==============================] - 16s 85ms/step - loss: 0.6951 - accuracy: 0.6264 - val_loss: 0.6949 - val_accuracy: 0.2340\n",
      "Epoch 6/150\n",
      "188/188 [==============================] - 16s 83ms/step - loss: 0.6941 - accuracy: 0.5012 - val_loss: 0.6832 - val_accuracy: 0.8405\n",
      "Epoch 7/150\n",
      "188/188 [==============================] - 16s 83ms/step - loss: 0.6932 - accuracy: 0.6663 - val_loss: 0.6892 - val_accuracy: 0.8405\n",
      "Epoch 8/150\n",
      "188/188 [==============================] - 16s 86ms/step - loss: 0.6951 - accuracy: 0.5628 - val_loss: 0.7082 - val_accuracy: 0.1601\n",
      "Epoch 9/150\n",
      "188/188 [==============================] - 17s 90ms/step - loss: 0.6937 - accuracy: 0.3852 - val_loss: 0.7015 - val_accuracy: 0.2194\n",
      "Epoch 10/150\n",
      "188/188 [==============================] - 17s 91ms/step - loss: 0.6926 - accuracy: 0.4746 - val_loss: 0.6675 - val_accuracy: 0.8376\n",
      "Epoch 11/150\n",
      "188/188 [==============================] - 17s 91ms/step - loss: 0.6941 - accuracy: 0.5338 - val_loss: 0.6857 - val_accuracy: 0.8306\n",
      "27/27 [==============================] - 1s 26ms/step - loss: 0.6757 - accuracy: 0.8802\n",
      "Training took a total of 371 seconds\n",
      "Training by looking back 72 hours of alarm data\n",
      "Epoch 1/150\n",
      "188/188 [==============================] - 25s 116ms/step - loss: 0.6975 - accuracy: 0.5463 - val_loss: 0.7069 - val_accuracy: 0.1590\n",
      "Epoch 2/150\n",
      "188/188 [==============================] - 21s 112ms/step - loss: 0.6960 - accuracy: 0.4468 - val_loss: 0.6872 - val_accuracy: 0.8218\n",
      "Epoch 3/150\n",
      "188/188 [==============================] - 21s 112ms/step - loss: 0.6960 - accuracy: 0.4152 - val_loss: 0.7148 - val_accuracy: 0.1584\n",
      "Epoch 4/150\n",
      "188/188 [==============================] - 21s 112ms/step - loss: 0.6948 - accuracy: 0.4342 - val_loss: 0.7036 - val_accuracy: 0.1584\n",
      "Epoch 5/150\n",
      "188/188 [==============================] - 21s 111ms/step - loss: 0.6948 - accuracy: 0.3824 - val_loss: 0.7017 - val_accuracy: 0.1590\n",
      "Epoch 6/150\n",
      "188/188 [==============================] - 21s 113ms/step - loss: 0.6939 - accuracy: 0.3550 - val_loss: 0.7132 - val_accuracy: 0.1578\n",
      "Epoch 7/150\n",
      "188/188 [==============================] - 21s 112ms/step - loss: 0.6943 - accuracy: 0.3784 - val_loss: 0.6925 - val_accuracy: 0.2330\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 0.6837 - accuracy: 0.5308\n",
      "Training took a total of 397 seconds\n"
     ]
    }
   ],
   "source": [
    "seq_result = {}\n",
    "lookback = [6,12,18,24,48,72]\n",
    "for hour in lookback:\n",
    "    start = datetime.now()\n",
    "    print(f\"Training by looking back {hour} hours of alarm data\")\n",
    "    wba124 = seven_days_LSTM(\"WBA124\", wba124_fullalarm, hour, 3)\n",
    "\n",
    "    # pad the alarm to train on LSTM\n",
    "    unpadded_arr = wba124.X_seq\n",
    "    mean_length = int(np.mean([len(x) for x in unpadded_arr]))\n",
    "    padded_alarm = np.zeros([len(unpadded_arr), mean_length])\n",
    "    for i,j in enumerate(unpadded_arr):\n",
    "        padded_alarm[i][0:len(j)] = j[:mean_length]\n",
    "\n",
    "    # scale training data for the model to learn faster\n",
    "    scaler = StandardScaler()\n",
    "    scaled_X_seq = scaler.fit_transform(padded_alarm)\n",
    "\n",
    "    #train_val_test split\n",
    "    val_percentage = 0.2\n",
    "    test_percentage = 0.1\n",
    "\n",
    "    test_index = int(len(scaled_X_seq) * (1-test_percentage))\n",
    "    val_index = int(len(scaled_X_seq) * (1- val_percentage - test_percentage))\n",
    "\n",
    "    X_train_seq, X_val_seq, X_test_seq = scaled_X_seq[:val_index], scaled_X_seq[val_index:test_index], scaled_X_seq[test_index:]\n",
    "    y_train_seq, y_val_seq, y_test_seq = wba124.y[:val_index], wba124.y[val_index:test_index], wba124.y[test_index:]\n",
    "\n",
    "    X_train_seq = X_train_seq.reshape(X_train_seq.shape[0], X_train_seq.shape[1], 1)\n",
    "    X_val_seq = X_val_seq.reshape(X_val_seq.shape[0], X_val_seq.shape[1], 1)\n",
    "    X_test_seq = X_test_seq.reshape(X_test_seq.shape[0], X_test_seq.shape[1], 1)\n",
    "\n",
    "    class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(y_train_seq),\n",
    "                                                 y_train_seq)\n",
    "    class_weights_dict = dict(enumerate(class_weights))\n",
    "\n",
    "    #need to reinitialize the model because x_train_seq changes in shape\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, input_shape=(X_train_seq.shape[1:]), return_sequences=True))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(LSTM(64, input_shape=(X_train_seq.shape[1:])))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(32, activation = 'relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(2, activation = 'softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    callbacks = [EarlyStopping(monitor='val_accuracy', mode='max', patience=5)]\n",
    "\n",
    "    history = model.fit(X_train_seq, y_train_seq, \n",
    "                    batch_size=BATCH_SIZE, epochs=EPOCHS, \n",
    "                    validation_data=(X_val_seq, y_val_seq), \n",
    "                    class_weight=class_weights_dict, callbacks=callbacks)\n",
    "    \n",
    "    evaluate = model.evaluate(X_test_seq, y_test_seq) #loss, mse\n",
    "\n",
    "    end = datetime.now()\n",
    "    time = end - start\n",
    "    seq_result[hour, mean_length] = evaluate\n",
    "    print(f\"Training took a total of {time.seconds} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e68372e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(6, 9): [0.6825759410858154, 0.6364692449569702],\n",
       " (12, 19): [0.6905587315559387, 0.6155632734298706],\n",
       " (18, 28): [0.7176927924156189, 0.09639953821897507],\n",
       " (24, 38): [0.7060851454734802, 0.2601625919342041],\n",
       " (48, 76): [0.6757280826568604, 0.880232572555542],\n",
       " (72, 114): [0.6836994290351868, 0.530849814414978]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6aad2f7",
   "metadata": {},
   "source": [
    "# 3. Training with Embedding layer\n",
    "### LabelEncode the alarm id to determine n_vocab in Embedding layer\n",
    "### Since max_vocab measures the maximum number of unique vocab in our input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc33a2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encode(X_seq): # do this the manual way as we are not certain if sklearn LabelEncoder can handle 3D array\n",
    "    all_unique_alarms = [set(ele) for ele in X_seq]\n",
    "    unique_alarms = set()\n",
    "    for ele in all_unique_alarms:\n",
    "        unique_alarms |= ele\n",
    "    \n",
    "    enc_label = 1  #start encoding from 1 as we have to pad the sequence with 0\n",
    "    mapping_dict = {}\n",
    "    for ele in unique_alarms:\n",
    "        mapping_dict[ele] = enc_label\n",
    "        enc_label += 1\n",
    "\n",
    "        enc_array = []\n",
    "        \n",
    "    #X_seq is a 3D array\n",
    "    for timestamp in X_seq:\n",
    "        tmp_arr = []\n",
    "        for ele in timestamp:\n",
    "            tmp_arr.append(mapping_dict[ele])\n",
    "        enc_array.append(np.array(tmp_arr))\n",
    "\n",
    "    return np.array(enc_array), len(unique_alarms)+1, mapping_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28197e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(X_train, n_alarm):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=n_alarm, output_dim=10, input_length=X_train.shape[1], mask_zero=True))\n",
    "    model.add(Conv1D(256, kernel_size=3, strides=2, activation='relu'))\n",
    "    model.add(Conv1D(128, 3, activation='relu'))\n",
    "\n",
    "    model.add(LSTM(256, return_sequences=True, activation='relu'))\n",
    "    model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
    "    model.add(LSTM(64))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), 'accuracy'])\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb9cc591",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seq_result = {}\n",
    "lookback = [12, 24, 48, 72]\n",
    "\n",
    "monitor = 'val_recall'\n",
    "mode = 'max'\n",
    "hour = 24\n",
    "\n",
    "wba127_fullalarm = pd.read_excel(\"../Data/WBA127_FullAlarm.xlsx\", usecols = \"B,C,D,F,M\")\n",
    "wba127 = seven_days_LSTM(\"WBA127\", wba127_fullalarm, hour, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abe426d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_X_seq, n_alarms, mapping_dict = label_encode(wba127.X_seq)\n",
    "target = wba127.major_down_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfc96a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove empty sentences\n",
    "encoded_X_seq_r = []\n",
    "target_r = []\n",
    "\n",
    "for idx, ele in enumerate(encoded_X_seq):\n",
    "    if len(ele)!=0:\n",
    "        encoded_X_seq_r.append(ele)\n",
    "        target_r.append(target[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2aa23fb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# padding to average length\n",
    "avg_len = int(np.mean([len(ele) for ele in encoded_X_seq_r]))\n",
    "\n",
    "padded_alarm = pad_sequences(encoded_X_seq_r,\n",
    "                             maxlen=avg_len, \n",
    "                             padding='pre',\n",
    "                            truncating='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a6d8a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = int(0.7*len(padded_alarm))\n",
    "val_idx = int(0.8*(len(padded_alarm)))\n",
    "\n",
    "X_train, y_train = padded_alarm[:train_idx], np.array(target_r[:train_idx])\n",
    "X_val, y_val = padded_alarm[train_idx:val_idx], np.array(target_r[train_idx:val_idx])\n",
    "X_test, y_test = padded_alarm[val_idx:], np.array(target_r[val_idx:])\n",
    "\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                             np.unique(y_train),\n",
    "                                             y_train)\n",
    "class_weights_dict = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "746a0e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 68, 10)            460       \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 33, 256)           7936      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 31, 128)           98432     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 31, 256)           394240    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 31, 128)           197120    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 749,709\n",
      "Trainable params: 749,709\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = create_model(X_train, n_alarms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2795b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 68, 10)            460       \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 33, 256)           7936      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 31, 128)           98432     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 31, 256)           394240    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 31, 128)           197120    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 749,709\n",
      "Trainable params: 749,709\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/300\n",
      "166/166 [==============================] - 18s 83ms/step - loss: 0.6850 - precision: 0.1359 - recall: 0.4711 - accuracy: 0.6429 - val_loss: 0.7125 - val_precision: 0.0693 - val_recall: 0.7568 - val_accuracy: 0.4914\n",
      "Epoch 2/300\n",
      "166/166 [==============================] - 13s 78ms/step - loss: 0.6689 - precision: 0.1483 - recall: 0.6052 - accuracy: 0.6078 - val_loss: 0.8702 - val_precision: 0.0552 - val_recall: 0.8649 - val_accuracy: 0.2695\n",
      "Epoch 3/300\n",
      "166/166 [==============================] - 12s 75ms/step - loss: 0.6785 - precision: 0.1275 - recall: 0.5512 - accuracy: 0.5723 - val_loss: 0.7941 - val_precision: 0.0489 - val_recall: 1.0000 - val_accuracy: 0.0489\n",
      "Epoch 4/300\n",
      "166/166 [==============================] - 12s 75ms/step - loss: 0.6918 - precision: 0.1098 - recall: 0.5587 - accuracy: 0.4960 - val_loss: 0.7444 - val_precision: 0.0489 - val_recall: 1.0000 - val_accuracy: 0.0489\n",
      "Epoch 5/300\n",
      "166/166 [==============================] - 12s 74ms/step - loss: 0.6805 - precision: 0.1413 - recall: 0.4972 - accuracy: 0.6429 - val_loss: 0.8090 - val_precision: 0.0625 - val_recall: 0.7297 - val_accuracy: 0.4518\n",
      "Epoch 6/300\n",
      "166/166 [==============================] - 12s 75ms/step - loss: 0.6722 - precision: 0.1732 - recall: 0.4209 - accuracy: 0.7376 - val_loss: 0.7137 - val_precision: 0.0673 - val_recall: 0.7297 - val_accuracy: 0.4927\n",
      "Epoch 7/300\n",
      "166/166 [==============================] - 12s 75ms/step - loss: 0.6883 - precision: 0.1156 - recall: 0.5866 - accuracy: 0.5034 - val_loss: 0.7240 - val_precision: 0.0489 - val_recall: 1.0000 - val_accuracy: 0.0489\n",
      "Epoch 8/300\n",
      " 67/166 [===========>..................] - ETA: 7s - loss: 0.7390 - precision: 0.1141 - recall: 0.9163 - accuracy: 0.1572"
     ]
    }
   ],
   "source": [
    "model = create_model(X_train, n_alarms)\n",
    "\n",
    "# model seems to be overfitting, try to reduce overfitting by reduce LR, but model should take longer to converge so use a larger EPOCH\n",
    "callbacks = [ReduceLROnPlateau(monitor=monitor, factor=0.2, patience=5, min_lr=0.001), \\\n",
    "            EarlyStopping(monitor=monitor, patience=30, mode=mode, restore_best_weights=True)]\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                batch_size=BATCH_SIZE, epochs=EPOCHS, \n",
    "                validation_data=(X_val, y_val),\n",
    "                class_weight=class_weights_dict,\n",
    "                callbacks=callbacks)\n",
    "\n",
    "evaluate = model.evaluate(X_test, y_test) #loss, mse\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "classes = []\n",
    "for ele in pred:\n",
    "    classes.append(int((ele>0.5)[0]))\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, classes)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "701dbb0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{12: [[0.6287420988082886,\n",
       "   0.5336463451385498,\n",
       "   0.4633152186870575,\n",
       "   0.6475076079368591],\n",
       "  array([[932, 298],\n",
       "         [395, 341]])],\n",
       " (12, 30): [0.6287420988082886,\n",
       "  0.5336463451385498,\n",
       "  0.4633152186870575,\n",
       "  0.6475076079368591],\n",
       " 24: [[0.6324173808097839,\n",
       "   0.5170998573303223,\n",
       "   0.5142857432365417,\n",
       "   0.6386768221855164],\n",
       "  array([[877, 353],\n",
       "         [357, 378]])],\n",
       " (24, 58): [0.6324173808097839,\n",
       "  0.5170998573303223,\n",
       "  0.5142857432365417,\n",
       "  0.6386768221855164],\n",
       " 48: [[0.6813942790031433,\n",
       "   0.4801097512245178,\n",
       "   0.47683924436569214,\n",
       "   0.6113092303276062],\n",
       "  array([[850, 379],\n",
       "         [384, 350]])],\n",
       " (48, 115): [0.6813942790031433,\n",
       "  0.4801097512245178,\n",
       "  0.47683924436569214,\n",
       "  0.6113092303276062],\n",
       " 72: [[0.8038536310195923,\n",
       "   0.42728298902511597,\n",
       "   0.5156462788581848,\n",
       "   0.5596330165863037],\n",
       "  array([[719, 508],\n",
       "         [356, 379]])],\n",
       " (72, 169): [0.8038536310195923,\n",
       "  0.42728298902511597,\n",
       "  0.5156462788581848,\n",
       "  0.5596330165863037]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_result # stack Conv1D above LSTM (without removing noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cd13298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{12: [[0.6843389272689819,\n",
       "   0.4783889949321747,\n",
       "   0.7767145037651062,\n",
       "   0.5706973671913147],\n",
       "  array([[405, 531],\n",
       "         [140, 487]])],\n",
       " (12, 38): [0.6843389272689819,\n",
       "  0.4783889949321747,\n",
       "  0.7767145037651062,\n",
       "  0.5706973671913147],\n",
       " 24: [[0.6756141185760498,\n",
       "   0.4753146171569824,\n",
       "   0.7695924639701843,\n",
       "   0.5767813324928284],\n",
       "  array([[448, 542],\n",
       "         [147, 491]])],\n",
       " (24, 71): [0.6756141185760498,\n",
       "  0.4753146171569824,\n",
       "  0.7695924639701843,\n",
       "  0.5767813324928284],\n",
       " 48: [[0.686356782913208,\n",
       "   0.4554730951786041,\n",
       "   0.7577160596847534,\n",
       "   0.5595026612281799],\n",
       "  array([[454, 587],\n",
       "         [157, 491]])],\n",
       " (48, 133): [0.686356782913208,\n",
       "  0.4554730951786041,\n",
       "  0.7577160596847534,\n",
       "  0.5595026612281799],\n",
       " 72: [[0.6810200810432434,\n",
       "   0.4411483108997345,\n",
       "   0.7048929929733276,\n",
       "   0.5485183000564575],\n",
       "  array([[483, 584],\n",
       "         [193, 461]])],\n",
       " (72, 193): [0.6810200810432434,\n",
       "  0.4411483108997345,\n",
       "  0.7048929929733276,\n",
       "  0.5485183000564575]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_result # downsample negative data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1b9a45c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(12, 34): [0.7047469019889832,\n",
       "  0.1626969575881958,\n",
       "  0.7081339955329895,\n",
       "  0.534690797328949],\n",
       " (24, 66): [0.7164930105209351,\n",
       "  0.15516085922718048,\n",
       "  0.7257053256034851,\n",
       "  0.517192006111145],\n",
       " (48, 126): [0.6946452856063843,\n",
       "  0.14175792038440704,\n",
       "  0.7391975522041321,\n",
       "  0.4753846228122711]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_result # monitor val recall\n",
    "# {72: [0.7307, 0.1300, 0.8012, 0.3925]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c67a3624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(24, 34): [0.5954988598823547,\n",
       "  0.1780264526605606,\n",
       "  0.5582137107849121,\n",
       "  0.6430995464324951],\n",
       " (12, 34): [0.6063371300697327,\n",
       "  0.17000912129878998,\n",
       "  0.5948963165283203,\n",
       "  0.6087858080863953],\n",
       " (24, 66): [0.6042451858520508,\n",
       "  0.1820913404226303,\n",
       "  0.47492164373397827,\n",
       "  0.6962750554084778],\n",
       " (48, 126): [0.5850675106048584,\n",
       "  0.1593644618988037,\n",
       "  0.5108024477958679,\n",
       "  0.6473504304885864],\n",
       " (72, 185): [0.5972234010696411,\n",
       "  0.1689220666885376,\n",
       "  0.5535168051719666,\n",
       "  0.6538076400756836]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_result # train on 5 machines same EQ family with shuffle and masking and empty datapoints removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8529d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_result # everything on top but trained on a bidirectional LSTM layer\n",
    "# {12: [1.4355, 0.2238, 0.2041, 0.8222]}\n",
    "# {24: [1.0140, 0.2651, 0.2962, 0.8258]}\n",
    "# {48: [0.9016, 0.2873, 0.3210, 0.8366]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c179781",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d11b162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "plot_model(model, 'alarm_seq.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201281b6",
   "metadata": {},
   "source": [
    "# 4. Walk forward dataset with no overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e2dc1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "store -r wba127_clean_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5c4b528",
   "metadata": {},
   "outputs": [],
   "source": [
    "wba127_alarm = pd.read_excel('../Data/WBA127_FullAlarm.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfdd84ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Compute major down for RAW alarm table\n",
    "def major_down(alarm_table, status_table, hour):\n",
    "    MAJOR_DOWN = []\n",
    "    for idx, row in alarm_table.iterrows():\n",
    "        start = row['DT_SET']\n",
    "        end = start + timedelta(hours=hour)\n",
    "        \n",
    "        frame = status_table[(status_table['TIMESTAMP_START']>=start) &\n",
    "                            (status_table['TIMESTAMP_START']<=end)]\n",
    "        \n",
    "        UD = frame.loc[frame['LEVEL3']=='UDT']\n",
    "        \n",
    "        if len(UD) == 0: #no record within this 6 hours:\n",
    "            MAJOR_DOWN.append(0)\n",
    "        else:\n",
    "            time_diff = (UD['TIMESTAMP_END']-UD['TIMESTAMP_START']).dt.seconds\n",
    "            if any(time_diff>=3600): #threshold = 3600s\n",
    "                MAJOR_DOWN.append(1)\n",
    "            else:\n",
    "                MAJOR_DOWN.append(0)\n",
    "                \n",
    "    return MAJOR_DOWN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac450d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "alarm_down = major_down(wba127_alarm, wba127_clean_status, 6)\n",
    "wba127_alarm['6 HOUR DOWN'] = alarm_down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0b9b64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Use time since last alarm as another possible feature\n",
    "wba127_alarm['TIME SINCE LAST ALARM'] = (wba127_alarm['DT_SET'] - wba127_alarm['DT_SET'].shift(1)).dt.total_seconds()\n",
    "wba127_alarm = wba127_alarm.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd408e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = wba127_alarm[['Alarm ID', 'TIME SINCE LAST ALARM']]\n",
    "target = wba127_alarm['6 HOUR DOWN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b9d6e5f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alarm ID</th>\n",
       "      <th>6 HOUR DOWN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46197</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46198</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46199</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46200</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46201</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46202 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Alarm ID  6 HOUR DOWN\n",
       "0            23            0\n",
       "1            23            0\n",
       "2            23            0\n",
       "3            11            0\n",
       "4            45            0\n",
       "...         ...          ...\n",
       "46197        45            1\n",
       "46198        45            1\n",
       "46199        28            1\n",
       "46200        28            1\n",
       "46201        45            1\n",
       "\n",
       "[46202 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wba127_alarm[['Alarm ID', '6 HOUR DOWN']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b80b57c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. walk forward dataset with no overlap\n",
    "# 9240 samples, timestep = 5, 10\n",
    "\n",
    "lookback_window = 10\n",
    "\n",
    "data = []\n",
    "y = []\n",
    "\n",
    "for i in range(0, len(df), 5):\n",
    "    if i>=len(df)-5:\n",
    "        break\n",
    "    seq = df.iloc[i:i+5]['Alarm ID'].values\n",
    "    data.append(seq)\n",
    "    y.append(target[i+4]) # measure major down from the last timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "840aee2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Training with Embedding\n",
    "enc_data, n_alarms, mapping_dict = label_encode(data)\n",
    "\n",
    "train_idx = int(0.7*len(enc_data))\n",
    "val_idx = int(0.8*(len(enc_data)))\n",
    "\n",
    "X_train, y_train = np.array(enc_data[:train_idx]), np.array(y[:train_idx])\n",
    "X_val, y_val = np.array(enc_data[train_idx:val_idx]), np.array(y[train_idx:val_idx])\n",
    "X_test, y_test = np.array(enc_data[val_idx:]), np.array(y[val_idx:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ffdb253b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 1,\n",
       " 2: 2,\n",
       " 3: 3,\n",
       " 4: 4,\n",
       " 5: 5,\n",
       " 6: 6,\n",
       " 8: 7,\n",
       " 9: 8,\n",
       " 11: 9,\n",
       " 12: 10,\n",
       " 13: 11,\n",
       " 14: 12,\n",
       " 18: 13,\n",
       " 20: 14,\n",
       " 23: 15,\n",
       " 24: 16,\n",
       " 25: 17,\n",
       " 26: 18,\n",
       " 27: 19,\n",
       " 28: 20,\n",
       " 31: 21,\n",
       " 33: 22,\n",
       " 34: 23,\n",
       " 35: 24,\n",
       " 44: 25,\n",
       " 45: 26,\n",
       " 47: 27,\n",
       " 49: 28,\n",
       " 50: 29,\n",
       " 51: 30,\n",
       " 61: 31,\n",
       " 65: 32,\n",
       " 73: 33,\n",
       " 80: 34,\n",
       " 100: 35,\n",
       " 245: 36}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0072921e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Define model, use the same model as above\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=n_alarms, output_dim=10, input_length=X_train.shape[1], mask_zero=True))\n",
    "model.add(Conv1D(256, kernel_size=3, strides=2, activation='relu'))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation=\"relu\"))\n",
    "model.add(Dense(1,  activation=\"sigmoid\"))  \n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3e151cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "203/203 [==============================] - 2s 3ms/step - loss: 0.6687 - precision_1: 0.2192 - recall_1: 0.5313 - accuracy: 0.6331 - val_loss: 0.6883 - val_precision_1: 0.1184 - val_recall_1: 0.7000 - val_accuracy: 0.5227\n",
      "Epoch 2/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.6468 - precision_1: 0.2297 - recall_1: 0.7005 - accuracy: 0.5884 - val_loss: 0.6757 - val_precision_1: 0.1213 - val_recall_1: 0.6750 - val_accuracy: 0.5487\n",
      "Epoch 3/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.6419 - precision_1: 0.2355 - recall_1: 0.7055 - accuracy: 0.5985 - val_loss: 0.6351 - val_precision_1: 0.1268 - val_recall_1: 0.5625 - val_accuracy: 0.6266\n",
      "Epoch 4/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.6392 - precision_1: 0.2323 - recall_1: 0.6925 - accuracy: 0.5966 - val_loss: 0.7262 - val_precision_1: 0.1143 - val_recall_1: 0.7375 - val_accuracy: 0.4827\n",
      "Epoch 5/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.6355 - precision_1: 0.2375 - recall_1: 0.7015 - accuracy: 0.6036 - val_loss: 0.7248 - val_precision_1: 0.1132 - val_recall_1: 0.7375 - val_accuracy: 0.4773\n",
      "Epoch 6/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.6345 - precision_1: 0.2371 - recall_1: 0.7114 - accuracy: 0.5996 - val_loss: 0.6923 - val_precision_1: 0.1144 - val_recall_1: 0.6750 - val_accuracy: 0.5195\n",
      "Epoch 7/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.6320 - precision_1: 0.2428 - recall_1: 0.7015 - accuracy: 0.6136 - val_loss: 0.6884 - val_precision_1: 0.1133 - val_recall_1: 0.6500 - val_accuracy: 0.5292\n",
      "Epoch 8/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.6285 - precision_1: 0.2431 - recall_1: 0.6945 - accuracy: 0.6166 - val_loss: 0.7724 - val_precision_1: 0.1107 - val_recall_1: 0.7250 - val_accuracy: 0.4719\n",
      "Epoch 9/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.6270 - precision_1: 0.2427 - recall_1: 0.7104 - accuracy: 0.6105 - val_loss: 0.6873 - val_precision_1: 0.1165 - val_recall_1: 0.6875 - val_accuracy: 0.5216\n",
      "Epoch 10/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.6241 - precision_1: 0.2439 - recall_1: 0.7095 - accuracy: 0.6132 - val_loss: 0.7025 - val_precision_1: 0.1202 - val_recall_1: 0.7000 - val_accuracy: 0.5303\n",
      "Epoch 11/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.6196 - precision_1: 0.2453 - recall_1: 0.7134 - accuracy: 0.6144 - val_loss: 0.6916 - val_precision_1: 0.1239 - val_recall_1: 0.6750 - val_accuracy: 0.5584\n",
      "Epoch 12/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.6169 - precision_1: 0.2467 - recall_1: 0.7025 - accuracy: 0.6204 - val_loss: 0.7862 - val_precision_1: 0.1157 - val_recall_1: 0.7625 - val_accuracy: 0.4751\n",
      "Epoch 13/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.6131 - precision_1: 0.2497 - recall_1: 0.7224 - accuracy: 0.6197 - val_loss: 0.8247 - val_precision_1: 0.0984 - val_recall_1: 0.7500 - val_accuracy: 0.3831\n",
      "Epoch 14/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.6112 - precision_1: 0.2501 - recall_1: 0.7174 - accuracy: 0.6218 - val_loss: 0.7198 - val_precision_1: 0.0978 - val_recall_1: 0.6625 - val_accuracy: 0.4416\n",
      "Epoch 15/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.6072 - precision_1: 0.2533 - recall_1: 0.7244 - accuracy: 0.6254 - val_loss: 0.7771 - val_precision_1: 0.0974 - val_recall_1: 0.7000 - val_accuracy: 0.4123\n",
      "Epoch 16/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.6033 - precision_1: 0.2519 - recall_1: 0.7323 - accuracy: 0.6204 - val_loss: 0.7288 - val_precision_1: 0.1222 - val_recall_1: 0.6750 - val_accuracy: 0.5519\n",
      "Epoch 17/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.5970 - precision_1: 0.2537 - recall_1: 0.7323 - accuracy: 0.6237 - val_loss: 0.7320 - val_precision_1: 0.1135 - val_recall_1: 0.6500 - val_accuracy: 0.5303\n",
      "Epoch 18/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.5947 - precision_1: 0.2594 - recall_1: 0.7532 - accuracy: 0.6276 - val_loss: 0.7245 - val_precision_1: 0.1116 - val_recall_1: 0.6125 - val_accuracy: 0.5444\n",
      "Epoch 19/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.5931 - precision_1: 0.2610 - recall_1: 0.7313 - accuracy: 0.6365 - val_loss: 0.8060 - val_precision_1: 0.0964 - val_recall_1: 0.7000 - val_accuracy: 0.4058\n",
      "Epoch 20/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.5866 - precision_1: 0.2600 - recall_1: 0.7602 - accuracy: 0.6266 - val_loss: 0.6990 - val_precision_1: 0.1168 - val_recall_1: 0.6000 - val_accuracy: 0.5725\n",
      "Epoch 21/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.5846 - precision_1: 0.2614 - recall_1: 0.7433 - accuracy: 0.6337 - val_loss: 0.7512 - val_precision_1: 0.1167 - val_recall_1: 0.6625 - val_accuracy: 0.5368\n",
      "Epoch 22/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.5795 - precision_1: 0.2602 - recall_1: 0.7522 - accuracy: 0.6291 - val_loss: 0.6459 - val_precision_1: 0.1195 - val_recall_1: 0.4750 - val_accuracy: 0.6515\n",
      "Epoch 23/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.5728 - precision_1: 0.2632 - recall_1: 0.7483 - accuracy: 0.6354 - val_loss: 0.6805 - val_precision_1: 0.1022 - val_recall_1: 0.5125 - val_accuracy: 0.5682\n",
      "Epoch 24/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.5734 - precision_1: 0.2696 - recall_1: 0.7522 - accuracy: 0.6449 - val_loss: 0.7594 - val_precision_1: 0.0958 - val_recall_1: 0.6500 - val_accuracy: 0.4383\n",
      "Epoch 25/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.5699 - precision_1: 0.2708 - recall_1: 0.7512 - accuracy: 0.6470 - val_loss: 0.8023 - val_precision_1: 0.0975 - val_recall_1: 0.6875 - val_accuracy: 0.4221\n",
      "Epoch 26/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.5630 - precision_1: 0.2658 - recall_1: 0.7751 - accuracy: 0.6323 - val_loss: 0.7970 - val_precision_1: 0.0928 - val_recall_1: 0.6250 - val_accuracy: 0.4383\n",
      "Epoch 27/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.5603 - precision_1: 0.2734 - recall_1: 0.7741 - accuracy: 0.6452 - val_loss: 0.9067 - val_precision_1: 0.0951 - val_recall_1: 0.7250 - val_accuracy: 0.3788\n",
      "Epoch 28/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.5566 - precision_1: 0.2738 - recall_1: 0.7682 - accuracy: 0.6473 - val_loss: 0.8907 - val_precision_1: 0.0943 - val_recall_1: 0.6875 - val_accuracy: 0.4015\n",
      "Epoch 29/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.5564 - precision_1: 0.2686 - recall_1: 0.7881 - accuracy: 0.6336 - val_loss: 0.6905 - val_precision_1: 0.1105 - val_recall_1: 0.5250 - val_accuracy: 0.5931\n",
      "Epoch 30/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.5509 - precision_1: 0.2748 - recall_1: 0.7741 - accuracy: 0.6475 - val_loss: 0.7242 - val_precision_1: 0.0932 - val_recall_1: 0.5625 - val_accuracy: 0.4881\n",
      "Epoch 31/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.5446 - precision_1: 0.2802 - recall_1: 0.7891 - accuracy: 0.6523 - val_loss: 0.7542 - val_precision_1: 0.0934 - val_recall_1: 0.6000 - val_accuracy: 0.4610\n",
      "Epoch 32/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.5398 - precision_1: 0.2847 - recall_1: 0.7851 - accuracy: 0.6602 - val_loss: 0.7728 - val_precision_1: 0.1111 - val_recall_1: 0.6000 - val_accuracy: 0.5498\n",
      "Epoch 33/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.5357 - precision_1: 0.2827 - recall_1: 0.8000 - accuracy: 0.6535 - val_loss: 0.6238 - val_precision_1: 0.1231 - val_recall_1: 0.4125 - val_accuracy: 0.6948\n",
      "Epoch 34/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.5341 - precision_1: 0.2875 - recall_1: 0.7861 - accuracy: 0.6640 - val_loss: 0.6729 - val_precision_1: 0.1024 - val_recall_1: 0.5250 - val_accuracy: 0.5606\n",
      "Epoch 35/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.5309 - precision_1: 0.2875 - recall_1: 0.8030 - accuracy: 0.6602 - val_loss: 0.7992 - val_precision_1: 0.1176 - val_recall_1: 0.6000 - val_accuracy: 0.5758\n",
      "Epoch 36/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203/203 [==============================] - 0s 2ms/step - loss: 0.5218 - precision_1: 0.2897 - recall_1: 0.8090 - accuracy: 0.6622 - val_loss: 0.7519 - val_precision_1: 0.0925 - val_recall_1: 0.5375 - val_accuracy: 0.5032\n",
      "Epoch 37/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.5207 - precision_1: 0.2914 - recall_1: 0.7980 - accuracy: 0.6671 - val_loss: 0.8362 - val_precision_1: 0.0884 - val_recall_1: 0.6125 - val_accuracy: 0.4199\n",
      "Epoch 38/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.5161 - precision_1: 0.2911 - recall_1: 0.8209 - accuracy: 0.6616 - val_loss: 0.7640 - val_precision_1: 0.1084 - val_recall_1: 0.5500 - val_accuracy: 0.5693\n",
      "Epoch 39/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.5114 - precision_1: 0.3064 - recall_1: 0.7891 - accuracy: 0.6897 - val_loss: 0.8913 - val_precision_1: 0.0926 - val_recall_1: 0.6250 - val_accuracy: 0.4372\n",
      "Epoch 40/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.5082 - precision_1: 0.3025 - recall_1: 0.8219 - accuracy: 0.6778 - val_loss: 0.8655 - val_precision_1: 0.0916 - val_recall_1: 0.6125 - val_accuracy: 0.4405\n",
      "Epoch 41/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.5051 - precision_1: 0.3018 - recall_1: 0.8179 - accuracy: 0.6776 - val_loss: 0.8497 - val_precision_1: 0.0942 - val_recall_1: 0.5875 - val_accuracy: 0.4751\n",
      "Epoch 42/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.4988 - precision_1: 0.3005 - recall_1: 0.8428 - accuracy: 0.6707 - val_loss: 0.7789 - val_precision_1: 0.1166 - val_recall_1: 0.5625 - val_accuracy: 0.5931\n",
      "Epoch 43/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.4951 - precision_1: 0.3078 - recall_1: 0.8159 - accuracy: 0.6863 - val_loss: 0.7604 - val_precision_1: 0.1114 - val_recall_1: 0.5250 - val_accuracy: 0.5963\n",
      "Epoch 44/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.4929 - precision_1: 0.3084 - recall_1: 0.8428 - accuracy: 0.6820 - val_loss: 0.6568 - val_precision_1: 0.1141 - val_recall_1: 0.4250 - val_accuracy: 0.6645\n",
      "Epoch 45/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.4916 - precision_1: 0.3098 - recall_1: 0.8279 - accuracy: 0.6866 - val_loss: 0.7471 - val_precision_1: 0.1173 - val_recall_1: 0.5500 - val_accuracy: 0.6028\n",
      "Epoch 46/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.4845 - precision_1: 0.3034 - recall_1: 0.8547 - accuracy: 0.6725 - val_loss: 0.6825 - val_precision_1: 0.1162 - val_recall_1: 0.4125 - val_accuracy: 0.6775\n",
      "Epoch 47/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.4806 - precision_1: 0.3112 - recall_1: 0.8428 - accuracy: 0.6857 - val_loss: 0.7465 - val_precision_1: 0.1211 - val_recall_1: 0.5375 - val_accuracy: 0.6223\n",
      "Epoch 48/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.4741 - precision_1: 0.3181 - recall_1: 0.8388 - accuracy: 0.6956 - val_loss: 0.8373 - val_precision_1: 0.0990 - val_recall_1: 0.6000 - val_accuracy: 0.4924\n",
      "Epoch 49/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.4739 - precision_1: 0.3085 - recall_1: 0.8537 - accuracy: 0.6800 - val_loss: 0.6408 - val_precision_1: 0.0996 - val_recall_1: 0.3250 - val_accuracy: 0.6872\n",
      "Epoch 50/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.4777 - precision_1: 0.3174 - recall_1: 0.8279 - accuracy: 0.6967 - val_loss: 0.8135 - val_precision_1: 0.0900 - val_recall_1: 0.5500 - val_accuracy: 0.4794\n",
      "Epoch 51/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.4654 - precision_1: 0.3197 - recall_1: 0.8368 - accuracy: 0.6979 - val_loss: 0.6274 - val_precision_1: 0.1149 - val_recall_1: 0.3375 - val_accuracy: 0.7175\n",
      "Epoch 52/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.4664 - precision_1: 0.3222 - recall_1: 0.8438 - accuracy: 0.6999 - val_loss: 0.8799 - val_precision_1: 0.1098 - val_recall_1: 0.5625 - val_accuracy: 0.5671\n",
      "Epoch 53/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.4596 - precision_1: 0.3239 - recall_1: 0.8577 - accuracy: 0.6998 - val_loss: 0.7947 - val_precision_1: 0.0855 - val_recall_1: 0.4875 - val_accuracy: 0.5043\n",
      "Epoch 54/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.4574 - precision_1: 0.3261 - recall_1: 0.8358 - accuracy: 0.7061 - val_loss: 0.8694 - val_precision_1: 0.0843 - val_recall_1: 0.5500 - val_accuracy: 0.4437\n",
      "Epoch 55/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.4580 - precision_1: 0.3201 - recall_1: 0.8876 - accuracy: 0.6895 - val_loss: 0.7586 - val_precision_1: 0.0951 - val_recall_1: 0.4875 - val_accuracy: 0.5541\n",
      "Epoch 56/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.4512 - precision_1: 0.3308 - recall_1: 0.8627 - accuracy: 0.7075 - val_loss: 0.7408 - val_precision_1: 0.0969 - val_recall_1: 0.5125 - val_accuracy: 0.5444\n",
      "Epoch 57/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.4477 - precision_1: 0.3244 - recall_1: 0.8348 - accuracy: 0.7042 - val_loss: 0.7653 - val_precision_1: 0.0920 - val_recall_1: 0.5000 - val_accuracy: 0.5292\n",
      "Epoch 58/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.4470 - precision_1: 0.3306 - recall_1: 0.8697 - accuracy: 0.7061 - val_loss: 0.8147 - val_precision_1: 0.1064 - val_recall_1: 0.5000 - val_accuracy: 0.5931\n",
      "Epoch 59/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.4416 - precision_1: 0.3342 - recall_1: 0.8488 - accuracy: 0.7138 - val_loss: 0.6761 - val_precision_1: 0.1331 - val_recall_1: 0.4125 - val_accuracy: 0.7165\n",
      "Epoch 60/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.4440 - precision_1: 0.3340 - recall_1: 0.8517 - accuracy: 0.7130 - val_loss: 0.9512 - val_precision_1: 0.0913 - val_recall_1: 0.5625 - val_accuracy: 0.4773\n",
      "Epoch 61/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.4381 - precision_1: 0.3517 - recall_1: 0.8498 - accuracy: 0.7333 - val_loss: 0.8852 - val_precision_1: 0.0813 - val_recall_1: 0.5125 - val_accuracy: 0.4567\n",
      "Epoch 62/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.4344 - precision_1: 0.3404 - recall_1: 0.8627 - accuracy: 0.7189 - val_loss: 0.9306 - val_precision_1: 0.0927 - val_recall_1: 0.5750 - val_accuracy: 0.4762\n",
      "Epoch 63/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.4370 - precision_1: 0.3428 - recall_1: 0.8517 - accuracy: 0.7233 - val_loss: 0.7498 - val_precision_1: 0.1266 - val_recall_1: 0.5000 - val_accuracy: 0.6580\n",
      "Epoch 64/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.4299 - precision_1: 0.3435 - recall_1: 0.8617 - accuracy: 0.7226 - val_loss: 1.1644 - val_precision_1: 0.0943 - val_recall_1: 0.6250 - val_accuracy: 0.4481\n",
      "Epoch 65/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.4314 - precision_1: 0.3406 - recall_1: 0.8667 - accuracy: 0.7186 - val_loss: 0.8309 - val_precision_1: 0.0915 - val_recall_1: 0.5125 - val_accuracy: 0.5173\n",
      "Epoch 66/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.4240 - precision_1: 0.3418 - recall_1: 0.8706 - accuracy: 0.7194 - val_loss: 0.7623 - val_precision_1: 0.1206 - val_recall_1: 0.4750 - val_accuracy: 0.6548\n",
      "Epoch 67/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.4236 - precision_1: 0.3418 - recall_1: 0.8856 - accuracy: 0.7172 - val_loss: 0.8822 - val_precision_1: 0.0901 - val_recall_1: 0.5375 - val_accuracy: 0.4903\n",
      "Epoch 68/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.4176 - precision_1: 0.3476 - recall_1: 0.8756 - accuracy: 0.7253 - val_loss: 0.8041 - val_precision_1: 0.1066 - val_recall_1: 0.4250 - val_accuracy: 0.6418\n",
      "Epoch 69/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.4221 - precision_1: 0.3421 - recall_1: 0.8905 - accuracy: 0.7169 - val_loss: 0.7457 - val_precision_1: 0.1188 - val_recall_1: 0.4500 - val_accuracy: 0.6634\n",
      "Epoch 70/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.4191 - precision_1: 0.3539 - recall_1: 0.8517 - accuracy: 0.7353 - val_loss: 0.8587 - val_precision_1: 0.0872 - val_recall_1: 0.4500 - val_accuracy: 0.5444\n",
      "Epoch 71/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.4202 - precision_1: 0.3459 - recall_1: 0.8657 - accuracy: 0.7248 - val_loss: 0.7259 - val_precision_1: 0.1073 - val_recall_1: 0.3875 - val_accuracy: 0.6677\n",
      "58/58 [==============================] - 0s 875us/step - loss: 0.7396 - precision_1: 0.2707 - recall_1: 0.2756 - accuracy: 0.6429\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1064,  334],\n",
       "       [ 326,  124]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#6. Compute class weight to achieve balance between two classes\n",
    "\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                             np.unique(y_train),\n",
    "                                             y_train)\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "\n",
    "\n",
    "callbacks = [ReduceLROnPlateau(monitor='val_accuracy', factor=0.2, patience=5, min_lr=0.001), \\\n",
    "            EarlyStopping(monitor='val_accuracy', patience=20, mode='max', restore_best_weights=True)]\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                batch_size=BATCH_SIZE, epochs=EPOCHS, \n",
    "                validation_data=(X_val, y_val),\n",
    "                class_weight=class_weights_dict,\n",
    "                callbacks=callbacks)\n",
    "\n",
    "evaluate = model.evaluate(X_test, y_test) #loss, mse\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "classes = []\n",
    "for ele in pred:\n",
    "    classes.append(int((ele>0.5)[0]))\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, classes)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1754b093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seems like accuracy not improving, check data\n",
    "pos_idx = np.where([i==1 for i in y_train])[0]\n",
    "check_df = X_train[pos_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33224a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = pd.DataFrame(columns=['Seq', 'Target'])\n",
    "for idx, ele in enumerate(check_df):\n",
    "    c = c.append({'Seq':ele, 'Target':y[idx]}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18c76ee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Seq</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[19, 25, 25, 16, 26]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[9, 25, 26, 30, 10]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[9, 33, 9, 9, 9]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[20, 20, 9, 9, 25]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[25, 25, 25, 9, 33]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>[20, 20, 15, 15, 15]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>[20, 20, 25, 20, 20]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>[20, 20, 20, 20, 16]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>[16, 26, 20, 16, 26]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>[26, 30, 20, 20, 30]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1005 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Seq Target\n",
       "0     [19, 25, 25, 16, 26]      0\n",
       "1      [9, 25, 26, 30, 10]      0\n",
       "2         [9, 33, 9, 9, 9]      0\n",
       "3       [20, 20, 9, 9, 25]      0\n",
       "4      [25, 25, 25, 9, 33]      0\n",
       "...                    ...    ...\n",
       "1000  [20, 20, 15, 15, 15]      0\n",
       "1001  [20, 20, 25, 20, 20]      0\n",
       "1002  [20, 20, 20, 20, 16]      0\n",
       "1003  [16, 26, 20, 16, 26]      0\n",
       "1004  [26, 30, 20, 20, 30]      0\n",
       "\n",
       "[1005 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2330f872",
   "metadata": {},
   "source": [
    "# 5. Remove alarm id from the front during padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb7b45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_wba124_X_seq, n_alarm_wba124, mapping_dict_wba124 = label_encode(wba124.X_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ae65a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "feature = pad_sequences(enc_wba124_X_seq, maxlen=n_alarm_wba124, value=0, \n",
    "                         truncating='pre', padding='pre') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65aac4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(feature, wba124.major_down_arr, test_size=0.4)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.4)\n",
    "\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(y_train),\n",
    "                                                 y_train)\n",
    "weights ={}\n",
    "for idx, val in enumerate(class_weights):\n",
    "    weights[idx] = val\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb61b154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and predict\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(n_alarm_wba124, 128, input_length=feature.shape[1], mask_zero=True))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_accuracy', mode='max', patience=5)]\n",
    "\n",
    "model.fit(np.array(X_train), np.array(y_train), \n",
    "          epochs=10, \n",
    "          batch_size=BATCH_SIZE,\n",
    "          verbose = 1,\n",
    "          class_weight=weights,\n",
    "          callbacks=callbacks,\n",
    "          validation_data=(X_val, np.array(y_val)))\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "classes = []\n",
    "for ele in pred:\n",
    "    classes.append(int((ele>0.5)[0]))\n",
    "\n",
    "print(confusion_matrix(np.array(y_test), classes)), accuracy_score(np.array(y_test), classes)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "def to_labels(y_scores, threshold):\n",
    "    return (y_scores >= threshold).astype('int')\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(np.array(y_test), classes)\n",
    "J = tpr - fpr\n",
    "ix = np.argmax(J)\n",
    "best_thresh = thresholds[ix]\n",
    "print('Best Threshold=%f' % (best_thresh))\n",
    "\n",
    "testest = to_labels(classes, best_thresh) # best thresh optimizes recall\n",
    "confusion_matrix(np.array(y_test), testest), accuracy_score(np.array(y_test), testest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5ee5b8",
   "metadata": {},
   "source": [
    "# 6. Sample Weighing Alarm ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "538fc0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in data\n",
    "\n",
    "wba123_fullalarm = pd.read_excel(\"../Data/WBA123_FullAlarm.xlsx\", usecols = \"B,C,D,F,M\")\n",
    "wba123 = seven_days_LSTM(\"WBA123\", wba123_fullalarm, 24, 3)\n",
    "\n",
    "wba124_fullalarm = pd.read_excel(\"../Data/WBA124_FullAlarm.xlsx\", usecols = \"B,C,D,F,M\")\n",
    "wba124 = seven_days_LSTM(\"WBA124\", wba124_fullalarm, 24, 3)\n",
    "\n",
    "wba126_fullalarm = pd.read_excel(\"../Data/WBA126_FullAlarm.xlsx\", usecols = \"B,C,D,F,M\")\n",
    "wba126 = seven_days_LSTM(\"WBA126\", wba126_fullalarm, 24, 3)\n",
    "\n",
    "wba127_fullalarm = pd.read_excel(\"../Data/WBA127_FullAlarm.xlsx\", usecols = \"B,C,D,F,M\")\n",
    "wba127 = seven_days_LSTM(\"WBA127\", wba127_fullalarm, 24, 3)\n",
    "\n",
    "wba128_fullalarm = pd.read_excel(\"../Data/WBA128_FullAlarm.xlsx\", usecols = \"B,C,D,F,M\")\n",
    "wba128 = seven_days_LSTM(\"WBA128\", wba128_fullalarm, 24, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e2ec3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp1 = np.concatenate((wba123.X_seq, wba124.X_seq, wba126.X_seq, wba127.X_seq, wba128.X_seq))\n",
    "encoded_X_seq, n_alarms, mapping_dict = label_encode(tmp1)\n",
    "target = np.concatenate((wba123.major_down_arr, wba124.major_down_arr, wba126.major_down_arr, wba127.major_down_arr, wba128.major_down_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c535a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34894"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty_alarms_index = []\n",
    "for i in range(encoded_X_seq.shape[0]):\n",
    "    if encoded_X_seq[i].shape[0]==0:\n",
    "        empty_alarms_index.append(i)\n",
    "        \n",
    "y_values_for_empty_alarms = [target[i] for i in empty_alarms_index]\n",
    "from collections import Counter\n",
    "Counter(y_values_for_empty_alarms)\n",
    "#There are only 604 records of EMPTY alarms which cause breakdown (target = 1) out of 43000 -> very little, only 1%. \n",
    "#So these empty alarms records will be removed. \n",
    "\n",
    "# Remove empty alarms\n",
    "encoded_X_seq_no_empty = np.delete(encoded_X_seq,empty_alarms_index)\n",
    "encoded_X_seq_no_empty.shape[0]\n",
    "target_no_empty_alarms = np.delete(target,empty_alarms_index)\n",
    "target_no_empty_alarms.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23419c2f",
   "metadata": {},
   "source": [
    "#### Sample weighting - generate weight for each alarm ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37b4ba89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{25: 5.266695454545454,\n",
       " 11: 5.517490476190476,\n",
       " 34: 46.346920000000004,\n",
       " 4: 21.066781818181816,\n",
       " 42: 9.269384,\n",
       " 46: 5.517490476190476,\n",
       " 44: 5.517490476190476,\n",
       " 33: 46.346920000000004,\n",
       " 17: 5.517490476190476,\n",
       " 5: 57.93365,\n",
       " 29: 6.815723529411765,\n",
       " 24: 5.266695454545454,\n",
       " 19: 5.517490476190476,\n",
       " 32: 46.346920000000004,\n",
       " 21: 5.517490476190476,\n",
       " 20: 5.517490476190476,\n",
       " 12: 6.815723529411765,\n",
       " 38: 57.93365,\n",
       " 10: 6.815723529411765,\n",
       " 6: 9.269384,\n",
       " 35: 9.269384,\n",
       " 2: 6.815723529411765,\n",
       " 31: 5.517490476190476,\n",
       " 13: 5.517490476190476,\n",
       " 3: 6.815723529411765,\n",
       " 14: 5.517490476190476,\n",
       " 47: 5.517490476190476,\n",
       " 41: 9.269384,\n",
       " 22: 5.0377086956521735,\n",
       " 16: 6.815723529411765,\n",
       " 18: 6.815723529411765,\n",
       " 15: 6.815723529411765,\n",
       " 23: 5.517490476190476,\n",
       " 8: 9.269384,\n",
       " 48: 6.815723529411765,\n",
       " 37: 21.066781818181816,\n",
       " 36: 5.517490476190476,\n",
       " 43: 6.815723529411765,\n",
       " 52: 5.517490476190476,\n",
       " 49: 6.815723529411765,\n",
       " 9: 9.269384,\n",
       " 39: 9.269384,\n",
       " 28: 5.517490476190476,\n",
       " 26: 7.022260606060606,\n",
       " 53: 5.517490476190476,\n",
       " 40: 9.269384,\n",
       " 50: 5.517490476190476,\n",
       " 7: 9.269384,\n",
       " 27: 13.63144705882353,\n",
       " 30: 21.066781818181816,\n",
       " 1: 21.066781818181816,\n",
       " 51: 6.815723529411765,\n",
       " 45: 6.815723529411765,\n",
       " 0: 0}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Determining Sampling weights\n",
    "all_alarms = np.concatenate(encoded_X_seq_no_empty,axis = 0) #combining all ALARMS appear in X INTO 1 LIST\n",
    "#Counter(all_alarms).keys()\n",
    "\n",
    "alarm_weight = dict()\n",
    "for key in Counter(all_alarms).keys():\n",
    "    alarm_weight[key] = (all_alarms.shape[0]/all_alarms[key])/10000\n",
    "\n",
    "#100 alarms, alarm ID 44 appear 3 times. the 100/3 = 33\n",
    "\n",
    "alarm_weight[0] = 0 #For zeros value in X (to ignore the padding)\n",
    "alarm_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d310fb9",
   "metadata": {},
   "source": [
    "#### Last n alarms data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ff90273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# last_5['length==5'] = [len(last_5['last_5_alarms'][i])==5 for i in range(last_5.shape[0])]\n",
    "# last_5.loc[(last_5['length==5'] == False)] #There are 703 rows where the number of alarms in that timeframe <5. \n",
    "# #Out of these 703 records, only 49 are major down. So we will remove these records. \n",
    "# #last_5.loc[(last_5['length==5'] == False) & (last_5['target'] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9f60563",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'last_5_clean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-b4d3cf1758c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Drop duplicates (duplication = no alarms happen in the 3 hours period between rows)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlast_5_clean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlast_5_clean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'last_5_alarms'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlast_5_clean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'str_version'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlast_5_clean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'last_5_alarms'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mduplicate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlast_5_clean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mduplicated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'str_version'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'last_5_clean' is not defined"
     ]
    }
   ],
   "source": [
    "#Drop duplicates (duplication = no alarms happen in the 3 hours period between rows)\n",
    "last_5_clean = last_5_clean[['last_5_alarms','target']]\n",
    "last_5_clean['str_version'] = last_5_clean['last_5_alarms'].astype(str)\n",
    "duplicate = last_5_clean.duplicated(subset=['str_version'])\n",
    "\n",
    "index_duplicate = [i for i,x in enumerate(duplicate) if x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d193daba",
   "metadata": {},
   "outputs": [],
   "source": [
    "l5nd = last_5_clean.drop_duplicates(subset=['str_version']) #l5nd = last 5 clean no duplicates \n",
    "pd.set_option(\"display.max_rows\",100)\n",
    "l5nd['target'].value_counts()\n",
    "l5nd_sf = l5nd.sample(frac=1,random_state = 3)\n",
    "l5nd_sf = l5nd_sf.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41181949",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Padding data with alarm sequence length <5 \n",
    "pad_last_alarms = pad_sequences(\n",
    "    l5nd_sf['last_5_alarms'], maxlen=5, dtype='int32', padding='pre',\n",
    "    truncating='pre', value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3360b9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_tr_last,X_ts_last,y_tr_last,y_ts_last = train_test_split(pad_last_alarms,l5nd_sf['target'],stratify = l5nd_sf['target'], test_size = 0.2, random_state = 43)\n",
    "\n",
    "from collections import Counter \n",
    "Counter(y_ts_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed830e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_weight: to be fit inside model.fit Keras API\n",
    "modelwtr_last = np.zeros((X_tr_last.shape[0],5))\n",
    "for i in range(modelwtr_last.shape[0]):\n",
    "    for j in range(5):\n",
    "        modelwtr_last[i,j] = alarm_weight[(X_tr_last[i][j])]\n",
    "        \n",
    "#FOR TEST \n",
    "modelwts_last = np.zeros((X_ts_last.shape[0],5)) #initialize model_weight\n",
    "#model_weight: to be fit inside model.fit Keras API\n",
    "for i in range(modelwts_last.shape[0]):\n",
    "    for j in range(5):\n",
    "        modelwts_last[i,j] = alarm_weight[(X_ts_last[i][j])]\n",
    "        \n",
    "#Changing to 1D\n",
    "mw1dtr_last = np.array([modelwtr_last[i].sum()/(modelwtr_last.shape[1]*30) for i in range(modelwtr_last.shape[0])])\n",
    "mw1dts_last = np.array([modelwts_last[i].sum()/(modelwts_last.shape[1]*30) for i in range(modelwts_last.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc37147",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SMOTE\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "oversample = BorderlineSMOTE()\n",
    "X_tr_last_sm, y_tr_last_sm = oversample.fit_resample(X_tr_last,y_tr_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35a1db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model weight for SMOTE dataset\n",
    "#model_weight: to be fit inside model.fit Keras API\n",
    "modelwtr_last_sm = np.zeros((X_tr_last_sm.shape[0],5))\n",
    "\n",
    "for i in range(modelwtr_last_sm.shape[0]):\n",
    "    for j in range(5):\n",
    "        modelwtr_last_sm[i,j] = alarm_weight[(X_tr_last_sm[i][j])]\n",
    "        \n",
    "#Changing to 1D\n",
    "mw1dtr_last_sm = np.array([modelwtr_last_sm[i].sum()/(modelwtr_last_sm.shape[1]*30) for i in range(modelwtr_last_sm.shape[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4c656b",
   "metadata": {},
   "source": [
    "#### Generate Sample weight for both training & test set (for model.fit & model.evaluate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1596ace4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one sample weight for training and another for test\n",
    "\n",
    "#FOR TRAINING\n",
    "model_weight_tr = np.zeros((pad_X_tr_smote.shape[0],pad_X_tr_smote.shape[1])) #initialize model_weight\n",
    "#model_weight: to be fit inside model.fit Keras API\n",
    "for i in range(model_weight_tr.shape[0]):\n",
    "    for j in range(model_weight_tr.shape[1]):\n",
    "        model_weight_tr[i,j] = alarm_weight[(pad_X_tr_smote[i][j])]\n",
    "\n",
    "#FOR TEST\n",
    "model_weight_ts = np.zeros((pad_X_ts.shape[0],pad_X_ts.shape[1])) #initialize model_weight\n",
    "#model_weight: to be fit inside model.fit Keras API\n",
    "for i in range(model_weight_ts.shape[0]):\n",
    "    for j in range(model_weight_ts.shape[1]):\n",
    "        model_weight_ts[i,j] = alarm_weight[(pad_X_ts[i][j])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa18834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take mean sample of the sample weight as the sample weight for the general sentence\n",
    "\n",
    "model_weight_1D_tr = np.array([model_weight_tr[i].sum()/(model_weight_tr.shape[1]*30) for i in range(model_weight_tr.shape[0])])\n",
    "model_weight_1D_ts = np.array([model_weight_ts[i].sum()/(model_weight_ts.shape[1]*30) for i in range(model_weight_ts.shape[0])])\n",
    "                                                                                            \n",
    "#model_weight[i].sum()/model_weight.shape[1] = taking the average of ALL the weights in the i-th row of model_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511fdbca",
   "metadata": {},
   "source": [
    "#### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4d0744",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_length = pad_X_tr_smote.shape[1]\n",
    "input_length = 5 #for last_5 alarms data\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "class_weight = class_weight.compute_class_weight('balanced'\n",
    "                                               ,np.unique(y_tr_last)\n",
    "                                               ,y_tr_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3107fa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(100, 200, input_length = input_length, mask_zero=True))\n",
    "model.add(LSTM(32,return_sequences=True,dropout=0.1))\n",
    "model.add(LSTM(32,return_sequences=True,dropout=0.1))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dense(64,activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              metrics=[tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), 'accuracy'])\n",
    "\n",
    "model.summary()\n",
    "history = model.fit(X_tr_last_sm, y_tr_last_sm, epochs=1, \n",
    "                    sample_weight = mw1dtr_last_sm)\n",
    "\n",
    "evaluate = model.evaluate(X_ts_last, y_ts_last, sample_weight = mw1dts_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7dd1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction for last alarms \n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "y_pred_last = model.predict(X_ts_last)\n",
    "\n",
    "#Finding the correct threshold for the prediction probability \n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_ts_last, y_pred_last)\n",
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "print(\"Threshold value is:\", optimal_threshold)\n",
    "\n",
    "y_pred_classes = [1 if i>=0.19547457 else 0 for i in y_pred_last]\n",
    "\n",
    "print(confusion_matrix(y_ts_last,y_pred_classes))\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "print('Precision: ', precision_score(y_ts_last, y_pred_classes))\n",
    "print('Recall: ',recall_score(y_ts_last,y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48e6eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "y_pred = model.predict(pad_X_ts)\n",
    "\n",
    "#Finding the correct threshold for the prediction probability \n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_ts, y_pred)\n",
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "print(\"Threshold value is:\", optimal_threshold)\n",
    "\n",
    "y_pred_classes = [1 if i>=0.19547457 else 0 for i in y_pred]\n",
    "\n",
    "print(confusion_matrix(y_ts,y_pred_classes))\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "print('Precision: ', precision_score(y_ts, y_pred_classes))\n",
    "print('Recall: ',recall_score(y_ts,y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f689ba2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENV-MAL-VE",
   "language": "python",
   "name": "env-mal-ve_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
