{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e516e46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization, \\\n",
    "                                    Input, Embedding, Masking, Bidirectional, Conv1D, Flatten, \\\n",
    "                                    MaxPooling1D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "from sklearn.utils import class_weight, shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 300\n",
    "\n",
    "from datetime import datetime, timedelta, date\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cx_Oracle\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "class seven_days_LSTM:\n",
    "    def __init__(self, eq_id, alarm_table, hour_horizontal, hour_vertical):\n",
    "        self.eq_id = eq_id\n",
    "        self.alarm_table = alarm_table\n",
    "        self.status_table = self.query_status()\n",
    "        self.hour_horizontal = hour_horizontal\n",
    "        self.hour_vertical = hour_vertical\n",
    "        \n",
    "        status_start = self.status_table.iloc[0][\"TIMESTAMP_START\"].date() + timedelta(days=1)\n",
    "        status_end = self.status_table.iloc[len(self.status_table)-1][\"TIMESTAMP_START\"].date()\n",
    "        alarm_start = self.alarm_table.iloc[0][\"DT_SET\"].date() + timedelta(days=1) # add one day to make it start from 00:00:00\n",
    "        alarm_end = self.alarm_table.iloc[len(self.alarm_table)-1][\"DT_SET\"].date()\n",
    "        self.start_date = max(status_start, alarm_start)\n",
    "        self.end_date = min(status_end, alarm_end)\n",
    "        \n",
    "        self.timeframe_table = self.generate_time(self.start_date.strftime(\"%d/%m/%Y\"), self.end_date.strftime(\"%d/%m/%Y\"), \\\n",
    "                                                  self.hour_horizontal, self.hour_vertical)\n",
    "        \n",
    "        self.major_down_arr = self.major_down(self.timeframe_table, self.status_table, 6, 3600)\n",
    "\n",
    "        self.X_seq = self.alarm_breakdown_pattern(self.timeframe_table, self.alarm_table, self.status_table, self.hour_horizontal)\n",
    "        \n",
    "    def generate_time(self, start_date:str, end_date:str, hours_row:int, hour:int):\n",
    "        start = datetime.strptime(start_date, '%d/%m/%Y')\n",
    "        end = datetime.strptime(end_date, '%d/%m/%Y')\n",
    "\n",
    "        dates = []\n",
    "        while start+timedelta(hours=hours_row)<=end:\n",
    "            row = [start, start+timedelta(hours=hours_row)]\n",
    "            dates.append(row)\n",
    "            start += timedelta(hours=hour)\n",
    "\n",
    "        return pd.DataFrame(dates, columns=['TIMESTAMP_START', 'TIMESTAMP_END'])\n",
    "\n",
    "    \n",
    "    def alarm_breakdown_pattern(self, datetime_table, alarm_table, status_table, hour):\n",
    "        ORIG_ALARMS = []\n",
    "        \n",
    "        #validate alarm table date\n",
    "        if alarm_table.iloc[0]['DT_SET'] < status_table.iloc[0]['TIMESTAMP_START'] or \\\n",
    "            alarm_table.iloc[len(alarm_table)-1]['DT_SET'] > status_table.iloc[len(status_table)-1]['TIMESTAMP_START']:\n",
    "            raise ValueError(\"Alarm table date must be within the range of status table date\")\n",
    "\n",
    "        for idx, row in datetime_table.iterrows():\n",
    "            start = row['TIMESTAMP_START']\n",
    "            end = row['TIMESTAMP_END']\n",
    "\n",
    "            table = alarm_table[(alarm_table['DT_SET']>=start) & (alarm_table['DT_SET']<=end)]\n",
    "            new_table = table[[\"Alarm ID\"]]\n",
    "            \n",
    "            tmp2 = []\n",
    "            for n in new_table.values: # this part is needed to achieve the data structure in X_seq, else it would fail\n",
    "                tmp2.append(n[0])\n",
    "            ORIG_ALARMS.append(tmp2)\n",
    "\n",
    "        return np.array(ORIG_ALARMS)\n",
    "    \n",
    "    def query_status(self):\n",
    "        try:\n",
    "            oracle_string = \"oracle+cx_oracle://{username}:{password}@{hostname}:{port}/{database}\"\n",
    "            engine = create_engine(\n",
    "                oracle_string.format(\n",
    "                    username = 'TFM4CEBERUS',\n",
    "                    password = 'TFM4CEBERUS',\n",
    "                    hostname = 'ome-db.bth.infineon.com',\n",
    "                    port = '1538',\n",
    "                    database = 'ome'\n",
    "                    )\n",
    "                )\n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "\n",
    "        query = f\"\"\"select EQ_ID, TIMESTAMP_START, TIMESTAMP_END, DURATION, LEVEL3_NAME, LEVEL3 \n",
    "                from (SELECT\n",
    "                  eq.eq_id, eq.name, eq.eq_type_ident\n",
    "                , data.timestamp_start,data.timestamp_end\n",
    "                , ROUND((data.timestamp_end - data.timestamp_start)*24*60*60,0) AS Duration\n",
    "                , data.tr25_3_status,data.tr25_4_status,data.tr25_5_status,data.eq_status\n",
    "                , level5s.state_name\n",
    "                , level5.state_name Level5_Name, level5.state_sign Level5\n",
    "                , level4.state_name Level4_Name, level4.state_sign Level4\n",
    "                , level3.state_name Level3_Name, level3.state_sign Level3\n",
    "                ,mh.device\n",
    "                ,mh.package,\n",
    "                mh.lotid as lot,\n",
    "                mh.product,\n",
    "                mh.operation\n",
    "\n",
    "                FROM OMEDATA.EQUIPMENT_STATE_HISTORY data\n",
    "                , OMEADMIN.EQUIPMENT_INSTANCES eq\n",
    "                , V_EQ_STATES level5s\n",
    "                , OMEADMIN.DEF_STANDARD_STATEMODEL level5\n",
    "                , OMEADMIN.DEF_STANDARD_STATEMODEL level4\n",
    "                , OMEADMIN.DEF_STANDARD_STATEMODEL level3\n",
    "                , OMEDATA.METAKEY_HISTORY mh\n",
    "\n",
    "                WHERE data.eq_ident  = eq.eq_ident\n",
    "                AND  data.eq_status = level5s.state_ident(+)\n",
    "                AND level5.state_ident = data.tr25_5_status\n",
    "                AND level4.state_ident = data.tr25_4_status\n",
    "                AND level3.state_ident = data.tr25_3_status\n",
    "                AND  data.metakey_ident =mh.ident(+)\n",
    "                and data.timestamp_start > sysdate - 1500)\n",
    "                where eq_id = '{self.eq_id}'\n",
    "                ORDER BY TIMESTAMP_START\"\"\"\n",
    "\n",
    "        status = pd.read_sql(query, engine)\n",
    "        status.columns = map(lambda x: str(x).upper(), status.columns) \n",
    "\n",
    "        return status\n",
    "\n",
    "    def major_down(self, input_table, status_table, hour, threshold):\n",
    "        hour = pd.Timedelta(hours=hour)\n",
    "        major_down = []\n",
    "        \n",
    "        # timeframe table must be a subset of the status table to correctly determine major down\n",
    "        if status_table.iloc[0][\"TIMESTAMP_START\"] > input_table.iloc[0][\"TIMESTAMP_START\"]:\n",
    "            raise Exception(\"Timeframe table must be a subset of the status table\")\n",
    "        if status_table.iloc[len(status_table)-1][\"TIMESTAMP_START\"] <= input_table.iloc[len(input_table)-1][\"TIMESTAMP_START\"]:\n",
    "            raise Exception(\"Timeframe table must be a subset of the status table\")   \n",
    "            \n",
    "        for idx, row in input_table.iterrows():\n",
    "            start = row['TIMESTAMP_END']\n",
    "            end = start+hour\n",
    "            frame = status_table[(status_table['TIMESTAMP_START']>start) & (status_table['TIMESTAMP_START']<end)]\n",
    "            UD = frame.loc[frame['LEVEL3']=='UDT']\n",
    "\n",
    "            if len(UD) == 0: #no record within this 6 hours:\n",
    "                major_down.append(0)\n",
    "            else:\n",
    "                time_diff = (UD['TIMESTAMP_END']-UD['TIMESTAMP_START']).dt.seconds\n",
    "                if any(time_diff>threshold):\n",
    "                    major_down.append(1)\n",
    "                else:\n",
    "                    major_down.append(0)\n",
    "        return major_down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baa2d728",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_full_alarm(eq_id, apc_alarm_table_path):\n",
    "    \n",
    "    alarm_apc = pd.read_excel(apc_alarm_table_path, engine=\"openpyxl\", usecols = \"B,C,D,F\")\n",
    "    start_date = sorted(alarm_apc[\"DT_SET\"].dt.date)[0]\n",
    "    start_date_STR = start_date.strftime(\"%d/%m/%Y\")\n",
    "    alarm_apc_new = alarm_apc.rename(columns={\"Equipment\": \"EQ_ID\", \"Alarm ID\": \"ALARM_ID\", \"DT_SET\": \"TIMESTAMP_START\", \"DT_CLEAR\":\"TIMESTAMP_END\"})\n",
    "    \n",
    "    try:\n",
    "        oracle_string = \"oracle+cx_oracle://{username}:{password}@{hostname}:{port}/{database}\"\n",
    "        engine = create_engine(\n",
    "            oracle_string.format(\n",
    "                username = 'TFM4CEBERUS',\n",
    "                password = 'TFM4CEBERUS',\n",
    "                hostname = 'ome-db.bth.infineon.com',\n",
    "                port = '1538',\n",
    "                database = 'ome'\n",
    "            )\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "\n",
    "    query = f\"\"\"SELECT * FROM (select ei.eq_id, ea.alarm_id, ac.name as alarm_class, ah.timestamp_start,ah.timestamp_end\n",
    "                from OMEADMIN.equipment_instances ei\n",
    "                join OMEADMIN.equipment_alarms ea on (ei.eq_type_ident(+) = ea.eq_type_ident)\n",
    "                join OMEDATA.ALARM_HISTORY ah on (ea.alarm_id = ah.alarm_id and ah.eq_ident = ei.eq_ident)\n",
    "                join OMEDATA.METAKEY_HISTORY mh on (ah.metakey_ident = mh.ident)\n",
    "                join OMEADMIN.EQUIPMENT_ALARM_CLASSES ac on (ac.IDENT = ea.ALARM_CLASS_IDENT and ac.eq_type_ident = ea.eq_type_ident)\n",
    "                where ah.timestamp_start > sysdate - 365\n",
    "                and ah.timestamp_start < sysdate -1)\n",
    "                WHERE EQ_ID = '{eq_id}'\n",
    "                ORDER BY TIMESTAMP_START\n",
    "                \"\"\"\n",
    "\n",
    "    alarm = pd.read_sql(query, engine)\n",
    "    alarm.columns = map(lambda x: str(x).upper(), alarm.columns)\n",
    "    \n",
    "    #map the alarm class\n",
    "    all_alarm_id = alarm[\"ALARM_ID\"].unique().tolist()\n",
    "    all_alarm_dict = dict.fromkeys(all_alarm_id, None)\n",
    "    \n",
    "    for key in all_alarm_dict.keys():\n",
    "        alarm_class = alarm[alarm.ALARM_ID ==key].iloc[0][\"ALARM_CLASS\"]\n",
    "        all_alarm_dict[key] = alarm_class\n",
    "    \n",
    "    alarm_apc_new[\"ALARM_CLASS\"] = alarm_apc_new[\"ALARM_ID\"].map(all_alarm_dict)\n",
    "    alarm_apc_new[\"ALARM_CLASS\"] = alarm_apc_new[\"ALARM_CLASS\"].fillna(value=\"Important Alarms\") #those alarms cannot be found in TFM must be the important alarms\n",
    "    \n",
    "    filtered_alarm = alarm.loc[alarm[\"TIMESTAMP_START\"].dt.date < start_date] # in case TFM have more data than APC, for earlier data, take from TFM\n",
    "    return pd.concat([filtered_alarm, alarm_apc_new], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7329595b",
   "metadata": {},
   "source": [
    "# Padding the alarm sequence to max length to help achieve consistent input length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d0c4a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wba124_fullalarm = find_full_alarm(\"WBA124\", \"Data/WBA124_FullAlarm.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7be09286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training by looking back 12 hours of alarm data\n",
      "Epoch 1/150\n",
      "189/189 [==============================] - 96s 490ms/step - loss: 0.6948 - accuracy: 0.5970 - val_loss: 0.6766 - val_accuracy: 0.8396\n",
      "Epoch 2/150\n",
      "189/189 [==============================] - 92s 487ms/step - loss: 0.6943 - accuracy: 0.5607 - val_loss: 0.7032 - val_accuracy: 0.1604\n",
      "Epoch 3/150\n",
      "189/189 [==============================] - 91s 483ms/step - loss: 0.6951 - accuracy: 0.6291 - val_loss: 0.6885 - val_accuracy: 0.8396\n",
      "Epoch 4/150\n",
      "189/189 [==============================] - 91s 482ms/step - loss: 0.6944 - accuracy: 0.5687 - val_loss: 0.7131 - val_accuracy: 0.1604\n",
      "Epoch 5/150\n",
      "189/189 [==============================] - 91s 482ms/step - loss: 0.6936 - accuracy: 0.3570 - val_loss: 0.6986 - val_accuracy: 0.1604\n",
      "Epoch 6/150\n",
      "189/189 [==============================] - 91s 483ms/step - loss: 0.6941 - accuracy: 0.2842 - val_loss: 0.6927 - val_accuracy: 0.8396\n",
      "Epoch 7/150\n",
      "189/189 [==============================] - 91s 481ms/step - loss: 0.6931 - accuracy: 0.4571 - val_loss: 0.6966 - val_accuracy: 0.1604\n",
      "Epoch 8/150\n",
      "189/189 [==============================] - 91s 482ms/step - loss: 0.6931 - accuracy: 0.2829 - val_loss: 0.6941 - val_accuracy: 0.1604\n",
      "Epoch 9/150\n",
      "189/189 [==============================] - 91s 483ms/step - loss: 0.6931 - accuracy: 0.2304 - val_loss: 0.6932 - val_accuracy: 0.1604\n",
      "Epoch 10/150\n",
      "189/189 [==============================] - 91s 480ms/step - loss: 0.6930 - accuracy: 0.7405 - val_loss: 0.6917 - val_accuracy: 0.8396\n",
      "Epoch 11/150\n",
      "189/189 [==============================] - 91s 480ms/step - loss: 0.6931 - accuracy: 0.7194 - val_loss: 0.6949 - val_accuracy: 0.1604\n",
      "Epoch 12/150\n",
      "189/189 [==============================] - 91s 484ms/step - loss: 0.6930 - accuracy: 0.2590 - val_loss: 0.6847 - val_accuracy: 0.8396\n",
      "Epoch 13/150\n",
      "189/189 [==============================] - 91s 481ms/step - loss: 0.6933 - accuracy: 0.7432 - val_loss: 0.6940 - val_accuracy: 0.1604\n",
      "Epoch 14/150\n",
      "189/189 [==============================] - 91s 481ms/step - loss: 0.6933 - accuracy: 0.2464 - val_loss: 0.6852 - val_accuracy: 0.8396\n",
      "Epoch 15/150\n",
      "189/189 [==============================] - 91s 483ms/step - loss: 0.6945 - accuracy: 0.4197 - val_loss: 0.6936 - val_accuracy: 0.1604\n",
      "Epoch 16/150\n",
      "189/189 [==============================] - 92s 487ms/step - loss: 0.6931 - accuracy: 0.3020 - val_loss: 0.6976 - val_accuracy: 0.1604\n",
      "Epoch 17/150\n",
      "189/189 [==============================] - 91s 484ms/step - loss: 0.6933 - accuracy: 0.4893 - val_loss: 0.6910 - val_accuracy: 0.8396\n",
      "Epoch 18/150\n",
      "189/189 [==============================] - 91s 483ms/step - loss: 0.6939 - accuracy: 0.5954 - val_loss: 0.7039 - val_accuracy: 0.1604\n",
      "Epoch 19/150\n",
      "189/189 [==============================] - 91s 483ms/step - loss: 0.6933 - accuracy: 0.2120 - val_loss: 0.6038 - val_accuracy: 0.8396\n",
      "Epoch 20/150\n",
      "189/189 [==============================] - 91s 483ms/step - loss: 0.6972 - accuracy: 0.5257 - val_loss: 0.6965 - val_accuracy: 0.1604\n",
      "Epoch 21/150\n",
      "189/189 [==============================] - 91s 483ms/step - loss: 0.6934 - accuracy: 0.6394 - val_loss: 0.6867 - val_accuracy: 0.8396\n",
      "Epoch 22/150\n",
      "189/189 [==============================] - 91s 484ms/step - loss: 0.6933 - accuracy: 0.7689 - val_loss: 0.6873 - val_accuracy: 0.8396\n",
      "Epoch 23/150\n",
      "189/189 [==============================] - 91s 482ms/step - loss: 0.6932 - accuracy: 0.3487 - val_loss: 0.6927 - val_accuracy: 0.8396\n",
      "Epoch 24/150\n",
      "189/189 [==============================] - 91s 482ms/step - loss: 0.6930 - accuracy: 0.5102 - val_loss: 0.6915 - val_accuracy: 0.8396\n",
      "Epoch 25/150\n",
      "189/189 [==============================] - 91s 482ms/step - loss: 0.6931 - accuracy: 0.2241 - val_loss: 0.6911 - val_accuracy: 0.8396\n",
      "Epoch 26/150\n",
      "189/189 [==============================] - 91s 483ms/step - loss: 0.6930 - accuracy: 0.8604 - val_loss: 0.6928 - val_accuracy: 0.8396\n",
      "Epoch 27/150\n",
      "189/189 [==============================] - 91s 484ms/step - loss: 0.6931 - accuracy: 0.3952 - val_loss: 0.6956 - val_accuracy: 0.1604\n",
      "Epoch 28/150\n",
      "189/189 [==============================] - 91s 483ms/step - loss: 0.6930 - accuracy: 0.5917 - val_loss: 0.6947 - val_accuracy: 0.1604\n",
      "Epoch 29/150\n",
      "189/189 [==============================] - 91s 484ms/step - loss: 0.6931 - accuracy: 0.1672 - val_loss: 0.6946 - val_accuracy: 0.1604\n",
      "Epoch 30/150\n",
      "189/189 [==============================] - 91s 483ms/step - loss: 0.6931 - accuracy: 0.4383 - val_loss: 0.6936 - val_accuracy: 0.1604\n",
      "Epoch 31/150\n",
      "189/189 [==============================] - 92s 485ms/step - loss: 0.6931 - accuracy: 0.2085 - val_loss: 0.6930 - val_accuracy: 0.8396\n",
      "Epoch 32/150\n",
      "189/189 [==============================] - 92s 488ms/step - loss: 0.6931 - accuracy: 0.7166 - val_loss: 0.6936 - val_accuracy: 0.1604\n",
      "Epoch 33/150\n",
      "189/189 [==============================] - 92s 487ms/step - loss: 0.6933 - accuracy: 0.8614 - val_loss: 0.6927 - val_accuracy: 0.8396\n",
      "Epoch 34/150\n",
      "189/189 [==============================] - 91s 483ms/step - loss: 0.6930 - accuracy: 0.3140 - val_loss: 0.6945 - val_accuracy: 0.1604\n",
      "Epoch 35/150\n",
      "189/189 [==============================] - 92s 485ms/step - loss: 0.6930 - accuracy: 0.4976 - val_loss: 0.6929 - val_accuracy: 0.8396\n",
      "Epoch 36/150\n",
      "189/189 [==============================] - 92s 484ms/step - loss: 0.6930 - accuracy: 0.1650 - val_loss: 0.6927 - val_accuracy: 0.8396\n",
      "Epoch 37/150\n",
      "189/189 [==============================] - 91s 481ms/step - loss: 0.6931 - accuracy: 0.7840 - val_loss: 0.6932 - val_accuracy: 0.1604\n",
      "Epoch 38/150\n",
      "189/189 [==============================] - 91s 481ms/step - loss: 0.6930 - accuracy: 0.8713 - val_loss: 0.6925 - val_accuracy: 0.8396\n",
      "Epoch 39/150\n",
      "189/189 [==============================] - 91s 482ms/step - loss: 0.6933 - accuracy: 0.3367 - val_loss: 0.6704 - val_accuracy: 0.8396\n",
      "Epoch 40/150\n",
      "189/189 [==============================] - 91s 482ms/step - loss: 0.6938 - accuracy: 0.5109 - val_loss: 0.6890 - val_accuracy: 0.8396\n",
      "Epoch 41/150\n",
      "189/189 [==============================] - 91s 483ms/step - loss: 0.6932 - accuracy: 0.7933 - val_loss: 0.6901 - val_accuracy: 0.8396\n",
      "Epoch 42/150\n",
      "189/189 [==============================] - 91s 480ms/step - loss: 0.6930 - accuracy: 0.2283 - val_loss: 0.6934 - val_accuracy: 0.1604\n",
      "Epoch 43/150\n",
      "189/189 [==============================] - 91s 481ms/step - loss: 0.6935 - accuracy: 0.7606 - val_loss: 0.6924 - val_accuracy: 0.8396\n",
      "Epoch 44/150\n",
      "189/189 [==============================] - 91s 481ms/step - loss: 0.6930 - accuracy: 0.2092 - val_loss: 0.6932 - val_accuracy: 0.1604\n",
      "Epoch 45/150\n",
      "189/189 [==============================] - 91s 482ms/step - loss: 0.6934 - accuracy: 0.2525 - val_loss: 0.6879 - val_accuracy: 0.8396\n",
      "Epoch 46/150\n",
      "189/189 [==============================] - 91s 484ms/step - loss: 0.6933 - accuracy: 0.4561 - val_loss: 0.6916 - val_accuracy: 0.8396\n",
      "Epoch 47/150\n",
      "189/189 [==============================] - 91s 481ms/step - loss: 0.6940 - accuracy: 0.7081 - val_loss: 0.6952 - val_accuracy: 0.1604\n",
      "Epoch 48/150\n",
      "189/189 [==============================] - 91s 481ms/step - loss: 0.6931 - accuracy: 0.4297 - val_loss: 0.6947 - val_accuracy: 0.1604\n",
      "Epoch 49/150\n",
      "189/189 [==============================] - 91s 479ms/step - loss: 0.6930 - accuracy: 0.3360 - val_loss: 0.6951 - val_accuracy: 0.1604\n",
      "Epoch 50/150\n",
      "189/189 [==============================] - 92s 488ms/step - loss: 0.6930 - accuracy: 0.1147 - val_loss: 0.6975 - val_accuracy: 0.1604\n",
      "Epoch 51/150\n",
      "189/189 [==============================] - 91s 482ms/step - loss: 0.6930 - accuracy: 0.0933 - val_loss: 0.6943 - val_accuracy: 0.1604\n",
      "Epoch 52/150\n",
      "189/189 [==============================] - 91s 483ms/step - loss: 0.6930 - accuracy: 0.3651 - val_loss: 0.6946 - val_accuracy: 0.1604\n",
      "Epoch 53/150\n",
      "189/189 [==============================] - 91s 483ms/step - loss: 0.6930 - accuracy: 0.6445 - val_loss: 0.6954 - val_accuracy: 0.1604\n",
      "Epoch 54/150\n",
      "189/189 [==============================] - 91s 481ms/step - loss: 0.6930 - accuracy: 0.2482 - val_loss: 0.6945 - val_accuracy: 0.1604\n",
      "Epoch 55/150\n",
      "189/189 [==============================] - 91s 481ms/step - loss: 0.6931 - accuracy: 0.6354 - val_loss: 0.6937 - val_accuracy: 0.1604\n",
      "Epoch 56/150\n",
      "189/189 [==============================] - 91s 484ms/step - loss: 0.6930 - accuracy: 0.1953 - val_loss: 0.6935 - val_accuracy: 0.1604\n",
      "Epoch 57/150\n",
      "189/189 [==============================] - 92s 485ms/step - loss: 0.6930 - accuracy: 0.2597 - val_loss: 0.6936 - val_accuracy: 0.1604\n",
      "Epoch 58/150\n",
      "189/189 [==============================] - 91s 480ms/step - loss: 0.6931 - accuracy: 0.8582 - val_loss: 0.6939 - val_accuracy: 0.1604\n",
      "Epoch 59/150\n",
      "189/189 [==============================] - 91s 484ms/step - loss: 0.6930 - accuracy: 0.0936 - val_loss: 0.6947 - val_accuracy: 0.1604\n",
      "Epoch 60/150\n",
      "189/189 [==============================] - 92s 486ms/step - loss: 0.6930 - accuracy: 0.0931 - val_loss: 0.6937 - val_accuracy: 0.1604\n",
      "Epoch 61/150\n",
      "189/189 [==============================] - 91s 481ms/step - loss: 0.6931 - accuracy: 0.5258 - val_loss: 0.6912 - val_accuracy: 0.8396\n",
      "Epoch 62/150\n",
      "189/189 [==============================] - 91s 482ms/step - loss: 0.7305 - accuracy: 0.7251 - val_loss: 0.6830 - val_accuracy: 0.8396\n",
      "Epoch 63/150\n",
      "189/189 [==============================] - 91s 480ms/step - loss: 0.6971 - accuracy: 0.3648 - val_loss: 0.7019 - val_accuracy: 0.1604\n",
      "Epoch 64/150\n",
      "189/189 [==============================] - 91s 481ms/step - loss: 0.6936 - accuracy: 0.2396 - val_loss: 0.6940 - val_accuracy: 0.1604\n",
      "Epoch 65/150\n",
      "189/189 [==============================] - 91s 483ms/step - loss: 0.6935 - accuracy: 0.5569 - val_loss: 0.6920 - val_accuracy: 0.8396\n",
      "Epoch 66/150\n",
      "189/189 [==============================] - 91s 482ms/step - loss: 0.6933 - accuracy: 0.4900 - val_loss: 0.6873 - val_accuracy: 0.8396\n",
      "Epoch 67/150\n",
      "189/189 [==============================] - 91s 482ms/step - loss: 0.6930 - accuracy: 0.4991 - val_loss: 0.6893 - val_accuracy: 0.8396\n",
      "Epoch 68/150\n",
      "189/189 [==============================] - 92s 485ms/step - loss: 0.6939 - accuracy: 0.5472 - val_loss: 0.6887 - val_accuracy: 0.8396\n",
      "Epoch 69/150\n",
      "189/189 [==============================] - 92s 485ms/step - loss: 0.6935 - accuracy: 0.7226 - val_loss: 0.6892 - val_accuracy: 0.8396\n",
      "Epoch 70/150\n",
      "189/189 [==============================] - 92s 485ms/step - loss: 0.6939 - accuracy: 0.4621 - val_loss: 0.6931 - val_accuracy: 0.1673\n",
      "Epoch 71/150\n",
      "189/189 [==============================] - 91s 482ms/step - loss: 0.6935 - accuracy: 0.4413 - val_loss: 0.6919 - val_accuracy: 0.8396\n",
      "Epoch 72/150\n",
      "189/189 [==============================] - 91s 484ms/step - loss: 0.6941 - accuracy: 0.5081 - val_loss: 0.6889 - val_accuracy: 0.8396\n",
      "Epoch 73/150\n",
      "189/189 [==============================] - 91s 483ms/step - loss: 0.6932 - accuracy: 0.5514 - val_loss: 0.7058 - val_accuracy: 0.1604\n",
      "Epoch 74/150\n",
      "189/189 [==============================] - 91s 483ms/step - loss: 0.6942 - accuracy: 0.5280 - val_loss: 0.6962 - val_accuracy: 0.1604\n",
      "Epoch 75/150\n",
      "189/189 [==============================] - 91s 482ms/step - loss: 0.6936 - accuracy: 0.3631 - val_loss: 0.6920 - val_accuracy: 0.8396\n",
      "Epoch 76/150\n",
      "189/189 [==============================] - 91s 483ms/step - loss: 0.6940 - accuracy: 0.4315 - val_loss: 0.6999 - val_accuracy: 0.1604\n",
      "Epoch 77/150\n",
      "189/189 [==============================] - 92s 487ms/step - loss: 0.6928 - accuracy: 0.3696 - val_loss: 0.6675 - val_accuracy: 0.8396\n",
      "Epoch 78/150\n",
      "189/189 [==============================] - 92s 485ms/step - loss: 0.6944 - accuracy: 0.3721 - val_loss: 0.7025 - val_accuracy: 0.1604\n",
      "Epoch 79/150\n",
      "189/189 [==============================] - 92s 487ms/step - loss: 0.6936 - accuracy: 0.3712 - val_loss: 0.6944 - val_accuracy: 0.1604\n",
      "Epoch 80/150\n",
      "189/189 [==============================] - 92s 485ms/step - loss: 0.6933 - accuracy: 0.2344 - val_loss: 0.6963 - val_accuracy: 0.1604\n",
      "Epoch 81/150\n",
      "189/189 [==============================] - 92s 485ms/step - loss: 0.6932 - accuracy: 0.5633 - val_loss: 0.6979 - val_accuracy: 0.1604\n",
      "Epoch 82/150\n",
      "189/189 [==============================] - 92s 485ms/step - loss: 0.6934 - accuracy: 0.1275 - val_loss: 0.6948 - val_accuracy: 0.1604\n",
      "Epoch 83/150\n",
      "189/189 [==============================] - 92s 485ms/step - loss: 0.6931 - accuracy: 0.5816 - val_loss: 0.6953 - val_accuracy: 0.1604\n",
      "Epoch 84/150\n",
      "189/189 [==============================] - 92s 485ms/step - loss: 0.6935 - accuracy: 0.5618 - val_loss: 0.6933 - val_accuracy: 0.1604\n",
      "Epoch 85/150\n",
      "189/189 [==============================] - 91s 484ms/step - loss: 0.6933 - accuracy: 0.5555 - val_loss: 0.6973 - val_accuracy: 0.1604\n",
      "Epoch 86/150\n",
      "189/189 [==============================] - 92s 486ms/step - loss: 0.6938 - accuracy: 0.2090 - val_loss: 0.6969 - val_accuracy: 0.1604\n",
      "Epoch 87/150\n",
      "189/189 [==============================] - 91s 484ms/step - loss: 0.6930 - accuracy: 0.3583 - val_loss: 0.6985 - val_accuracy: 0.1604\n",
      "Epoch 88/150\n",
      "189/189 [==============================] - 91s 480ms/step - loss: 0.6937 - accuracy: 0.3741 - val_loss: 0.6968 - val_accuracy: 0.1604\n",
      "Epoch 89/150\n",
      "189/189 [==============================] - 92s 485ms/step - loss: 0.6930 - accuracy: 0.1971 - val_loss: 0.6959 - val_accuracy: 0.1604\n",
      "Epoch 90/150\n",
      "189/189 [==============================] - 91s 483ms/step - loss: 0.6932 - accuracy: 0.2339 - val_loss: 0.6941 - val_accuracy: 0.1604\n",
      "Epoch 91/150\n",
      "189/189 [==============================] - 92s 488ms/step - loss: 0.6934 - accuracy: 0.3628 - val_loss: 0.6890 - val_accuracy: 0.8396\n",
      "Epoch 92/150\n",
      "189/189 [==============================] - 92s 489ms/step - loss: 0.6930 - accuracy: 0.5283 - val_loss: 0.6918 - val_accuracy: 0.8396\n",
      "Epoch 93/150\n",
      "189/189 [==============================] - 92s 489ms/step - loss: 0.6930 - accuracy: 0.8614 - val_loss: 0.6930 - val_accuracy: 0.8396\n",
      "Epoch 94/150\n",
      "189/189 [==============================] - 91s 481ms/step - loss: 0.6931 - accuracy: 0.5021 - val_loss: 0.6914 - val_accuracy: 0.8396\n",
      "Epoch 95/150\n",
      "189/189 [==============================] - 91s 484ms/step - loss: 0.6932 - accuracy: 0.6020 - val_loss: 0.6939 - val_accuracy: 0.1604\n",
      "Epoch 96/150\n",
      "189/189 [==============================] - 93s 490ms/step - loss: 0.6930 - accuracy: 0.7163 - val_loss: 0.6941 - val_accuracy: 0.1604\n",
      "Epoch 97/150\n",
      "189/189 [==============================] - 92s 487ms/step - loss: 0.6938 - accuracy: 0.2459 - val_loss: 0.6960 - val_accuracy: 0.1604\n",
      "Epoch 98/150\n",
      "189/189 [==============================] - 91s 484ms/step - loss: 0.6931 - accuracy: 0.4777 - val_loss: 0.6953 - val_accuracy: 0.1604\n",
      "Epoch 99/150\n",
      "189/189 [==============================] - 91s 484ms/step - loss: 0.6935 - accuracy: 0.2424 - val_loss: 0.6960 - val_accuracy: 0.1604\n",
      "Epoch 100/150\n",
      "189/189 [==============================] - 92s 488ms/step - loss: 0.6933 - accuracy: 0.6298 - val_loss: 0.6926 - val_accuracy: 0.8396\n",
      "Epoch 101/150\n",
      "189/189 [==============================] - 92s 487ms/step - loss: 0.6928 - accuracy: 0.2401 - val_loss: 0.6987 - val_accuracy: 0.1604\n",
      "Epoch 102/150\n",
      "189/189 [==============================] - 92s 488ms/step - loss: 0.6942 - accuracy: 0.2490 - val_loss: 0.6446 - val_accuracy: 0.8396\n",
      "Epoch 103/150\n",
      "189/189 [==============================] - 92s 487ms/step - loss: 0.6934 - accuracy: 0.1997 - val_loss: 0.7028 - val_accuracy: 0.1604\n",
      "Epoch 104/150\n",
      "189/189 [==============================] - 92s 485ms/step - loss: 0.6932 - accuracy: 0.1569 - val_loss: 0.6973 - val_accuracy: 0.1604\n",
      "Epoch 105/150\n",
      "189/189 [==============================] - 91s 484ms/step - loss: 0.6928 - accuracy: 0.3621 - val_loss: 0.7018 - val_accuracy: 0.1604\n",
      "Epoch 106/150\n",
      "189/189 [==============================] - 92s 485ms/step - loss: 0.6928 - accuracy: 0.3940 - val_loss: 0.7122 - val_accuracy: 0.1604\n",
      "Epoch 107/150\n",
      "189/189 [==============================] - 92s 488ms/step - loss: 0.6932 - accuracy: 0.2175 - val_loss: 0.7059 - val_accuracy: 0.1604\n",
      "Epoch 108/150\n",
      "189/189 [==============================] - 92s 487ms/step - loss: 0.6939 - accuracy: 0.2202 - val_loss: 0.7017 - val_accuracy: 0.1604\n",
      "Epoch 109/150\n",
      "189/189 [==============================] - 92s 485ms/step - loss: 0.6936 - accuracy: 0.3023 - val_loss: 0.6980 - val_accuracy: 0.1604\n",
      "Epoch 110/150\n",
      "189/189 [==============================] - 92s 486ms/step - loss: 0.6922 - accuracy: 0.2457 - val_loss: 0.7008 - val_accuracy: 0.1604\n",
      "Epoch 111/150\n",
      "189/189 [==============================] - 93s 495ms/step - loss: 0.6943 - accuracy: 0.3624 - val_loss: 0.7027 - val_accuracy: 0.1604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/150\n",
      "189/189 [==============================] - 91s 484ms/step - loss: 0.6934 - accuracy: 0.3350 - val_loss: 0.7025 - val_accuracy: 0.1604\n",
      "Epoch 113/150\n",
      "189/189 [==============================] - 90s 479ms/step - loss: 0.6930 - accuracy: 0.2720 - val_loss: 0.7009 - val_accuracy: 0.1604\n",
      "Epoch 114/150\n",
      "189/189 [==============================] - 78s 412ms/step - loss: 0.6931 - accuracy: 0.3246 - val_loss: 0.6988 - val_accuracy: 0.1604\n",
      "Epoch 115/150\n",
      "189/189 [==============================] - 78s 414ms/step - loss: 0.6932 - accuracy: 0.1602 - val_loss: 0.6963 - val_accuracy: 0.1604\n",
      "Epoch 116/150\n",
      "189/189 [==============================] - 87s 461ms/step - loss: 0.6931 - accuracy: 0.1753 - val_loss: 0.6938 - val_accuracy: 0.1604\n",
      "Epoch 117/150\n",
      "189/189 [==============================] - 92s 486ms/step - loss: 0.6930 - accuracy: 0.6674 - val_loss: 0.6929 - val_accuracy: 0.8396\n",
      "Epoch 118/150\n",
      "189/189 [==============================] - 92s 485ms/step - loss: 0.6936 - accuracy: 0.5743 - val_loss: 0.6954 - val_accuracy: 0.1604\n",
      "Epoch 119/150\n",
      "189/189 [==============================] - 91s 482ms/step - loss: 0.6930 - accuracy: 0.4011 - val_loss: 0.6949 - val_accuracy: 0.1604\n",
      "Epoch 120/150\n",
      "189/189 [==============================] - 91s 480ms/step - loss: 0.6935 - accuracy: 0.7534 - val_loss: 0.6965 - val_accuracy: 0.1604\n",
      "Epoch 121/150\n",
      "189/189 [==============================] - 92s 487ms/step - loss: 0.6931 - accuracy: 0.2796 - val_loss: 0.6985 - val_accuracy: 0.1604\n",
      "Epoch 122/150\n",
      "189/189 [==============================] - 92s 484ms/step - loss: 0.6932 - accuracy: 0.3849 - val_loss: 0.6955 - val_accuracy: 0.1604\n",
      "Epoch 123/150\n",
      "189/189 [==============================] - 91s 484ms/step - loss: 0.6929 - accuracy: 0.1091 - val_loss: 0.6945 - val_accuracy: 0.1604\n",
      "Epoch 124/150\n",
      "189/189 [==============================] - 92s 486ms/step - loss: 0.6933 - accuracy: 0.3045 - val_loss: 0.6925 - val_accuracy: 0.8396\n",
      "Epoch 125/150\n",
      "189/189 [==============================] - 92s 485ms/step - loss: 0.6933 - accuracy: 0.8094 - val_loss: 0.6940 - val_accuracy: 0.1604\n",
      "Epoch 126/150\n",
      "189/189 [==============================] - 92s 486ms/step - loss: 0.6935 - accuracy: 0.2824 - val_loss: 0.6985 - val_accuracy: 0.1604\n",
      "Epoch 127/150\n",
      "189/189 [==============================] - 91s 479ms/step - loss: 0.6942 - accuracy: 0.4513 - val_loss: 0.7017 - val_accuracy: 0.1604\n",
      "Epoch 128/150\n",
      "189/189 [==============================] - 91s 483ms/step - loss: 0.6936 - accuracy: 0.1698 - val_loss: 0.7065 - val_accuracy: 0.1604\n",
      "Epoch 129/150\n",
      "189/189 [==============================] - 91s 482ms/step - loss: 0.6933 - accuracy: 0.2258 - val_loss: 0.6961 - val_accuracy: 0.1604\n",
      "Epoch 130/150\n",
      "189/189 [==============================] - 91s 482ms/step - loss: 0.6933 - accuracy: 0.6361 - val_loss: 0.6981 - val_accuracy: 0.1604\n",
      "Epoch 131/150\n",
      "189/189 [==============================] - 92s 486ms/step - loss: 0.6931 - accuracy: 0.1511 - val_loss: 0.6980 - val_accuracy: 0.1604\n",
      "Epoch 132/150\n",
      "189/189 [==============================] - 91s 484ms/step - loss: 0.6922 - accuracy: 0.6429 - val_loss: 0.6939 - val_accuracy: 0.1604\n",
      "Epoch 133/150\n",
      "189/189 [==============================] - 91s 482ms/step - loss: 0.6939 - accuracy: 0.3678 - val_loss: 0.7025 - val_accuracy: 0.1604\n",
      "Epoch 134/150\n",
      "189/189 [==============================] - 92s 486ms/step - loss: 0.6947 - accuracy: 0.2248 - val_loss: 0.7023 - val_accuracy: 0.1604\n",
      "Epoch 135/150\n",
      "189/189 [==============================] - 91s 481ms/step - loss: 0.6934 - accuracy: 0.1325 - val_loss: 0.6967 - val_accuracy: 0.1604\n",
      "Epoch 136/150\n",
      "189/189 [==============================] - 92s 485ms/step - loss: 0.6933 - accuracy: 0.3349 - val_loss: 0.6952 - val_accuracy: 0.1604\n",
      "Epoch 137/150\n",
      "189/189 [==============================] - 91s 484ms/step - loss: 0.6930 - accuracy: 0.1171 - val_loss: 0.6948 - val_accuracy: 0.1604\n",
      "Epoch 138/150\n",
      "189/189 [==============================] - 92s 485ms/step - loss: 0.6930 - accuracy: 0.3734 - val_loss: 0.6949 - val_accuracy: 0.1604\n",
      "Epoch 139/150\n",
      "189/189 [==============================] - 91s 481ms/step - loss: 0.6930 - accuracy: 0.3151 - val_loss: 0.6966 - val_accuracy: 0.1604\n",
      "Epoch 140/150\n",
      "189/189 [==============================] - 92s 487ms/step - loss: 0.6936 - accuracy: 0.3121 - val_loss: 0.6959 - val_accuracy: 0.1604\n",
      "Epoch 141/150\n",
      "189/189 [==============================] - 92s 486ms/step - loss: 0.6931 - accuracy: 0.1290 - val_loss: 0.6942 - val_accuracy: 0.1604\n",
      "Epoch 142/150\n",
      "189/189 [==============================] - 91s 484ms/step - loss: 0.6930 - accuracy: 0.7242 - val_loss: 0.6940 - val_accuracy: 0.1604\n",
      "Epoch 143/150\n",
      "189/189 [==============================] - 92s 485ms/step - loss: 0.6931 - accuracy: 0.7637 - val_loss: 0.6952 - val_accuracy: 0.1604\n",
      "Epoch 144/150\n",
      "189/189 [==============================] - 91s 482ms/step - loss: 0.6932 - accuracy: 0.1491 - val_loss: 0.6951 - val_accuracy: 0.1604\n",
      "Epoch 145/150\n",
      "189/189 [==============================] - 91s 484ms/step - loss: 0.6933 - accuracy: 0.2735 - val_loss: 0.6934 - val_accuracy: 0.1604\n",
      "Epoch 146/150\n",
      "189/189 [==============================] - 91s 482ms/step - loss: 0.6931 - accuracy: 0.3701 - val_loss: 0.6921 - val_accuracy: 0.8396\n",
      "Epoch 147/150\n",
      "189/189 [==============================] - 92s 485ms/step - loss: 0.6929 - accuracy: 0.7163 - val_loss: 0.6957 - val_accuracy: 0.1604\n",
      "Epoch 148/150\n",
      "189/189 [==============================] - 92s 485ms/step - loss: 0.6933 - accuracy: 0.2984 - val_loss: 0.6950 - val_accuracy: 0.1604\n",
      "Epoch 149/150\n",
      "189/189 [==============================] - 91s 483ms/step - loss: 0.6931 - accuracy: 0.7008 - val_loss: 0.6935 - val_accuracy: 0.1604\n",
      "Epoch 150/150\n",
      "189/189 [==============================] - 92s 486ms/step - loss: 0.6931 - accuracy: 0.6631 - val_loss: 0.6956 - val_accuracy: 0.1604\n",
      "27/27 [==============================] - 4s 141ms/step - loss: 0.6961 - accuracy: 0.0894\n",
      "Training took a total of 13819 seconds\n"
     ]
    }
   ],
   "source": [
    "# seq_result = {}\n",
    "# lookback = [6,12,18,24,48,72]\n",
    "# for hour in lookback:\n",
    "hour = 12\n",
    "start = datetime.now()\n",
    "print(f\"Training by looking back {hour} hours of alarm data\")\n",
    "wba124 = seven_days_LSTM(\"WBA124\", wba124_fullalarm, hour, 3)\n",
    "\n",
    "# pad the alarm to train on LSTM\n",
    "unpadded_arr = wba124.X_seq\n",
    "padded_alarm = np.zeros([len(unpadded_arr),len(max(unpadded_arr,key = lambda x: len(x)))])\n",
    "for i,j in enumerate(unpadded_arr):\n",
    "     padded_alarm[i][0:len(j)] = j\n",
    "\n",
    "# scale training data for the model to learn faster, because max length is taking the model too long to train per epoch\n",
    "scaler = StandardScaler()\n",
    "scaled_X_seq = scaler.fit_transform(padded_alarm)\n",
    "\n",
    "#train_val_test split\n",
    "val_percentage = 0.2\n",
    "test_percentage = 0.1\n",
    "\n",
    "test_index = int(len(scaled_X_seq) * (1-test_percentage))\n",
    "val_index = int(len(scaled_X_seq) * (1- val_percentage - test_percentage))\n",
    "\n",
    "X_train_seq, X_val_seq, X_test_seq = scaled_X_seq[:val_index], scaled_X_seq[val_index:test_index], scaled_X_seq[test_index:]\n",
    "y_train_seq, y_val_seq, y_test_seq = wba124.y[:val_index], wba124.y[val_index:test_index], wba124.y[test_index:]\n",
    "\n",
    "X_train_seq = X_train_seq.reshape(X_train_seq.shape[0], X_train_seq.shape[1], 1)\n",
    "X_val_seq = X_val_seq.reshape(X_val_seq.shape[0], X_val_seq.shape[1], 1)\n",
    "X_test_seq = X_test_seq.reshape(X_test_seq.shape[0], X_test_seq.shape[1], 1)\n",
    "\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                             np.unique(y_train_seq),\n",
    "                                             y_train_seq)\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "\n",
    "#need to reinitialize the model because x_train_seq changes in shape\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(X_train_seq.shape[1:]), return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(LSTM(64, input_shape=(X_train_seq.shape[1:])))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(32, activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(2, activation = 'softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train_seq, y_train_seq, \n",
    "                batch_size=BATCH_SIZE, epochs=EPOCHS, \n",
    "                validation_data=(X_val_seq, y_val_seq), \n",
    "                class_weight=class_weights_dict)\n",
    "evaluate = model.evaluate(X_test_seq, y_test_seq) #loss, mse\n",
    "\n",
    "end = datetime.now()\n",
    "time = end - start\n",
    "print(f\"Training took a total of {time.seconds} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a9bed4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, [0.6960725784301758, 0.08943089097738266])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hour, evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28605e22",
   "metadata": {},
   "source": [
    "## Padding the sequence with the average length\n",
    "#### https://towardsdatascience.com/using-tensorflow-ragged-tensors-2af07849a7bd\n",
    "#### Apparently can also greatly help boost accracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb3be33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wba124_fullalarm = find_full_alarm(\"WBA124\", \"Data/WBA124_FullAlarm.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70942ac3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training by looking back 6 hours of alarm data\n",
      "Epoch 1/150\n",
      "189/189 [==============================] - 7s 18ms/step - loss: 0.6948 - accuracy: 0.6301 - val_loss: 0.6975 - val_accuracy: 0.1649\n",
      "Epoch 2/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.6955 - accuracy: 0.4774 - val_loss: 0.6836 - val_accuracy: 0.7718\n",
      "Epoch 3/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.6945 - accuracy: 0.4411 - val_loss: 0.6766 - val_accuracy: 0.7816\n",
      "Epoch 4/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.6948 - accuracy: 0.4905 - val_loss: 0.6793 - val_accuracy: 0.7729\n",
      "Epoch 5/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.6951 - accuracy: 0.3723 - val_loss: 0.6520 - val_accuracy: 0.7898\n",
      "Epoch 6/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.6938 - accuracy: 0.3476 - val_loss: 0.7000 - val_accuracy: 0.1626\n",
      "Epoch 7/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.6943 - accuracy: 0.4866 - val_loss: 0.7106 - val_accuracy: 0.1603\n",
      "Epoch 8/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.6932 - accuracy: 0.3473 - val_loss: 0.6687 - val_accuracy: 0.8043\n",
      "Epoch 9/150\n",
      "189/189 [==============================] - 3s 13ms/step - loss: 0.6926 - accuracy: 0.5315 - val_loss: 0.6927 - val_accuracy: 0.7660\n",
      "Epoch 10/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.6938 - accuracy: 0.4047 - val_loss: 0.7122 - val_accuracy: 0.1597\n",
      "Epoch 11/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.6925 - accuracy: 0.4226 - val_loss: 0.6741 - val_accuracy: 0.7706\n",
      "Epoch 12/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.6936 - accuracy: 0.4879 - val_loss: 0.6809 - val_accuracy: 0.7741\n",
      "Epoch 13/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.6926 - accuracy: 0.4748 - val_loss: 0.6616 - val_accuracy: 0.8130\n",
      "Epoch 14/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.6934 - accuracy: 0.4992 - val_loss: 0.6717 - val_accuracy: 0.7956\n",
      "Epoch 15/150\n",
      "189/189 [==============================] - 2s 12ms/step - loss: 0.6929 - accuracy: 0.5110 - val_loss: 0.6948 - val_accuracy: 0.7747\n",
      "Epoch 16/150\n",
      "189/189 [==============================] - 2s 11ms/step - loss: 0.6950 - accuracy: 0.4482 - val_loss: 0.7011 - val_accuracy: 0.1597\n",
      "Epoch 17/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.6923 - accuracy: 0.3984 - val_loss: 0.6710 - val_accuracy: 0.7915\n",
      "Epoch 18/150\n",
      "189/189 [==============================] - 2s 13ms/step - loss: 0.6932 - accuracy: 0.5045 - val_loss: 0.6752 - val_accuracy: 0.7863\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.6826 - accuracy: 0.6365\n",
      "Training took a total of 170 seconds\n",
      "Training by looking back 12 hours of alarm data\n",
      "Epoch 1/150\n",
      "189/189 [==============================] - 9s 31ms/step - loss: 0.6986 - accuracy: 0.4835 - val_loss: 0.7120 - val_accuracy: 0.2138\n",
      "Epoch 2/150\n",
      "189/189 [==============================] - 5s 26ms/step - loss: 0.6953 - accuracy: 0.5132 - val_loss: 0.7598 - val_accuracy: 0.1702\n",
      "Epoch 3/150\n",
      "189/189 [==============================] - 5s 26ms/step - loss: 0.6933 - accuracy: 0.5811 - val_loss: 0.6939 - val_accuracy: 0.1993\n",
      "Epoch 4/150\n",
      "189/189 [==============================] - 5s 26ms/step - loss: 0.6942 - accuracy: 0.4911 - val_loss: 0.6556 - val_accuracy: 0.8013\n",
      "Epoch 5/150\n",
      "189/189 [==============================] - 5s 25ms/step - loss: 0.6939 - accuracy: 0.6153 - val_loss: 0.6857 - val_accuracy: 0.7879\n",
      "Epoch 6/150\n",
      "189/189 [==============================] - 4s 23ms/step - loss: 0.6936 - accuracy: 0.5034 - val_loss: 0.7119 - val_accuracy: 0.1604\n",
      "Epoch 7/150\n",
      "189/189 [==============================] - 4s 23ms/step - loss: 0.6930 - accuracy: 0.4053 - val_loss: 0.6773 - val_accuracy: 0.8013\n",
      "Epoch 8/150\n",
      "189/189 [==============================] - 5s 24ms/step - loss: 0.6922 - accuracy: 0.6399 - val_loss: 0.6969 - val_accuracy: 0.7699\n",
      "Epoch 9/150\n",
      "189/189 [==============================] - 4s 23ms/step - loss: 0.6924 - accuracy: 0.5408 - val_loss: 0.6778 - val_accuracy: 0.7908\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.6906 - accuracy: 0.6156\n",
      "Training took a total of 181 seconds\n",
      "Training by looking back 18 hours of alarm data\n",
      "Epoch 1/150\n",
      "189/189 [==============================] - 11s 39ms/step - loss: 0.6987 - accuracy: 0.5272 - val_loss: 0.6318 - val_accuracy: 0.7936\n",
      "Epoch 2/150\n",
      "189/189 [==============================] - 6s 33ms/step - loss: 0.6946 - accuracy: 0.5586 - val_loss: 0.7075 - val_accuracy: 0.1605\n",
      "Epoch 3/150\n",
      "189/189 [==============================] - 6s 32ms/step - loss: 0.6932 - accuracy: 0.4993 - val_loss: 0.7159 - val_accuracy: 0.1622\n",
      "Epoch 4/150\n",
      "189/189 [==============================] - 6s 32ms/step - loss: 0.6935 - accuracy: 0.4824 - val_loss: 0.6240 - val_accuracy: 0.7890\n",
      "Epoch 5/150\n",
      "189/189 [==============================] - 6s 33ms/step - loss: 0.6924 - accuracy: 0.4560 - val_loss: 0.6927 - val_accuracy: 0.7698\n",
      "Epoch 6/150\n",
      "189/189 [==============================] - 6s 32ms/step - loss: 0.6929 - accuracy: 0.4777 - val_loss: 0.7067 - val_accuracy: 0.1640\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 0.7177 - accuracy: 0.0964\n",
      "Training took a total of 186 seconds\n",
      "Training by looking back 24 hours of alarm data\n",
      "Epoch 1/150\n",
      "189/189 [==============================] - 12s 48ms/step - loss: 0.6980 - accuracy: 0.6038 - val_loss: 0.7011 - val_accuracy: 0.1605\n",
      "Epoch 2/150\n",
      "189/189 [==============================] - 8s 44ms/step - loss: 0.6949 - accuracy: 0.4505 - val_loss: 0.6871 - val_accuracy: 0.7756\n",
      "Epoch 3/150\n",
      "189/189 [==============================] - 9s 46ms/step - loss: 0.6935 - accuracy: 0.5121 - val_loss: 0.6926 - val_accuracy: 0.2157\n",
      "Epoch 4/150\n",
      "189/189 [==============================] - 9s 46ms/step - loss: 0.6950 - accuracy: 0.5334 - val_loss: 0.7098 - val_accuracy: 0.1605\n",
      "Epoch 5/150\n",
      "189/189 [==============================] - 9s 48ms/step - loss: 0.6937 - accuracy: 0.2520 - val_loss: 0.6483 - val_accuracy: 0.7971\n",
      "Epoch 6/150\n",
      "189/189 [==============================] - 9s 48ms/step - loss: 0.6951 - accuracy: 0.5070 - val_loss: 0.6827 - val_accuracy: 0.8174\n",
      "Epoch 7/150\n",
      "189/189 [==============================] - 9s 48ms/step - loss: 0.6940 - accuracy: 0.5154 - val_loss: 0.6744 - val_accuracy: 0.7733\n",
      "Epoch 8/150\n",
      "189/189 [==============================] - 9s 48ms/step - loss: 0.6930 - accuracy: 0.5493 - val_loss: 0.6749 - val_accuracy: 0.7750\n",
      "Epoch 9/150\n",
      "189/189 [==============================] - 9s 48ms/step - loss: 0.6934 - accuracy: 0.4654 - val_loss: 0.7070 - val_accuracy: 0.1605\n",
      "Epoch 10/150\n",
      "189/189 [==============================] - 9s 48ms/step - loss: 0.6983 - accuracy: 0.2895 - val_loss: 0.6706 - val_accuracy: 0.7872\n",
      "Epoch 11/150\n",
      "189/189 [==============================] - 9s 47ms/step - loss: 0.6943 - accuracy: 0.4953 - val_loss: 0.7087 - val_accuracy: 0.1872\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.7061 - accuracy: 0.2602\n",
      "Training took a total of 250 seconds\n",
      "Training by looking back 48 hours of alarm data\n",
      "Epoch 1/150\n",
      "188/188 [==============================] - 21s 93ms/step - loss: 0.6977 - accuracy: 0.4881 - val_loss: 0.7178 - val_accuracy: 0.1595\n",
      "Epoch 2/150\n",
      "188/188 [==============================] - 17s 90ms/step - loss: 0.6938 - accuracy: 0.5109 - val_loss: 0.6980 - val_accuracy: 0.2002\n",
      "Epoch 3/150\n",
      "188/188 [==============================] - 16s 88ms/step - loss: 0.6942 - accuracy: 0.4994 - val_loss: 0.6886 - val_accuracy: 0.8399\n",
      "Epoch 4/150\n",
      "188/188 [==============================] - 16s 85ms/step - loss: 0.6938 - accuracy: 0.5832 - val_loss: 0.7020 - val_accuracy: 0.2381\n",
      "Epoch 5/150\n",
      "188/188 [==============================] - 16s 85ms/step - loss: 0.6951 - accuracy: 0.6264 - val_loss: 0.6949 - val_accuracy: 0.2340\n",
      "Epoch 6/150\n",
      "188/188 [==============================] - 16s 83ms/step - loss: 0.6941 - accuracy: 0.5012 - val_loss: 0.6832 - val_accuracy: 0.8405\n",
      "Epoch 7/150\n",
      "188/188 [==============================] - 16s 83ms/step - loss: 0.6932 - accuracy: 0.6663 - val_loss: 0.6892 - val_accuracy: 0.8405\n",
      "Epoch 8/150\n",
      "188/188 [==============================] - 16s 86ms/step - loss: 0.6951 - accuracy: 0.5628 - val_loss: 0.7082 - val_accuracy: 0.1601\n",
      "Epoch 9/150\n",
      "188/188 [==============================] - 17s 90ms/step - loss: 0.6937 - accuracy: 0.3852 - val_loss: 0.7015 - val_accuracy: 0.2194\n",
      "Epoch 10/150\n",
      "188/188 [==============================] - 17s 91ms/step - loss: 0.6926 - accuracy: 0.4746 - val_loss: 0.6675 - val_accuracy: 0.8376\n",
      "Epoch 11/150\n",
      "188/188 [==============================] - 17s 91ms/step - loss: 0.6941 - accuracy: 0.5338 - val_loss: 0.6857 - val_accuracy: 0.8306\n",
      "27/27 [==============================] - 1s 26ms/step - loss: 0.6757 - accuracy: 0.8802\n",
      "Training took a total of 371 seconds\n",
      "Training by looking back 72 hours of alarm data\n",
      "Epoch 1/150\n",
      "188/188 [==============================] - 25s 116ms/step - loss: 0.6975 - accuracy: 0.5463 - val_loss: 0.7069 - val_accuracy: 0.1590\n",
      "Epoch 2/150\n",
      "188/188 [==============================] - 21s 112ms/step - loss: 0.6960 - accuracy: 0.4468 - val_loss: 0.6872 - val_accuracy: 0.8218\n",
      "Epoch 3/150\n",
      "188/188 [==============================] - 21s 112ms/step - loss: 0.6960 - accuracy: 0.4152 - val_loss: 0.7148 - val_accuracy: 0.1584\n",
      "Epoch 4/150\n",
      "188/188 [==============================] - 21s 112ms/step - loss: 0.6948 - accuracy: 0.4342 - val_loss: 0.7036 - val_accuracy: 0.1584\n",
      "Epoch 5/150\n",
      "188/188 [==============================] - 21s 111ms/step - loss: 0.6948 - accuracy: 0.3824 - val_loss: 0.7017 - val_accuracy: 0.1590\n",
      "Epoch 6/150\n",
      "188/188 [==============================] - 21s 113ms/step - loss: 0.6939 - accuracy: 0.3550 - val_loss: 0.7132 - val_accuracy: 0.1578\n",
      "Epoch 7/150\n",
      "188/188 [==============================] - 21s 112ms/step - loss: 0.6943 - accuracy: 0.3784 - val_loss: 0.6925 - val_accuracy: 0.2330\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 0.6837 - accuracy: 0.5308\n",
      "Training took a total of 397 seconds\n"
     ]
    }
   ],
   "source": [
    "seq_result = {}\n",
    "lookback = [6,12,18,24,48,72]\n",
    "for hour in lookback:\n",
    "    start = datetime.now()\n",
    "    print(f\"Training by looking back {hour} hours of alarm data\")\n",
    "    wba124 = seven_days_LSTM(\"WBA124\", wba124_fullalarm, hour, 3)\n",
    "\n",
    "    # pad the alarm to train on LSTM\n",
    "    unpadded_arr = wba124.X_seq\n",
    "    mean_length = int(np.mean([len(x) for x in unpadded_arr]))\n",
    "    padded_alarm = np.zeros([len(unpadded_arr), mean_length])\n",
    "    for i,j in enumerate(unpadded_arr):\n",
    "        padded_alarm[i][0:len(j)] = j[:mean_length]\n",
    "\n",
    "    # scale training data for the model to learn faster\n",
    "    scaler = StandardScaler()\n",
    "    scaled_X_seq = scaler.fit_transform(padded_alarm)\n",
    "\n",
    "    #train_val_test split\n",
    "    val_percentage = 0.2\n",
    "    test_percentage = 0.1\n",
    "\n",
    "    test_index = int(len(scaled_X_seq) * (1-test_percentage))\n",
    "    val_index = int(len(scaled_X_seq) * (1- val_percentage - test_percentage))\n",
    "\n",
    "    X_train_seq, X_val_seq, X_test_seq = scaled_X_seq[:val_index], scaled_X_seq[val_index:test_index], scaled_X_seq[test_index:]\n",
    "    y_train_seq, y_val_seq, y_test_seq = wba124.y[:val_index], wba124.y[val_index:test_index], wba124.y[test_index:]\n",
    "\n",
    "    X_train_seq = X_train_seq.reshape(X_train_seq.shape[0], X_train_seq.shape[1], 1)\n",
    "    X_val_seq = X_val_seq.reshape(X_val_seq.shape[0], X_val_seq.shape[1], 1)\n",
    "    X_test_seq = X_test_seq.reshape(X_test_seq.shape[0], X_test_seq.shape[1], 1)\n",
    "\n",
    "    class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(y_train_seq),\n",
    "                                                 y_train_seq)\n",
    "    class_weights_dict = dict(enumerate(class_weights))\n",
    "\n",
    "    #need to reinitialize the model because x_train_seq changes in shape\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, input_shape=(X_train_seq.shape[1:]), return_sequences=True))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(LSTM(64, input_shape=(X_train_seq.shape[1:])))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(32, activation = 'relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(2, activation = 'softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    callbacks = [EarlyStopping(monitor='val_accuracy', mode='max', patience=5)]\n",
    "\n",
    "    history = model.fit(X_train_seq, y_train_seq, \n",
    "                    batch_size=BATCH_SIZE, epochs=EPOCHS, \n",
    "                    validation_data=(X_val_seq, y_val_seq), \n",
    "                    class_weight=class_weights_dict, callbacks=callbacks)\n",
    "    \n",
    "    evaluate = model.evaluate(X_test_seq, y_test_seq) #loss, mse\n",
    "\n",
    "    end = datetime.now()\n",
    "    time = end - start\n",
    "    seq_result[hour, mean_length] = evaluate\n",
    "    print(f\"Training took a total of {time.seconds} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e68372e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(6, 9): [0.6825759410858154, 0.6364692449569702],\n",
       " (12, 19): [0.6905587315559387, 0.6155632734298706],\n",
       " (18, 28): [0.7176927924156189, 0.09639953821897507],\n",
       " (24, 38): [0.7060851454734802, 0.2601625919342041],\n",
       " (48, 76): [0.6757280826568604, 0.880232572555542],\n",
       " (72, 114): [0.6836994290351868, 0.530849814414978]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6aad2f7",
   "metadata": {},
   "source": [
    "# Training with Embedding layer\n",
    "### LabelEncode the alarm id to determine n_vocab in Embedding layer\n",
    "### Since max_vocab measures the maximum number of unique vocab in our input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc33a2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encode(X_seq): # do this the manual way as we are not certain if sklearn LabelEncoder can handle 3D array\n",
    "    all_unique_alarms = [set(ele) for ele in X_seq]\n",
    "    unique_alarms = set()\n",
    "    for ele in all_unique_alarms:\n",
    "        unique_alarms |= ele\n",
    "    \n",
    "    enc_label = 1  #start encoding from 1 as we have to pad the sequence with 0\n",
    "    mapping_dict = {}\n",
    "    for ele in unique_alarms:\n",
    "        mapping_dict[ele] = enc_label\n",
    "        enc_label += 1\n",
    "\n",
    "        enc_array = []\n",
    "        \n",
    "    #X_seq is a 3D array\n",
    "    for timestamp in X_seq:\n",
    "        tmp_arr = []\n",
    "        for ele in timestamp:\n",
    "            tmp_arr.append(mapping_dict[ele])\n",
    "        enc_array.append(np.array(tmp_arr))\n",
    "\n",
    "    return np.array(enc_array), len(unique_alarms)+1, mapping_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28197e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_model(padded_alarm, n_alarms):\n",
    "#     model = Sequential()\n",
    "#     model.add(Input(shape=(padded_alarm.shape[1])))\n",
    "#     model.add(Embedding(n_alarms, 128, mask_zero=True))\n",
    "#     model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "#     model.add(Bidirectional(LSTM(10)))\n",
    "#     model.add(Dropout(0.3))\n",
    "#     model.add(Dense(10, activation='relu'))\n",
    "#     model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#     model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), 'accuracy'])\n",
    "    \n",
    "#     return model\n",
    "\n",
    "def create_model(X_train, n_alarm):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=n_alarms, output_dim=10, input_length=X_train.shape[1], mask_zero=True))\n",
    "    model.add(Conv1D(64,15,strides=2,input_shape=(X_train.shape[1], 1), use_bias=False, activation='relu'))\n",
    "    model.add(Conv1D(64,3))\n",
    "    model.add(Conv1D(64,3,strides=2, activation=\"relu\"))\n",
    "    model.add(Conv1D(64,3))\n",
    "    model.add(Conv1D(64,3,strides=2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), 'accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a6bf92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomly_select_negative(X_seq, major_down_arr, ratio):\n",
    "    bool_arr = [ele==0 for ele in major_down_arr]\n",
    "    major_arr = np.array(major_down_arr)[np.where(bool_arr)[0]]\n",
    "    print(len(major_arr), len(major_down_arr))\n",
    "    negative = X_seq[np.where(bool_arr)[0]]\n",
    "    \n",
    "    positive_bool_arr = [ele==1 for ele in major_down_arr]\n",
    "    positive_major_arr = np.array(major_down_arr)[np.where(positive_bool_arr)[0]]\n",
    "    print(len(positive_major_arr))\n",
    "    positive = X_seq[np.where(positive_bool_arr)[0]]\n",
    "    \n",
    "    discard, keep, target_discard, target_keep = train_test_split(negative, major_arr, test_size=ratio)\n",
    "    \n",
    "    handpicked = np.concatenate((positive, keep))\n",
    "    target = np.concatenate((positive_major_arr, target_keep))\n",
    "    \n",
    "    if len(handpicked) != len(target):\n",
    "        raise Exception(\"Length of training inputs are different\")\n",
    "    \n",
    "    return handpicked, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40286b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_empty_datapoint(X_seq, major_down_arr):\n",
    "    bool_arr = [len(ele)==0 for ele in X_seq] #this is to find the index to remove for bot y array and X_seq\n",
    "    idx_remove = np.where(bool_arr)[0]\n",
    "    major_down_arr = np.delete(np.array(major_down_arr), idx_remove) # remove the corresponding y value as well\n",
    "    X_seq = np.delete(X_seq, idx_remove) #remove rows with no alarms\n",
    "    return X_seq, major_down_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb9cc591",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seq_result = {}\n",
    "lookback = [12, 24, 48, 72]\n",
    "\n",
    "monitor = 'val_recall'\n",
    "mode = 'max'\n",
    "hour = 24\n",
    "# count = 0\n",
    "# for hour in lookback:\n",
    "#     if count  == 0:\n",
    "#         monitor = \"val_recall\"\n",
    "#     else:\n",
    "#         monitor = f\"val_recall_{count}\"\n",
    "    \n",
    "#     count += 1\n",
    "#     start = datetime.now()\n",
    "\n",
    "wba123_fullalarm = pd.read_excel(\"Data/WBA123_FullAlarm.xlsx\", usecols = \"B,C,D,F,M\")\n",
    "wba123 = seven_days_LSTM(\"WBA123\", wba123_fullalarm, hour, 3)\n",
    "\n",
    "wba124_fullalarm = pd.read_excel(\"Data/WBA124_FullAlarm.xlsx\", usecols = \"B,C,D,F,M\")\n",
    "wba124 = seven_days_LSTM(\"WBA124\", wba124_fullalarm, hour, 3)\n",
    "\n",
    "wba126_fullalarm = pd.read_excel(\"Data/WBA126_FullAlarm.xlsx\", usecols = \"B,C,D,F,M\")\n",
    "wba126 = seven_days_LSTM(\"WBA126\", wba126_fullalarm, hour, 3)\n",
    "\n",
    "wba127_fullalarm = pd.read_excel(\"Data/WBA127_FullAlarm.xlsx\", usecols = \"B,C,D,F,M\")\n",
    "wba127 = seven_days_LSTM(\"WBA127\", wba127_fullalarm, hour, 3)\n",
    "\n",
    "wba128_fullalarm = pd.read_excel(\"Data/WBA128_FullAlarm.xlsx\", usecols = \"B,C,D,F,M\")\n",
    "wba128 = seven_days_LSTM(\"WBA128\", wba128_fullalarm, hour, 3)\n",
    "\n",
    "#     #remove empty datapoints to help reduce loss\n",
    "#     encoded_X_seq, target = remove_empty_datapoint(encoded_X_seq, target)\n",
    "    \n",
    "    #hand pick negative data to counter imbalance\n",
    "#     encoded_X_seq, target = randomly_select_negative(encoded_X_seq, target, 0.2)\n",
    "#     print(len(encoded_X_seq), len(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abe426d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp1 = np.concatenate((wba123.X_seq, wba124.X_seq, wba126.X_seq, wba127.X_seq, wba128.X_seq))\n",
    "encoded_X_seq, n_alarms, mapping_dict = label_encode(tmp1)\n",
    "target = np.concatenate((wba123.major_down_arr, wba124.major_down_arr, wba126.major_down_arr, wba127.major_down_arr, wba128.major_down_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2aa23fb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "monitor = 'val_recall'\n",
    "\n",
    "#shuffle the X and Y values to make generalize better\n",
    "shuffled = shuffle(encoded_X_seq, target)\n",
    "encoded_X_seq = shuffled[0]\n",
    "target = shuffled[1]\n",
    "\n",
    "# padding to average length\n",
    "mean_length = int(np.mean([len(x) for x in encoded_X_seq]))\n",
    "padded_alarm = np.zeros([len(encoded_X_seq), mean_length])\n",
    "for i,j in enumerate(encoded_X_seq):\n",
    "    padded_alarm[i][0:len(j)] = j[:mean_length]\n",
    "\n",
    "#train_val_test split\n",
    "X_train_seq, X_val_seq, y_train_seq, y_val_seq =  train_test_split(padded_alarm, target, test_size=0.4, random_state=42, stratify=target)\n",
    "X_val_seq, X_test_seq, y_val_seq, y_test_seq =  train_test_split(X_val_seq, y_val_seq, test_size=0.4, random_state=42, stratify=y_val_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5c2795b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/engine/training.py:853 train_function  *\n        return step_function(self, iterator)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/engine/training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/engine/training.py:835 run_step  **\n        outputs = model.train_step(data)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/engine/training.py:792 train_step\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/engine/compile_utils.py:457 update_state\n        metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/utils/metrics_utils.py:73 decorated\n        update_op = update_state_fn(*args, **kwargs)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/metrics.py:177 update_state_fn\n        return ag_update_state(*args, **kwargs)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/metrics.py:1366 update_state  **\n        sample_weight=sample_weight)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/utils/metrics_utils.py:623 update_confusion_matrix_variables\n        y_pred.shape.assert_is_compatible_with(y_true.shape)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/tensorflow/python/framework/tensor_shape.py:1161 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 2) and (None, 1) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-6a6910432b37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m                 \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                 callbacks=callbacks)\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mevaluate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_seq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#loss, mse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    759\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 760\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3065\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3066\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3067\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3463\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3306\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3307\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3308\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3309\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3310\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    992\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/engine/training.py:853 train_function  *\n        return step_function(self, iterator)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/engine/training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/engine/training.py:835 run_step  **\n        outputs = model.train_step(data)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/engine/training.py:792 train_step\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/engine/compile_utils.py:457 update_state\n        metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/utils/metrics_utils.py:73 decorated\n        update_op = update_state_fn(*args, **kwargs)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/metrics.py:177 update_state_fn\n        return ag_update_state(*args, **kwargs)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/metrics.py:1366 update_state  **\n        sample_weight=sample_weight)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/utils/metrics_utils.py:623 update_confusion_matrix_variables\n        y_pred.shape.assert_is_compatible_with(y_true.shape)\n    /home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/tensorflow/python/framework/tensor_shape.py:1161 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 2) and (None, 1) are incompatible\n"
     ]
    }
   ],
   "source": [
    "model = create_model(padded_alarm, n_alarms)\n",
    "\n",
    "# model seems to be overfitting, try to reduce overfitting by reduce LR, but model should take longer to converge so use a larger EPOCH\n",
    "callbacks = [ReduceLROnPlateau(monitor=monitor, factor=0.2, patience=5, min_lr=0.001), \\\n",
    "            EarlyStopping(monitor=monitor, patience=30, mode=mode, restore_best_weights=True)]\n",
    "\n",
    "history = model.fit(X_train_seq, y_train_seq, \n",
    "                batch_size=BATCH_SIZE, epochs=EPOCHS, \n",
    "                validation_data=(X_val_seq, y_val_seq), \n",
    "                callbacks=callbacks)\n",
    "\n",
    "evaluate = model.evaluate(X_test_seq, y_test_seq) #loss, mse\n",
    "\n",
    "pred = model.predict(X_test_seq)\n",
    "classes = []\n",
    "for ele in pred:\n",
    "    classes.append(int((ele>0.5)[0]))\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test_seq, classes)\n",
    "\n",
    "seq_result[hour] = [evaluate, cm]\n",
    "\n",
    "end = datetime.now()\n",
    "time = end - start\n",
    "print(f\"Training took {time.seconds} seconds to complete.\")\n",
    "seq_result[hour, mean_length] = evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a754f11",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer conv1d is incompatible with the layer: : expected min_ndim=3, found ndim=2. Full shape received: (53, 128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-29d238c3cc80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_embed_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_test_seq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0malarms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m44\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m45\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/backend.py\u001b[0m in \u001b[0;36mfunc\u001b[0;34m(model_inputs)\u001b[0m\n\u001b[1;32m   4076\u001b[0m     \u001b[0mwrap_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4077\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4078\u001b[0;31m       \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4079\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mwrap_outputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4080\u001b[0m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    413\u001b[0m     \"\"\"\n\u001b[1;32m    414\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m--> 415\u001b[0;31m         inputs, training=training, mask=mask)\n\u001b[0m\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1018\u001b[0m         training=training_mode):\n\u001b[1;32m   1019\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m       \u001b[0minput_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1021\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0meager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \u001b[0mcall_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    232\u001b[0m                          \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                          \u001b[0;34m'. Full shape received: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                          str(tuple(shape)))\n\u001b[0m\u001b[1;32m    235\u001b[0m     \u001b[0;31m# Check dtype.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer conv1d is incompatible with the layer: : expected min_ndim=3, found ndim=2. Full shape received: (53, 128)"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# with a Sequential model\n",
    "get_embed_out = keras.backend.function(\n",
    "    model.layers[0].input,\n",
    "    model.layers[1].output)\n",
    "\n",
    "\n",
    "layer_output = get_embed_out([X_test_seq[0]])\n",
    "\n",
    "alarms = [44, 45 ,90, 150]\n",
    "emb_alarms = tf.constant([mapping_dict[alarm] for alarm in alarms])\n",
    "\n",
    "words = get_embed_out([enc_review])[0]\n",
    "\n",
    "plt.scatter(words[:,0], words[:,1])\n",
    "for i, txt in enumerate(alarms):\n",
    "    plt.annotate(txt, (words[i,0], words[i,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e0fb32f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<KerasTensor: shape=(None, 53) dtype=float32 (created by layer 'embedding_1_input')>,\n",
       " <KerasTensor: shape=(None, 20, 64) dtype=float32 (created by layer 'conv1d_5')>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].input, model.layers[1].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b81ef0d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer conv1d is incompatible with the layer: : expected min_ndim=3, found ndim=2. Full shape received: (53, 128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-a6964863743b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_embed_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_test_seq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/backend.py\u001b[0m in \u001b[0;36mfunc\u001b[0;34m(model_inputs)\u001b[0m\n\u001b[1;32m   4076\u001b[0m     \u001b[0mwrap_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4077\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4078\u001b[0;31m       \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4079\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mwrap_outputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4080\u001b[0m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    413\u001b[0m     \"\"\"\n\u001b[1;32m    414\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m--> 415\u001b[0;31m         inputs, training=training, mask=mask)\n\u001b[0m\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1018\u001b[0m         training=training_mode):\n\u001b[1;32m   1019\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m       \u001b[0minput_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1021\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0meager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \u001b[0mcall_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    232\u001b[0m                          \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                          \u001b[0;34m'. Full shape received: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                          str(tuple(shape)))\n\u001b[0m\u001b[1;32m    235\u001b[0m     \u001b[0;31m# Check dtype.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer conv1d is incompatible with the layer: : expected min_ndim=3, found ndim=2. Full shape received: (53, 128)"
     ]
    }
   ],
   "source": [
    "layer_output = get_embed_out([X_test_seq[0]])\n",
    "print(type(layer_output), len(layer_output), layer_output[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49dce51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_wba124_X_seq, n_alarm_wba124, mapping_dict_wba124 = label_encode(wba124.X_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5564ab0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "feature = pad_sequences(enc_wba124_X_seq, maxlen=n_alarm_wba124, value=0, \n",
    "                         truncating='pre', padding='pre') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dd126c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.5609915198956295, 1: 4.598930481283422}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(feature, wba124.major_down_arr, test_size=0.4)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.4)\n",
    "\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(y_train),\n",
    "                                                 y_train)\n",
    "weights ={}\n",
    "for idx, val in enumerate(class_weights):\n",
    "    weights[idx] = val\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5199fb5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "162/162 [==============================] - 6s 22ms/step - loss: 0.6785 - accuracy: 0.5545 - val_loss: 0.6619 - val_accuracy: 0.4423\n",
      "Epoch 2/10\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.6614 - accuracy: 0.4715 - val_loss: 0.6575 - val_accuracy: 0.4583\n",
      "Epoch 3/10\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.6477 - accuracy: 0.4713 - val_loss: 0.7895 - val_accuracy: 0.3711\n",
      "Epoch 4/10\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.6436 - accuracy: 0.4638 - val_loss: 0.6128 - val_accuracy: 0.4893\n",
      "Epoch 5/10\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.6346 - accuracy: 0.5116 - val_loss: 0.6018 - val_accuracy: 0.5058\n",
      "Epoch 6/10\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.6254 - accuracy: 0.4913 - val_loss: 0.7448 - val_accuracy: 0.3910\n",
      "Epoch 7/10\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.6182 - accuracy: 0.4818 - val_loss: 0.6637 - val_accuracy: 0.4535\n",
      "Epoch 8/10\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.6080 - accuracy: 0.5444 - val_loss: 0.6437 - val_accuracy: 0.4651\n",
      "Epoch 9/10\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.6047 - accuracy: 0.5932 - val_loss: 0.6631 - val_accuracy: 0.4453\n",
      "Epoch 10/10\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5899 - accuracy: 0.5547 - val_loss: 0.6133 - val_accuracy: 0.4937\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(n_alarm_wba124, 128, input_length=feature.shape[1], mask_zero=True))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_accuracy', mode='max', patience=5)]\n",
    "\n",
    "model.fit(np.array(X_train), np.array(y_train), \n",
    "          epochs=10, \n",
    "          batch_size=BATCH_SIZE,\n",
    "          verbose = 1,\n",
    "          class_weight=weights,\n",
    "          callbacks=callbacks,\n",
    "          validation_data=(X_val, np.array(y_val)))\n",
    "\n",
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1e427919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_14 (Embedding)     (None, 48, 128)           6144      \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 48, 32)            12320     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 24, 32)            0         \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 71,765\n",
      "Trainable params: 71,765\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bfd2bf71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[552 696]\n",
      " [ 35  94]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 0.4691358024691358)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = []\n",
    "for ele in pred:\n",
    "    classes.append(int((ele>0.5)[0]))\n",
    "\n",
    "print(confusion_matrix(np.array(y_test), classes)), accuracy_score(np.array(y_test), classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c9ffd6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=1.000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[553, 695],\n",
       "        [ 37,  92]]),\n",
       " 0.4684095860566449)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "def to_labels(y_scores, threshold):\n",
    "    return (y_scores >= threshold).astype('int')\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(np.array(y_test), classes)\n",
    "J = tpr - fpr\n",
    "ix = np.argmax(J)\n",
    "best_thresh = thresholds[ix]\n",
    "print('Best Threshold=%f' % (best_thresh))\n",
    "\n",
    "testest = to_labels(classes, best_thresh) # best thresh optimizes recall\n",
    "confusion_matrix(np.array(y_test), testest), accuracy_score(np.array(y_test), testest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ee5246a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer conv1d_18 is incompatible with the layer: : expected min_ndim=3, found ndim=2. Full shape received: (4, 128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-1b1a8c2a2a1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0memb_alarms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmapping_dict_wba124\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0malarm\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0malarm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0malarms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_embed_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0memb_alarms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/backend.py\u001b[0m in \u001b[0;36mfunc\u001b[0;34m(model_inputs)\u001b[0m\n\u001b[1;32m   4076\u001b[0m     \u001b[0mwrap_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4077\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4078\u001b[0;31m       \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4079\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mwrap_outputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4080\u001b[0m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    413\u001b[0m     \"\"\"\n\u001b[1;32m    414\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m--> 415\u001b[0;31m         inputs, training=training, mask=mask)\n\u001b[0m\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1018\u001b[0m         training=training_mode):\n\u001b[1;32m   1019\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m       \u001b[0minput_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1021\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0meager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \u001b[0mcall_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/looselot/virtualenvs/ENV-MAL/lib/python3.7/site-packages/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    232\u001b[0m                          \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                          \u001b[0;34m'. Full shape received: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                          str(tuple(shape)))\n\u001b[0m\u001b[1;32m    235\u001b[0m     \u001b[0;31m# Check dtype.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer conv1d_18 is incompatible with the layer: : expected min_ndim=3, found ndim=2. Full shape received: (4, 128)"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# with a Sequential model\n",
    "get_embed_out = keras.backend.function(\n",
    "    [model.layers[0].input],\n",
    "    [model.layers[1].output])\n",
    "\n",
    "layer_output = get_embed_out([X_test[0].reshape(-1, X_test[0].shape[0])])\n",
    "\n",
    "alarms = [44, 45 ,90, 150]\n",
    "emb_alarms = tf.constant([mapping_dict_wba124[alarm] for alarm in alarms])\n",
    "\n",
    "words = get_embed_out([emb_alarms])[0]\n",
    "\n",
    "plt.scatter(words[:,0], words[:,1])\n",
    "for i, txt in enumerate(alarms):\n",
    "    plt.annotate(txt, (words[i,0], words[i,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "308e683d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([28, 29, 42, 17], dtype=int32)>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_alarms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8fcf1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920dde0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_result # Embedding + Conv1D + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "701dbb0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{12: [[0.6287420988082886,\n",
       "   0.5336463451385498,\n",
       "   0.4633152186870575,\n",
       "   0.6475076079368591],\n",
       "  array([[932, 298],\n",
       "         [395, 341]])],\n",
       " (12, 30): [0.6287420988082886,\n",
       "  0.5336463451385498,\n",
       "  0.4633152186870575,\n",
       "  0.6475076079368591],\n",
       " 24: [[0.6324173808097839,\n",
       "   0.5170998573303223,\n",
       "   0.5142857432365417,\n",
       "   0.6386768221855164],\n",
       "  array([[877, 353],\n",
       "         [357, 378]])],\n",
       " (24, 58): [0.6324173808097839,\n",
       "  0.5170998573303223,\n",
       "  0.5142857432365417,\n",
       "  0.6386768221855164],\n",
       " 48: [[0.6813942790031433,\n",
       "   0.4801097512245178,\n",
       "   0.47683924436569214,\n",
       "   0.6113092303276062],\n",
       "  array([[850, 379],\n",
       "         [384, 350]])],\n",
       " (48, 115): [0.6813942790031433,\n",
       "  0.4801097512245178,\n",
       "  0.47683924436569214,\n",
       "  0.6113092303276062],\n",
       " 72: [[0.8038536310195923,\n",
       "   0.42728298902511597,\n",
       "   0.5156462788581848,\n",
       "   0.5596330165863037],\n",
       "  array([[719, 508],\n",
       "         [356, 379]])],\n",
       " (72, 169): [0.8038536310195923,\n",
       "  0.42728298902511597,\n",
       "  0.5156462788581848,\n",
       "  0.5596330165863037]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_result # stack Conv1D above LSTM (without removing noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cd13298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{12: [[0.6843389272689819,\n",
       "   0.4783889949321747,\n",
       "   0.7767145037651062,\n",
       "   0.5706973671913147],\n",
       "  array([[405, 531],\n",
       "         [140, 487]])],\n",
       " (12, 38): [0.6843389272689819,\n",
       "  0.4783889949321747,\n",
       "  0.7767145037651062,\n",
       "  0.5706973671913147],\n",
       " 24: [[0.6756141185760498,\n",
       "   0.4753146171569824,\n",
       "   0.7695924639701843,\n",
       "   0.5767813324928284],\n",
       "  array([[448, 542],\n",
       "         [147, 491]])],\n",
       " (24, 71): [0.6756141185760498,\n",
       "  0.4753146171569824,\n",
       "  0.7695924639701843,\n",
       "  0.5767813324928284],\n",
       " 48: [[0.686356782913208,\n",
       "   0.4554730951786041,\n",
       "   0.7577160596847534,\n",
       "   0.5595026612281799],\n",
       "  array([[454, 587],\n",
       "         [157, 491]])],\n",
       " (48, 133): [0.686356782913208,\n",
       "  0.4554730951786041,\n",
       "  0.7577160596847534,\n",
       "  0.5595026612281799],\n",
       " 72: [[0.6810200810432434,\n",
       "   0.4411483108997345,\n",
       "   0.7048929929733276,\n",
       "   0.5485183000564575],\n",
       "  array([[483, 584],\n",
       "         [193, 461]])],\n",
       " (72, 193): [0.6810200810432434,\n",
       "  0.4411483108997345,\n",
       "  0.7048929929733276,\n",
       "  0.5485183000564575]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_result # downsample negative data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1b9a45c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(12, 34): [0.7047469019889832,\n",
       "  0.1626969575881958,\n",
       "  0.7081339955329895,\n",
       "  0.534690797328949],\n",
       " (24, 66): [0.7164930105209351,\n",
       "  0.15516085922718048,\n",
       "  0.7257053256034851,\n",
       "  0.517192006111145],\n",
       " (48, 126): [0.6946452856063843,\n",
       "  0.14175792038440704,\n",
       "  0.7391975522041321,\n",
       "  0.4753846228122711]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_result # monitor val recall\n",
    "# {72: [0.7307, 0.1300, 0.8012, 0.3925]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c67a3624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(24, 34): [0.5954988598823547,\n",
       "  0.1780264526605606,\n",
       "  0.5582137107849121,\n",
       "  0.6430995464324951],\n",
       " (12, 34): [0.6063371300697327,\n",
       "  0.17000912129878998,\n",
       "  0.5948963165283203,\n",
       "  0.6087858080863953],\n",
       " (24, 66): [0.6042451858520508,\n",
       "  0.1820913404226303,\n",
       "  0.47492164373397827,\n",
       "  0.6962750554084778],\n",
       " (48, 126): [0.5850675106048584,\n",
       "  0.1593644618988037,\n",
       "  0.5108024477958679,\n",
       "  0.6473504304885864],\n",
       " (72, 185): [0.5972234010696411,\n",
       "  0.1689220666885376,\n",
       "  0.5535168051719666,\n",
       "  0.6538076400756836]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_result # train on 5 machines same EQ family with shuffle and masking and empty datapoints removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8529d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_result # everything on top but trained on a bidirectional LSTM layer\n",
    "# {12: [1.4355, 0.2238, 0.2041, 0.8222]}\n",
    "# {24: [1.0140, 0.2651, 0.2962, 0.8258]}\n",
    "# {48: [0.9016, 0.2873, 0.3210, 0.8366]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c179781",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d11b162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef04aea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENV-MAL-VE",
   "language": "python",
   "name": "env-mal-ve_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
